{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 530 Code Snippets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //**** Mapping Values\n",
    "id_map = {}\n",
    "n = 1\n",
    "for user in people.unique():\n",
    "    id_map[user] = n\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //********************************************************************\n",
    "# //*** Pandas Frequency from dataframe\n",
    "# //********************************************************************\n",
    "df.value_counts().sort_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*****************************************\n",
    "# //*** Build a probability mass function\n",
    "# //*****************************************\n",
    "# //*** Returns Series as a PMF\n",
    "# //*****************************************\n",
    "def build_pmf(input_series):\n",
    "    output_series = input_series.copy()\n",
    "    total_values = input_series.sum()\n",
    "    for value,freq in output_series.items():\n",
    "        #print(f\"{value} {freq} {total_values} {freq/total_values}\")\n",
    "        output_series.loc[value] = freq/total_values\n",
    "    return output_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Build a Cumulative Distribution Function from a Probability Mass Function\n",
    "# //*** Returns a Series\n",
    "def build_cdf(input_series):\n",
    "    # //*** If input is not panda or pd series, try to convert it\n",
    "    if not isinstance(input_series,pd.core.series.Series):\n",
    "        input_series = pd.Series(input_series)\n",
    "        \n",
    "    # //*** If input is np.Array\n",
    "    output_series = input_series.copy()\n",
    "    cumulative_value = 0\n",
    "    for value,freq in output_series.items():\n",
    "        #print(f\"{value} {freq} {cumulative_value} {freq + cumulative_value}\")\n",
    "        cumulative_value = freq + cumulative_value\n",
    "        output_series.loc[value] = cumulative_value\n",
    "    return output_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Get a Percentile Rank from a CDF Frequency Series.\n",
    "def PercentileRank(scores, input_score):\n",
    "    count = 0\n",
    "    for value,cum_prob in scores.items():\n",
    "        if value <= input_score:\n",
    "            count += 1\n",
    "\n",
    "    percentile_rank = round(100.0 * count / len(scores),0)\n",
    "    return percentile_rank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Retrieve a percentile value from a CDF.\n",
    "# //*** Returns index value closest to input parameter percentile.\n",
    "def get_cdf_percentile(input_cdf,percentile):\n",
    "    #print(f\"{input_cdf}\")\n",
    "    #//*** Initialize output to first value\n",
    "    output = input_cdf.index[0]\n",
    "    \n",
    "    #//*** Loop through all items till the value exceeds the percentile\n",
    "    #//*** Return value from last loop\n",
    "    for index,value in input_cdf.items():\n",
    "        \n",
    "        if value > percentile:\n",
    "            return output\n",
    "        else:\n",
    "            output = index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //********************************************************************\n",
    "# //*** Function - Build a frequency Dictionary from an input Series\n",
    "# //********************************************************************\n",
    "def build_frequency_dict(input_series):\n",
    "    output_dict = {}\n",
    "    \n",
    "    for x in input_series.sort_values():\n",
    "\n",
    "        if x not in  output_dict.keys():\n",
    "            output_dict[x] = 1\n",
    "        else:\n",
    "            output_dict[x] = output_dict[x] + 1\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*********************************************************************\n",
    "#//*** Quick regression model results using patsy formula.\n",
    "#//*********************************************************************\n",
    "#//*** input_dict kwargs:\n",
    "#//*** summary (boolean) - Display a summary evaluation of the model\n",
    "#//*** pval (boolean) - Display the p-value of the model\n",
    "#//*** getrsquared (boolean) - returns the r**2 value of the model\n",
    "#//*** getpvalue (boolean) - returns the p value of the model\n",
    "#//*** getmodel (boolean) - returns the model\n",
    "#//*** method (string) - model type to run\n",
    "#//***       ols (default) - Ordinary Least Squares (linear regression)\n",
    "#//***       poisson - Poisson regression\n",
    "#//***       logit - logistic regression.\n",
    "#//*** Single output are returned as a single tyoe\n",
    "#//*** Multiple outots return as a string in the following order: rsquared, pvalue, model\n",
    "#//*****************************************************************************************\n",
    "def qmodel_patsy_ols(df,formula,**input_dict):\n",
    "    \n",
    "    #//*** Check that Statsmodel is loaded.\n",
    "    #//*** Requires the sys library which imports if not in use.\n",
    "    try:\n",
    "        if 'sys' not in sys.modules:\n",
    "            print(f\"{sys.modules}\")\n",
    "        else:\n",
    "            import sys\n",
    "    except:\n",
    "        import sys\n",
    "\n",
    "    if 'sm' not in sys.modules:\n",
    "        try:\n",
    "            import statsmodels.api as sm\n",
    "        except:\n",
    "            print(f\"This Function requires the 'statsmodel' library to be installed\")\n",
    "            return\n",
    "    if 'sm' not in sys.modules:\n",
    "        print(f\"Load Statsmodel\")\n",
    "        try:\n",
    "            import statsmodels.formula.api as smf\n",
    "        except:\n",
    "            print(f\"This Function requires the 'statsmodel' library to be installed\")\n",
    "            return\n",
    "\n",
    "    output = []\n",
    "    display_summary = False\n",
    "    display_pval = False\n",
    "    getpvalue = False\n",
    "    getrsquared = False\n",
    "    getmodel = False\n",
    "    method = \"ols\"\n",
    "    generalError = False\n",
    "    \n",
    "    for key,value in input_dict.items():\n",
    "        if key == 'summary':\n",
    "            display_summary = value\n",
    "        if key == 'pvalue':\n",
    "            display_pval = value\n",
    "        if key == 'getpvalue':\n",
    "            getpvalue = value\n",
    "        if key == 'getrsquared':\n",
    "            getrsquared = value\n",
    "        if key == 'method':\n",
    "            method = value\n",
    "        if key == 'getmodel':\n",
    "            getmodel = value\n",
    "\n",
    "    if method == \"ols\":\n",
    "        model = smf.ols(formula=formula, data=df).fit()\n",
    "    elif method == \"poisson\":\n",
    "        model = smf.poisson(formula, data=join).fit()\n",
    "    elif method == \"logit\":\n",
    "        try:\n",
    "            #model = smf.logit(formula, data=df).fit()\n",
    "            model = smf.logit(formula, data=df)\n",
    "            \n",
    "            #//*** Endogenous variables designates variables in an economic/econometric model that are explained, or predicted, by that mode\n",
    "            #//*** Test for endogenous variables. If less than half the variables are explained by the model, reject the model.\n",
    "            nobs = len(model.endog)\n",
    "            \n",
    "            if nobs < len(df)/2:\n",
    "                generalError = True\n",
    "            else:\n",
    "                model = model.fit()\n",
    "        except:\n",
    "            generalError = True\n",
    "    else:\n",
    "        print(f\"Provide a valid Method:\\n method='ols' [default]\\nmethod='logit'\")\n",
    "        return\n",
    "    # //*** On an error return 999 for all requested values\n",
    "    if generalError:\n",
    "        if getrsquared:\n",
    "            output.append(999)\n",
    "\n",
    "        if getpvalue:\n",
    "            output.append(pd.Series(data=[999]))\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    if display_summary:\n",
    "        print(\"==========================\")\n",
    "        print(\"Q model Quick Display\")\n",
    "        print(\"==========================\")\n",
    "        print_model = model.summary()\n",
    "        print(f\"{print_model}\")\n",
    "    if display_pval:\n",
    "        print(\"==========================\")\n",
    "        print(\"Q model P Values\")\n",
    "        print(\"==========================\")\n",
    "        model.pvalues.drop(['Intercept'])\n",
    "        for x,y in model.pvalues.items():\n",
    "            if x != 'Intercept':\n",
    "                print(f\"{x} : {y}\")\n",
    "    if getrsquared:\n",
    "        if method == \"logit\":\n",
    "            output.append(model.prsquared)\n",
    "        else:\n",
    "            output.append(model.rsquared)\n",
    "    \n",
    "    if getpvalue:\n",
    "        try:\n",
    "            output.append(model.pvalues.drop(index='Intercept') )\n",
    "        except:\n",
    "            output.append(model.pvalues.values)\n",
    "    \n",
    "    if getmodel:\n",
    "        output.append(model)\n",
    "\n",
    "    #//*** If more than one output variable, output a list\n",
    "    if len(output) > 1:\n",
    "        return output\n",
    "    elif len(output) == 1:\n",
    "        #//*** Single elements, just return the element\n",
    "        return output[0]\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*****************************************\n",
    "# //*** Loop through a series\n",
    "# //*****************************************\n",
    "for index, value in s.items():\n",
    "    print(f\"{index} {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Bin a continuous variable pandas Series\n",
    "# //*** Probably should use np.arange and pandas groupby instead\n",
    "def bin_value_counts(input_series, bin_size):\n",
    "    \n",
    "    # //*** build New Index\n",
    "    bin_index = np.arange(int(input_series.index.min()), int(input_series.index.max()+1), bin_size, float)\n",
    "    \n",
    "    # //*** Binned values as an array, these will eventually be combined with the bin_index\n",
    "    bin_values = []\n",
    "\n",
    "   \n",
    "    #//*** Build Bin counter. Start with Int of min value\n",
    "    loop_bin_index = 1\n",
    "    \n",
    "    #//*** build counter for the current bin\n",
    "    loop_bin_value = 0\n",
    "    \n",
    "    for bin in range(0,len(bin_index)):\n",
    "    \n",
    "        loop_value = 0\n",
    "        for index,value in input_series.items():\n",
    "            \n",
    "            if bin+1 == len(bin_index):\n",
    "                break\n",
    "              \n",
    "            if bin_index[bin] <= index < bin_index[bin + 1]:\n",
    "                loop_value = loop_value + value\n",
    "            if index > bin_index[bin + 1]:\n",
    "                continue\n",
    "        \n",
    "            \n",
    "        bin_values.append(loop_value)\n",
    "    #print(bin_index)\n",
    "    #print(bin_values)\n",
    "    #print(input_series)\n",
    "    return pd.Series(index=bin_index, data=bin_values).tail(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Matplotlib example side by side bar chart\n",
    "n = 5\n",
    "var1 = total_employee_hours_distribution_pmf\n",
    "var2 = billable_employee_hours_distribution_pmf\n",
    "var3 = overhead_employee_hours_distribution_pmf\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.2\n",
    "opacity = 0.9\n",
    "ax.bar(index, var1, bar_width, alpha=opacity, color='navy',label='Total Productivity')\n",
    "                \n",
    "ax.bar(index+bar_width, var2, bar_width, alpha=opacity, color='darkcyan', label='Billable')\n",
    "ax.bar(index+(bar_width*2), var3, bar_width, alpha=opacity, color='skyblue', label='Overhead')\n",
    "plt.ylim(billable_employee_hours_distribution_pmf.min() * .95,billable_employee_hours_distribution_pmf.max() * 1.05)\n",
    "#ax.set_xlabel('Seasons')\n",
    "ax.set_ylabel('Frequencies')\n",
    "plt.title(f\"All Employee: Productivity Distribution\")\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(g['days_of_week'])\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //**** Legends automatically generate too many labels.\n",
    "def deduplicate_legend(input_ax):\n",
    "    # //**** Get handle and label list for the current legend\n",
    "    # //**** Use first instance, toss the rest.\n",
    "    handles, labels = input_ax.get_legend_handles_labels()\n",
    "\n",
    "    handle_dict = {}\n",
    "\n",
    "    for x in range(len(labels)):\n",
    "        if labels[x] not in handle_dict.keys():\n",
    "            # //*** Label = handle\n",
    "            handle_dict[labels[x]] = handles[x]\n",
    "\n",
    "    # //*** Build unique output ists and handles\n",
    "    out_handles = []\n",
    "    out_labels = []\n",
    "    \n",
    "    for label,handle in handle_dict.items():\n",
    "        out_handles.append(handle)\n",
    "        out_labels.append(label)\n",
    "    \n",
    "    return out_handles,out_labels\n",
    "\n",
    "   \n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(sample_sizes,mean_standard_errors,1, color='r', label='Mean Error')\n",
    "ax.plot(sample_sizes,median_standard_errors,1, color='g', label='Median Error')\n",
    "plt.ylim(0,pd.Series(mean_standard_errors).max()*1.05)\n",
    "# //**** DeDuplicate handles and labels\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "plt.legend(handles,labels )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Better example in: Week07_StoneburnerKurt_DSC530\n",
    "# //*** dataframe binning from CDF\n",
    "# //*** Displays a percentile plot of independent variable vs dependent variables\n",
    "# //*** Dependent variable - dataframe column name - X axis, used as a mean for comparison\n",
    "# //*** Independent variable - dataframe column name - Y axis, used for CDF percentiles\n",
    "# //*** input_bin_percentages = a list [.1,.3,.5] of percentages to use for percentiles.\n",
    "# //*** plot_now = Boolean. True draws a basic plot with no labels. False, doesn't draw plot and allows more plt\n",
    "# //***            values to be assigned after such as adding labels.\n",
    "def plot_cdf_percentiles(input_df,dependent_variable,independent_variable,input_bin_percentages,plot_now=True):\n",
    "    # //*** Get min and Max ages to set the limits of the group by bins\n",
    "    # //*** Converting to integers adds headroom (extra space) to the floor\n",
    "    # //*** Max + 1 gives a little extra room for Max\n",
    "    minVal = int(input_df[dependent_variable].min())\n",
    "    maxVal = int(input_df[dependent_variable].max())+1\n",
    "\n",
    "    # //*** Build binning parameters. Minimum value, Maximum Value, # of Bins\n",
    "    bins = np.arange(minVal, maxVal, len(input_bin_percentages))\n",
    "\n",
    "    # //*** generate indices based on bins\n",
    "    indices = np.digitize(input_df[dependent_variable], bins)\n",
    "    groups = input_df.groupby(indices)\n",
    "\n",
    "    # //*** Build mean of dependent variable\n",
    "    # //*** Builds a list of means for each dependent binned values\n",
    "    dependent_variable_mean = [group[dependent_variable].mean() for i, group in groups]\n",
    "\n",
    "    # //*** Build a list CDFs for each binned value\n",
    "    CDFs = []\n",
    "    # //*** group is a tuple. Tuple[0] = index, tuple[1] = dataframe\n",
    "    for group in groups:\n",
    "        #//*** CDF for each binned dataframe\n",
    "        #//*** Each group is a tuple (Index,dataFrame) - hence group[1] = dataFrame\n",
    "        #//*** Get the independent variable in each group\n",
    "        #//*** 1. Build histogram\n",
    "        #//*** 2. build PMF\n",
    "        #//*** 3. build CDF\n",
    "        #//*** 4. Add resulting CDF to CDFs\n",
    "        CDFs.append( build_cdf( build_pmf( (group[1][independent_variable].value_counts().sort_index() ) ) ) )\n",
    "\n",
    "    labels = []\n",
    "    for x in input_bin_percentages:\n",
    "        # //*** Build a list of percentiles to plot from each cdf using the percentile stored in bin_values\n",
    "        weight_percentiles = [get_cdf_percentile(cdf,x) for cdf in CDFs]\n",
    "        loop_label= f\"{int(x*100)}th\"\n",
    "        plt.plot(dependent_variable_mean,weight_percentiles,1, label=loop_label)\n",
    "        labels.append(loop_label)\n",
    "\n",
    "    plt.legend(labels)\n",
    "    plt.xlim(minVal,maxVal)\n",
    "    \n",
    "    if plot_now==True:\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
