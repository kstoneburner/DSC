{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Page 114: 9-1 (As sample size increases, the power of a hypothesis test increases, which means it is more likely to be positive if the effect is real…)\n",
    "    Page 128: 10-1 (Using the data from the BRFSS, compute the linear least squares fit for log(weight) versus height…)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 530 - Week 08\n",
    "- ## Chapter 9, Exercise 1\n",
    "\n",
    "**Exercise:** As sample size increases, the power of a hypothesis test increases, which means it is more likely to be positive if the effect is real. Conversely, as sample size decreases, the test is less likely to be positive even if the effect is real.\n",
    "\n",
    "To investigate this behavior, run the tests in this chapter with different subsets of the NSFG data. You can use `thinkstats2.SampleRows` to select a random subset of the rows in a DataFrame.\n",
    "\n",
    "What happens to the p-values of these tests as sample size decreases? What is the smallest sample size that yields a positive test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //****************************************************************************************\n",
    "# //*** Set Working Directory to thinkstats folder.\n",
    "# //*** This pseudo-relative path call should work on all Stoneburner localized projects. \n",
    "# //****************************************************************************************\n",
    "\n",
    "import os\n",
    "import sys\n",
    "workingPath = os.getcwd().replace(\"coding\", \"ThinkStats2\\\\code\")\n",
    "sys.path.insert(1, workingPath)\n",
    "os.chdir(workingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Imports and Load Data\n",
    "import nsfg\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "import first\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "resp = nsfg.ReadFemResp()\n",
    "preg = nsfg.ReadFemPreg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSample_from_series(input_df,input_percentage=.1):\n",
    "    #//*** Returns a random sampling of the input_df or Series\n",
    "        \n",
    "    sample_size = int(len(input_df) * input_percentage)\n",
    "    remainder_size = len(input_df) - sample_size\n",
    "    \n",
    "    print(f\"{sample_size} {remainder_size}\")\n",
    "    \n",
    "    # //*** Set Loop safety as a function of sample_size and input_percentage\n",
    "    loop_safe_max = sample_size * 1/input_percentage**2\n",
    "    print(f\"Loop Safe Max: {loop_safe_max}\")\n",
    "    \n",
    "    loop_safe = 0\n",
    "    sample_index = []\n",
    "    sample_dict = {}\n",
    "    \n",
    "    # //*** Get a random integer between 0 and size of input_series -1\n",
    "    # //*** Build a list of unique random numbers equal to the sample size\n",
    "    # //*** A dictionary is used to keep track of unique values.\n",
    "    while len(sample_index) < sample_size:\n",
    "        # //*** Pick a random integer between - and len(input_df) -1 \n",
    "        random_int = np.random.randint( (len(input_df)-1) )\n",
    "        \n",
    "        #//*** Convert integer to index key\n",
    "        random_int = input_df.index[random_int]\n",
    "        \n",
    "               \n",
    "        \n",
    "        #//*** Check if we've used this number\n",
    "        if random_int not in sample_dict.keys():\n",
    "            sample_index.append(random_int)\n",
    "            sample_dict[random_int] = \"\"\n",
    "        \n",
    "        loop_safe = loop_safe + 1\n",
    "        \n",
    "        if loop_safe > loop_safe_max:\n",
    "            print(\"Loop Maximum exceeded! Quitting for Safety!\")\n",
    "            break;\n",
    "    \n",
    "    #//*** Sort the values\n",
    "    sample_index = np.sort(sample_index)\n",
    "    \n",
    "    #//*** Build a list of values, 1 is sample, 0 is not sample\n",
    "    #//*** This will be a column to add to the input_df\n",
    "    is_sample = []\n",
    "    for x in input_df.index:\n",
    "        if x in sample_index:\n",
    "            is_sample.append(1)\n",
    "        else:\n",
    "            is_sample.append(0)\n",
    "    \n",
    "    #//*** Add is_sample column\n",
    "    input_df = input_df.assign( is_sample = is_sample)\n",
    "    \n",
    "    # //*** get sample and remainder dataframes based on is_sample attribute\n",
    "    # //*** Get the sample data frame and the remainder dataframe\n",
    "    sample_df = input_df[input_df ['is_sample'] == 1]\n",
    "    remainder_df = input_df[input_df ['is_sample'] == 0 ]\n",
    "    print(len(sample_index))\n",
    "    print(len(sample_df))\n",
    "    \n",
    "    \n",
    "    return sample_df, remainder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Mean Difference - Test Statistic: 0.07511149297508268\n",
      "[40 38 39 ... 42 40 39]\n",
      "Proceeed!\n"
     ]
    }
   ],
   "source": [
    "def hypothesis_test(input):\n",
    "    \n",
    "    valid_types = [\"mean_diff\"]\n",
    "    \n",
    "    if 'type' not in input.keys():\n",
    "        print(f\"hypothesis test requires a type value\")\n",
    "        return \"\"\n",
    "    \n",
    "    if input['type'] not in valid_types:\n",
    "        print(\"Need a valid input type\")\n",
    "        print(f\"{valid_types}\")\n",
    "        return \"\"\n",
    "    \n",
    "    if 'data' not in input.keys():\n",
    "        print(f\"Need valid data\")\n",
    "        return \"\"\n",
    "    \n",
    "    print(f\"Proceeed!\")\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#sample_df,remainder_df = getSample_from_series(total_weight,.1)\n",
    "\n",
    "#total_weight['totalwgt_lb']\n",
    "#total_weight['agepreg']\n",
    "\n",
    "#Permutation Test\n",
    "#Difference in standard deviation\n",
    "#print(np.std( total_weight['totalwgt_lb']))\n",
    "#print(np.std( total_weight['agepreg']))\n",
    "#abs(np.std( total_weight['totalwgt_lb']) - np.std( total_weight['agepreg']))\n",
    "\n",
    "#get_p_scores(total_weight['totalwgt_lb'])\n",
    "\n",
    "#print(f\"{scipy.stats.pearsonr(total_weight['totalwgt_lb'],total_weight['agepreg'])}\")\n",
    "#correlation Testing\n",
    "#Testing Proportions\n",
    "#Chi Squared test\n",
    "\n",
    "#Difference of Means Permutation test\n",
    "# Generate a test statistic for reference.\n",
    "# This is the difference of the means\n",
    "# test statistic or t-value is the abs(difference of means)\n",
    "# combine both data sets.\n",
    "# 1000 thousand times:\n",
    "#      Randomly split combined data in half.\n",
    "#      Find the difference of the means for the random samples, for a random sample test statistic\n",
    "#      count the random test statistics that are greater than the base line test statistic\n",
    "# The P-value is the count / total tests run (1000)\n",
    "# The P-value represents the chance of the outcome occuring randomly.\n",
    "# Reference: https://www.ohbmbrainmappingblog.com/blog/a-brief-overview-of-permutation-testing-with-examples\n",
    "\n",
    "# //*** Get the birthweight Series data from the preg dataframe\n",
    "preg = preg.dropna(subset=['totalwgt_lb','agepreg'])\n",
    "\n",
    "firsts_df = preg[preg.birthord == 1]\n",
    "others_df = preg[preg.birthord != 1]\n",
    "\n",
    "first_preglen = firsts_df['prglngth']\n",
    "other_preglen = others_df['prglngth']\n",
    "\n",
    "\n",
    "\n",
    "test_statistic = abs( np.mean(first_preglen) - np.mean(other_preglen) )\n",
    "\n",
    "print(f\"Absolute Mean Difference - Test Statistic: {test_statistic}\")\n",
    "\n",
    "combined_data = np.hstack((first_preglen,other_preglen))\n",
    "\n",
    "np.random.shuffle(combined_data)\n",
    "\n",
    "print(f\"{combined_data}\")\n",
    "\n",
    "hypothesis_test({'type':'mean_diff','data':(first_preglen,other_preglen)})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Chapter 10, Exercise 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
