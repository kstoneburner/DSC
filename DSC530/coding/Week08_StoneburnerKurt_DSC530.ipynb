{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    Page 114: 9-1 (As sample size increases, the power of a hypothesis test increases, which means it is more likely to be positive if the effect is real…)\n",
    "    Page 128: 10-1 (Using the data from the BRFSS, compute the linear least squares fit for log(weight) versus height…)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 530 - Week 08\n",
    "- ## Chapter 9, Exercise 1\n",
    "\n",
    "**Exercise:** As sample size increases, the power of a hypothesis test increases, which means it is more likely to be positive if the effect is real. Conversely, as sample size decreases, the test is less likely to be positive even if the effect is real.\n",
    "\n",
    "To investigate this behavior, run the tests in this chapter with different subsets of the NSFG data. You can use `thinkstats2.SampleRows` to select a random subset of the rows in a DataFrame.\n",
    "\n",
    "What happens to the p-values of these tests as sample size decreases? What is the smallest sample size that yields a positive test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //****************************************************************************************\n",
    "# //*** Set Working Directory to thinkstats folder.\n",
    "# //*** This pseudo-relative path call should work on all Stoneburner localized projects. \n",
    "# //****************************************************************************************\n",
    "\n",
    "import os\n",
    "import sys\n",
    "workingPath = os.getcwd().replace(\"coding\", \"ThinkStats2\\\\code\")\n",
    "sys.path.insert(1, workingPath)\n",
    "os.chdir(workingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Imports and Load Data\n",
    "import nsfg\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "import first\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "resp = nsfg.ReadFemResp()\n",
    "preg = nsfg.ReadFemPreg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSample_from_series(input_df,input_percentage=.1):\n",
    "    #//*** Returns a random sampling of the input_df or Series\n",
    "    # //*** Series type conversion to dataFrame\n",
    "    \n",
    "    is_series = False\n",
    "    \n",
    "    if isinstance(input_df, pd.Series):\n",
    "        input_df = pd.DataFrame(input_df)\n",
    "        is_series = True\n",
    "    \n",
    "    sample_size = int(len(input_df) * input_percentage)\n",
    "    remainder_size = len(input_df) - sample_size\n",
    "    \n",
    "    #print(f\"{sample_size} {remainder_size}\")\n",
    "    \n",
    "    # //*** Set Loop safety as a function of sample_size and input_percentage\n",
    "    loop_safe_max = (sample_size * 1/input_percentage)**2\n",
    "    #print(f\"Loop Safe Max: {loop_safe_max}\")\n",
    "    \n",
    "    loop_safe = 0\n",
    "    sample_index = []\n",
    "    sample_dict = {}\n",
    "    \n",
    "    # //*** Get a random integer between 0 and size of input_series -1\n",
    "    # //*** Build a list of unique random numbers equal to the sample size\n",
    "    # //*** A dictionary is used to keep track of unique values.\n",
    "    while len(sample_index) < sample_size:\n",
    "        # //*** Pick a random integer between - and len(input_df) -1 \n",
    "        random_int = np.random.randint( (len(input_df)-1) )\n",
    "        \n",
    "        #//*** Convert integer to index key\n",
    "        random_int = input_df.index[random_int]\n",
    "        \n",
    "               \n",
    "        \n",
    "        #//*** Check if we've used this number\n",
    "        if random_int not in sample_dict.keys():\n",
    "            sample_index.append(random_int)\n",
    "            sample_dict[random_int] = \"\"\n",
    "        \n",
    "        loop_safe = loop_safe + 1\n",
    "        \n",
    "        if loop_safe > loop_safe_max:\n",
    "            print(\"Loop Maximum exceeded! Quitting for Safety!\")\n",
    "            break;\n",
    "    \n",
    "    #//*** Sort the values\n",
    "    sample_index = np.sort(sample_index)\n",
    "    \n",
    "    #//*** Build a list of values, 1 is sample, 0 is not sample\n",
    "    #//*** This will be a column to add to the input_df\n",
    "    is_sample = []\n",
    "    for x in input_df.index:\n",
    "        if x in sample_index:\n",
    "            is_sample.append(1)\n",
    "        else:\n",
    "            is_sample.append(0)\n",
    "    \n",
    "    #//*** Add is_sample column\n",
    "    input_df = input_df.assign( is_sample = is_sample)\n",
    "    \n",
    "    # //*** get sample and remainder dataframes based on is_sample attribute\n",
    "    # //*** Get the sample data frame and the remainder dataframe\n",
    "    sample_df = input_df[input_df ['is_sample'] == 1]\n",
    "    remainder_df = input_df[input_df ['is_sample'] == 0 ]\n",
    "    \n",
    "    # //**** Remove is_Sample Parameter\n",
    "    del sample_df['is_sample']\n",
    "    del remainder_df['is_sample']\n",
    "    \n",
    "    #print(len(sample_index))\n",
    "    #print(len(sample_df))\n",
    "\n",
    "    \n",
    "    if is_series == True:\n",
    "        sample_df = pd.Series(index= sample_df.index, data= sample_df.iloc[:,0])\n",
    "        remainder_df = pd.Series(index= remainder_df.index, data= remainder_df.iloc[:,0])\n",
    "    return sample_df, remainder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_stat(input_ts_type, data1, data2):\n",
    "\n",
    "    if input_ts_type ==  'mean_diff':\n",
    "        return abs( np.mean(data1) - np.mean(data2) )    \n",
    "\n",
    "    return \"\"\n",
    "\n",
    "def hypothesis_test(input_dict):\n",
    "    \n",
    "    valid_types = [\"mean_diff\"]\n",
    "    \n",
    "    if 'type' not in input_dict.keys():\n",
    "        print(f\"hypothesis test requires a type value\")\n",
    "        return \"\"\n",
    "    \n",
    "    if input_dict['type'] not in valid_types:\n",
    "        print(\"Need a valid input type\")\n",
    "        print(f\"{valid_types}\")\n",
    "        return \"\"\n",
    "    \n",
    "    if 'data' not in input_dict.keys():\n",
    "        print(f\"Need valid data\")\n",
    "        return \"\"\n",
    "    \n",
    "    # //*** Assign the total number of tests to run.\n",
    "    # //*** Defaults to 1000\n",
    "    if 'count' in input_dict.keys():\n",
    "        max_test_count = input_dict['count']\n",
    "    else:\n",
    "        max_test_count = 1000\n",
    "    \n",
    "    test_statistic = -1\n",
    "    \n",
    "\n",
    "    # //*** Convert data to Lists\n",
    "    data1 = input_dict['data'][0]\n",
    "    data2 = input_dict['data'][1]\n",
    "\n",
    "    # //*** Sample a random subset of data\n",
    "    # //*** Defaults to all data\n",
    "    if 'sample' in input_dict.keys():\n",
    "        # //*** Get random sample and convert to list\n",
    "        data1 = getSample_from_series(data1,input_dict['sample'])[0]\n",
    "        data2 = getSample_from_series(data2,input_dict['sample'])[0]\n",
    "        \n",
    "        #print(f\"Sample Lengths: {len(data1)} {len(data2)}\")\n",
    "    \n",
    "    data1 = list(data1)\n",
    "    data2 = list(data2)\n",
    "    \n",
    "    n = len(data1)\n",
    "\n",
    "\n",
    "    \n",
    "    # //*** Concatinate the lists\n",
    "    combined_data = np.hstack( (data1,data2) )\n",
    "    \n",
    "    #print(f\"Combined: {combined_data}\")\n",
    "    \n",
    "    # //*** get the test statistic. Function performs calculation based on type\n",
    "    # //*** Assume data has been properly validated at this point.\n",
    "    test_statistic = get_test_stat(input_dict['type'],data1,data2)\n",
    "    \n",
    "    #print(f\"Test Statistic: {test_statistic}\")\n",
    "    \n",
    "    null_count = 0\n",
    "    # //*** Build random permutations\n",
    "    for loop_counter in range(max_test_count):\n",
    "        \n",
    "        # //*** randomly shuffle the combined data\n",
    "        np.random.shuffle(combined_data)\n",
    "        \n",
    "        \n",
    "        # //*** Split shuffled data evenly\n",
    "        data1,data2 = combined_data[0:n],combined_data[n+1:]\n",
    "        \n",
    "        loop_test_statistic = get_test_stat(input_dict['type'],data1,data2)\n",
    "        \n",
    "        #print(f\"{test_statistic < loop_test_statistic} {test_statistic} {loop_test_statistic}\")\n",
    "        \n",
    "        # //*** If loop test statistic greater than test statistic. Then add to null count\n",
    "        if loop_test_statistic > test_statistic:\n",
    "            null_count = null_count + 1\n",
    "        \n",
    "    \n",
    "    #print(f\"Null Count: { null_count} / {max_test_count} \")\n",
    "    #print(f\"p-value {null_count / max_test_count }\")\n",
    "    return (null_count / max_test_count)\n",
    "\n",
    "#sample_df,remainder_df = getSample_from_series(total_weight,.1)\n",
    "\n",
    "#total_weight['totalwgt_lb']\n",
    "#total_weight['agepreg']\n",
    "\n",
    "#Permutation Test\n",
    "#Difference in standard deviation\n",
    "#print(np.std( total_weight['totalwgt_lb']))\n",
    "#print(np.std( total_weight['agepreg']))\n",
    "#abs(np.std( total_weight['totalwgt_lb']) - np.std( total_weight['agepreg']))\n",
    "\n",
    "#get_p_scores(total_weight['totalwgt_lb'])\n",
    "\n",
    "#print(f\"{scipy.stats.pearsonr(total_weight['totalwgt_lb'],total_weight['agepreg'])}\")\n",
    "#correlation Testing\n",
    "#Testing Proportions\n",
    "#Chi Squared test\n",
    "\n",
    "#Difference of Means Permutation test\n",
    "# Generate a test statistic for reference.\n",
    "# This is the difference of the means\n",
    "# test statistic or t-value is the abs(difference of means)\n",
    "# combine both data sets.\n",
    "# 1000 thousand times:\n",
    "#      Randomly split combined data in half.\n",
    "#      Find the difference of the means for the random samples, for a random sample test statistic\n",
    "#      count the random test statistics that are greater than the base line test statistic\n",
    "# The P-value is the count / total tests run (1000)\n",
    "# The P-value represents the chance of the outcome occuring randomly.\n",
    "# Reference: https://www.ohbmbrainmappingblog.com/blog/a-brief-overview-of-permutation-testing-with-examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Baseline (all data) p-val: 0.07511149297508268\n",
      "=======================================================\n",
      "Sample size 5.0%: p-val(mean) 0.5074 [ min: 0.001 max: 1.0 range: 0.999 ]\n",
      "================================================================================================\n",
      "Sample size 10.0%: p-val(mean) 0.4429 [ min: 0.003 max: 1.0 range: 0.997 ]\n",
      "================================================================================================\n",
      "Sample size 20.0%: p-val(mean) 0.4618 [ min: 0.006 max: 0.971 range: 0.965 ]\n",
      "================================================================================================\n",
      "Sample size 50.0%: p-val(mean) 0.3603 [ min: 0.005 max: 0.929 range: 0.924 ]\n",
      "================================================================================================\n",
      "Sample size 75.0%: p-val(mean) 0.2941 [ min: 0.012 max: 0.903 range: 0.891 ]\n",
      "================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# //*** Get the birthweight Series data from the preg dataframe\n",
    "preg = preg.dropna(subset=['totalwgt_lb','agepreg','birthord'])\n",
    "\n",
    "firsts_df = preg[preg.birthord == 1]\n",
    "others_df = preg[preg.birthord != 1]\n",
    "\n",
    "first_preglen = firsts_df['prglngth']\n",
    "other_preglen = others_df['prglngth']\n",
    "\n",
    "baseline_test_statistic = get_test_stat('mean_diff',first_preglen,other_preglen)\n",
    "print(f\"=======================================================\")\n",
    "print(f\"Baseline (all data) p-val: {baseline_test_statistic}\")\n",
    "print(f\"=======================================================\")\n",
    "\n",
    "for x in [.05,.1,.2,.5,.75]:\n",
    "#for x in [.05]:\n",
    "    pvals = [ hypothesis_test({ 'type':'mean_diff','data':(first_preglen,other_preglen),'sample':x }) for i in range(50) ]\n",
    "    pvals = np.array(pvals)\n",
    "    pval_mean, pval_min, pval_max, pval_range = np.mean(pvals),pvals.min(),pvals.max(),pvals.max()-pvals.min()\n",
    "    #print(f\"=====================\")\n",
    "    #print(f\"p-values from 100 tests of sampling data at a sample size of {x}\")\n",
    "    #print(f\"================================================================================================\")\n",
    "    print(f\"Sample size {round(x*100,2)}%: p-val(mean) {round(pval_mean,4)} [ min: {pval_min} max: {pval_max} range: {round(pval_range,4)} ]\")\n",
    "    print(f\"================================================================================================\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Chapter 10, Exercise 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
