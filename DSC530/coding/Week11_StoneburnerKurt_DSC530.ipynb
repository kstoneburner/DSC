{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 530 - Week 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanData(resp):\n",
    "    \"\"\"Cleans respondent data.\n",
    "\n",
    "    resp: DataFrame\n",
    "    \"\"\"\n",
    "    resp.cmdivorcx.replace([9998, 9999], np.nan, inplace=True)\n",
    "\n",
    "    resp['notdivorced'] = resp.cmdivorcx.isnull().astype(int)\n",
    "    resp['duration'] = (resp.cmdivorcx - resp.cmmarrhx) / 12.0\n",
    "    resp['durationsofar'] = (resp.cmintvw - resp.cmmarrhx) / 12.0\n",
    "\n",
    "    month0 = pd.to_datetime('1899-12-15')\n",
    "    dates = [month0 + pd.DateOffset(months=cm) \n",
    "             for cm in resp.cmbirth]\n",
    "    resp['decade'] = (pd.DatetimeIndex(dates).year - 1900) // 10\n",
    "    \n",
    "    resp.cmmarrhx.replace([9997, 9998, 9999], np.nan, inplace=True)\n",
    "    resp['agemarry'] = (resp.cmmarrhx - resp.cmbirth) / 12.0\n",
    "    resp['age'] = (resp.cmintvw - resp.cmbirth) / 12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*****************************************\n",
    "# //*** Build a probability mass function\n",
    "# //*****************************************\n",
    "# //*** Returns Series as a PMF\n",
    "# //*****************************************\n",
    "def build_pmf(input_series):\n",
    "    output_series = input_series.copy()\n",
    "    total_values = input_series.sum()\n",
    "    for value,freq in output_series.items():\n",
    "        #print(f\"{value} {freq} {total_values} {freq/total_values}\")\n",
    "        output_series.loc[value] = freq/total_values\n",
    "    return output_series\n",
    "\n",
    "# //*** Build a Cumulative Distribution Function from a Probability Mass Function\n",
    "# //*** Returns a Series\n",
    "def build_cdf(input_series):\n",
    "    # //*** If input is not panda or pd series, try to convert it\n",
    "    if not isinstance(input_series,pd.core.series.Series):\n",
    "        input_series = pd.Series(input_series)\n",
    "        \n",
    "    # //*** If input is np.Array\n",
    "    output_series = input_series.copy()\n",
    "    cumulative_value = 0\n",
    "    for value,freq in output_series.items():\n",
    "        #print(f\"{value} {freq} {cumulative_value} {freq + cumulative_value}\")\n",
    "        cumulative_value = freq + cumulative_value\n",
    "        output_series.loc[value] = cumulative_value\n",
    "    return output_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //****************************************************************************************\n",
    "# //*** Set Working Directory to thinkstats folder.\n",
    "# //*** This pseudo-relative path call should work on all Stoneburner localized projects. \n",
    "# //****************************************************************************************\n",
    "\n",
    "import os\n",
    "import sys\n",
    "workingPath = os.getcwd().replace(\"coding\", \"ThinkStats2\\\\code\")\n",
    "sys.path.insert(1, workingPath)\n",
    "os.chdir(workingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Imports and Load Data\n",
    "import nsfg\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "import first\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "resp6 = nsfg.ReadFemResp(dct_file='2002FemResp.dct',dat_file='2002FemResp.dat.gz')\n",
    "resp7 = nsfg.ReadFemResp(dct_file='2006_2010_FemRespSetup.dct',dat_file='2006_2010_FemResp.dat.gz')\n",
    "\n",
    "CleanData(resp6)\n",
    "\n",
    "CleanData(resp7)\n",
    "\n",
    "#//*** Combine 2002 and 2010 datasets\n",
    "resp = pd.concat([resp6,resp7], sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**    In NSFG Cycles 6 and 7, the variable `cmdivorcx` contains the date of divorce for the respondentâ€™s first marriage, if applicable, encoded in century-months.\n",
    "\n",
    "Compute the duration of marriages that have ended in divorce, and the duration, so far, of marriages that are ongoing. Estimate the hazard and survival curve for the duration of marriage.\n",
    "\n",
    "Use resampling to take into account sampling weights, and plot data from several resamples to visualize sampling error.\n",
    "\n",
    "Consider dividing the respondents into groups by decade of birth, and possibly by age at first marriage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#resp['notdivorced'] = resp.cmdivorcx.isnull().astype(int)\n",
    "#resp['duration'] = (resp.cmdivorcx - resp.cmmarrhx) / 12.0\n",
    "#resp['durationsofar'] = (resp.cmintvw - resp.cmmarrhx) / 12.0\n",
    "\n",
    "#//*** There are a number of coding errors with durationsofar. A few marriages and divorces are listed \n",
    "#//*** are negative lengths. Drop these rows\n",
    "resp.drop(index=resp[ resp['durationsofar'] <= 0 ].index, inplace=True)\n",
    "resp.drop(index=resp[ resp['duration'] <= 0 ].index, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "#//*** Not divorced attribute generate NaN for duration of marriage. \n",
    "#//*** Replace the NaN with durationsofar. This generates a length for all marriages\n",
    "\n",
    "resp['duration'].fillna(resp['durationsofar'], inplace=True)\n",
    "\n",
    "#//*** Generate histogram of durations. Rounded Continuous values to tenths for better value_counting / binning\n",
    "#duration_hist = round(resp[resp.evrmarry==1]['duration'],1).value_counts().sort_index()\n",
    "\n",
    "#//*** Build CDF from PMF\n",
    "#duration_cdf = build_cdf( build_pmf(duration_hist) )\n",
    "\n",
    "#//*** Build the Compimentary Survival Values\n",
    "#duration_survival = 1 - duration_cdf\n",
    "\n",
    "#for key,value in duration_survival.items():\n",
    "#    print(f\"{key} : {value}\")\n",
    "    \n",
    "#hazard_all_subjects = build_hazard_function(duration_survival)\n",
    "\n",
    "#print(hazard_all_subjects)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build hazard function from a cdf\n",
    "#//*** Hazard Function: (1-CDF(x)) - (1-CDF(x+1)) / (1-CDF(x))\n",
    "#//*** Difference between a value and the next value (ie the difference in two values) divided by the first value\n",
    "#//*** This is a percentage of difference between sequential survivor function (1-CDF[x]) values\n",
    "#//**** Returns a dictionary of hazard values\n",
    "def build_hazard_function(sf):\n",
    "    #//*** Convert cdf to survival function\n",
    "    #sf = 1 - pd.Series(input_cdf)\n",
    "    \n",
    "    #//*** output dictionary\n",
    "    out_dict= {}\n",
    "    \n",
    "    for index,value in enumerate(sf):\n",
    "        #//*** Skip the last value since it generates an out of array error.\n",
    "        #//*** Had troubles parsing a series len(-1) so did it this way\n",
    "        if index < len(sf)-1:\n",
    "            if sf.iloc[index] != 0:\n",
    "                #//*** Value = Hazard Value\n",
    "                out_dict[value] = ( sf.iloc[index] - sf.iloc[index+1] / sf.iloc[index] )\n",
    "            else:\n",
    "                out_dict[value] = 0\n",
    "    return out_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build a Kaplan Meier Survival Curve to estimate a survival function\n",
    "#//*** For an estimated/predicted lifetime\n",
    "\n",
    "def build_kaplan_meier_survival_curve(input_complete, input_ongoing):\n",
    "    #//*** Build Histogram Dictionary of Complete and ongoing\n",
    "    #//*** No reason to import a Counter Library for Basic stuff\n",
    "    #//*** Usual histogram method of value_counts and sort_index, combined with a for items loop\n",
    "    #//*** to convert to a dictionary\n",
    "    #from collections import Counter    \n",
    "    #hist_complete_counter = Counter(input_complete)\n",
    "    #hist_ongoing_counter =  Counter(input_ongoing)\n",
    "    hist_combined_list = []    \n",
    "\n",
    "    hist_complete = {}\n",
    "    for index, value in input_complete.value_counts().sort_index().items():\n",
    "        #//*** Add Unique value to the combined list\n",
    "        if index not in hist_complete.keys():\n",
    "            hist_combined_list.append(index)\n",
    "\n",
    "        #//*** Add to Dictionary\n",
    "        hist_complete[index] = value\n",
    "\n",
    "    hist_ongoing = {}\n",
    "    for index, value in input_ongoing.value_counts().sort_index().items():\n",
    "        #//*** Add Unique value to the combined list\n",
    "        if index not in hist_complete.keys():\n",
    "            hist_combined_list.append(index)\n",
    "\n",
    "        #//*** Add to Dictionary\n",
    "        hist_ongoing[index] = value\n",
    "\n",
    "    #hist_combined_list = list(hist_complete_counter | hist_ongoing_counter)\n",
    "    hist_combined_list.sort()\n",
    "    at_risk = len(input_complete) + len(input_ongoing)\n",
    "    \n",
    "\n",
    "    #//*** Create an empty Survival curve using the hist_comibined_list as a key\n",
    "    #//*** All values will be represented in the Survival Curve.\n",
    "    #//*** If something is missed it will be represented as a NaN\n",
    "    survival_curve = pd.Series(index=hist_combined_list,dtype='float')\n",
    "\n",
    "    #//*** Go through each value in the ongoing and complete dictionaries\n",
    "    #//*** Get the count of each, or zero if not found\n",
    "    for x in hist_combined_list:\n",
    "        \n",
    "\n",
    "        #ended = hist_complete_counter[x]\n",
    "        #censored = hist_ongoing_counter[x]\n",
    "        \n",
    "        if x in hist_complete.keys():\n",
    "            ended = hist_complete[x]\n",
    "        else:\n",
    "            ended = 0\n",
    "\n",
    "        if x in hist_ongoing.keys():\n",
    "            censored = hist_ongoing[x]\n",
    "        else:\n",
    "            censored = 0\n",
    "\n",
    "        #//*** Calculate the percentage of ended vs the remaining at risk\n",
    "        survival_curve[x] = ended / at_risk\n",
    "\n",
    "        \n",
    "        #//*** Reduced the at_risk total by the totals found\n",
    "        at_risk -= ended + censored\n",
    "\n",
    "    return survival_curve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EstimateHazardFunction(complete, ongoing, label='', verbose=False):\n",
    "    from collections import Counter    \n",
    "    \"\"\"Estimates the hazard function by Kaplan-Meier.\n",
    "\n",
    "    http://en.wikipedia.org/wiki/Kaplan%E2%80%93Meier_estimator\n",
    "\n",
    "    complete: list of complete lifetimes\n",
    "    ongoing: list of ongoing lifetimes\n",
    "    label: string\n",
    "    verbose: whether to display intermediate results\n",
    "    \"\"\"\n",
    "    if np.sum(np.isnan(complete)):\n",
    "        raise ValueError(\"complete contains NaNs\")\n",
    "    if np.sum(np.isnan(ongoing)):\n",
    "        raise ValueError(\"ongoing contains NaNs\")\n",
    "    \n",
    "    hist_complete = Counter(complete)\n",
    "    hist_ongoing = Counter(ongoing)\n",
    "\n",
    "    ts = list(hist_complete | hist_ongoing)\n",
    "    ts.sort()\n",
    "\n",
    "    at_risk = len(complete) + len(ongoing)\n",
    "    \n",
    "\n",
    "    lams = pd.Series(index=ts,dtype='float')\n",
    "    for t in ts:\n",
    "        ended = hist_complete[t]\n",
    "        censored = hist_ongoing[t]\n",
    "\n",
    "        lams[t] = ended / at_risk\n",
    "        if verbose:\n",
    "            print(t, at_risk, ended, censored, lams[t])\n",
    "\n",
    "        at_risk -= ended + censored\n",
    "        \n",
    "\n",
    "\n",
    "    return lams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7593503947287112\n",
      "1.7593503947287112\n"
     ]
    }
   ],
   "source": [
    "#//*** Estimate the hazard function by Kaplan-Meier\n",
    "#//*** Generates Risk for each specific Value. \n",
    "#//**** Round Ages \n",
    "complete = round(resp[resp.evrmarry==1]['agemarry'].dropna(),1)\n",
    "ongoing = round(resp[resp.evrmarry==0]['age'],1)\n",
    "\n",
    "\n",
    "survival_curve = build_kaplan_meier_survival_curve(complete,ongoing)\n",
    "book_curve = EstimateHazardFunction(complete,ongoing)\n",
    "print(f\"{survival_curve.sum()}\")\n",
    "print(f\"{book_curve.sum()}\")\n",
    "#kaplan_meier_hazard_function = build_hazard_function(survival_curve)\n",
    "\n",
    "#print(kaplan_meier_hazard_function)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Chapter X, Exercise X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Chapter X, Exercise X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Chapter X, Exercise X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
