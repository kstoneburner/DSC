{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 530 - Week 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "####//*** Reused Functions from previous exercises\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "# //*****************************************\n",
    "# //*** Build a probability mass function\n",
    "# //*****************************************\n",
    "# //*** Returns Series as a PMF\n",
    "# //*****************************************\n",
    "def build_pmf(input_series):\n",
    "    output_series = input_series.copy()\n",
    "    total_values = input_series.sum()\n",
    "    for value,freq in output_series.items():\n",
    "        #print(f\"{value} {freq} {total_values} {freq/total_values}\")\n",
    "        output_series.loc[value] = freq/total_values\n",
    "    return output_series\n",
    "\n",
    "# //*** Build a Cumulative Distribution Function from a Probability Mass Function\n",
    "# //*** Returns a Series\n",
    "def build_cdf(input_series):\n",
    "    # //*** If input is not panda or pd series, try to convert it\n",
    "    if not isinstance(input_series,pd.core.series.Series):\n",
    "        input_series = pd.Series(input_series)\n",
    "        \n",
    "    # //*** If input is np.Array\n",
    "    output_series = input_series.copy()\n",
    "    cumulative_value = 0\n",
    "    for value,freq in output_series.items():\n",
    "        #print(f\"{value} {freq} {cumulative_value} {freq + cumulative_value}\")\n",
    "        cumulative_value = freq + cumulative_value\n",
    "        output_series.loc[value] = cumulative_value\n",
    "    return output_series\n",
    "\n",
    "# //*** Retrieve a percentile value from a CDF.\n",
    "# //*** Returns index value closest to input parameter percentile.\n",
    "def get_cdf_percentile(input_cdf,percentile):\n",
    "    #print(f\"{input_cdf}\")\n",
    "    #//*** Initialize output to first value\n",
    "    output = input_cdf.index[0]\n",
    "    \n",
    "    #//*** Loop through all items till the value exceeds the percentile\n",
    "    #//*** Return value from last loop\n",
    "    for index,value in input_cdf.items():\n",
    "        \n",
    "        if value > percentile:\n",
    "            return output\n",
    "        else:\n",
    "            output = index\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "####//*** END Functions from previous exercises\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "####//*** Thinkstats function\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "def CleanData(resp):\n",
    "    \"\"\"Cleans respondent data.\n",
    "\n",
    "    resp: DataFrame\n",
    "    \"\"\"\n",
    "    resp.cmdivorcx.replace([9998, 9999], np.nan, inplace=True)\n",
    "\n",
    "    resp['notdivorced'] = resp.cmdivorcx.isnull().astype(int)\n",
    "    resp['duration'] = (resp.cmdivorcx - resp.cmmarrhx) / 12.0\n",
    "    resp['durationsofar'] = (resp.cmintvw - resp.cmmarrhx) / 12.0\n",
    "\n",
    "    month0 = pd.to_datetime('1899-12-15')\n",
    "    dates = [month0 + pd.DateOffset(months=cm) \n",
    "             for cm in resp.cmbirth]\n",
    "    resp['decade'] = (pd.DatetimeIndex(dates).year - 1900) // 10\n",
    "    \n",
    "    resp.cmmarrhx.replace([9997, 9998, 9999], np.nan, inplace=True)\n",
    "    resp['agemarry'] = (resp.cmmarrhx - resp.cmbirth) / 12.0\n",
    "    resp['age'] = (resp.cmintvw - resp.cmbirth) / 12.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "####//*** New Functions for this week\n",
    "####################################################\n",
    "####################################################\n",
    "####################################################\n",
    "# def build_hazard_function(sf):\n",
    "#-------- Takes a survival function and returns a hazard Function\n",
    "###################################################################\n",
    "# build_kaplan_meier_hazard_curve(input_complete, input_ongoing):\n",
    "#--------- Generates an estimates the longevity of a \n",
    "#--------- population and returns a hazard function \n",
    "###################################################################\n",
    "# build_survival_from_hazard(input_hazard_series):\n",
    "#--------- Builds Survival Function from a hazard function \n",
    "###################################################################\n",
    "#//*** Build hazard function from a cdf\n",
    "#//*** Hazard Function: (1-CDF(x)) - (1-CDF(x+1)) / (1-CDF(x))\n",
    "#//*** Difference between a value and the next value (ie the difference in two values) divided by the first value\n",
    "#//*** This is a percentage of difference between sequential survivor function (1-CDF[x]) values\n",
    "#//**** Returns a dictionary of hazard values\n",
    "def build_hazard_function(sf):\n",
    "    #//*** Convert cdf to survival function\n",
    "    #sf = 1 - pd.Series(input_cdf)\n",
    "    \n",
    "    #//*** output dictionary\n",
    "    out_dict= {}\n",
    "    \n",
    "    for index,value in enumerate(sf):\n",
    "        #//*** Skip the last value since it generates an out of array error.\n",
    "        #//*** Had troubles parsing a series len(-1) so did it this way\n",
    "        if index < len(sf)-1:\n",
    "            if sf.iloc[index] != 0:\n",
    "                #//*** Value = Hazard Value\n",
    "                out_dict[value] = ( sf.iloc[index] - sf.iloc[index+1] / sf.iloc[index] )\n",
    "            else:\n",
    "                out_dict[value] = 0\n",
    "    return out_dict\n",
    "\n",
    "#//*** Build a Kaplan Meier Survival Curve to estimate a survival function\n",
    "#//*** For an estimated/predicted lifetime\n",
    "\n",
    "def build_kaplan_meier_hazard_curve(input_complete, input_ongoing):\n",
    "    #//*** Build Histogram Dictionary of Complete and ongoing\n",
    "    #//*** No reason to import a Counter Library for Basic stuff\n",
    "    #//*** Usual histogram method of value_counts and sort_index, combined with a for items loop\n",
    "    #//*** to convert to a dictionary\n",
    "    #from collections import Counter    \n",
    "    #hist_complete_counter = Counter(input_complete)\n",
    "    #hist_ongoing_counter =  Counter(input_ongoing)\n",
    "    hist_combined_list = []    \n",
    "\n",
    "    hist_complete = {}\n",
    "    for index, value in input_complete.value_counts().sort_index().items():\n",
    "        #//*** Add Unique value to the combined list\n",
    "        if index not in hist_complete.keys():\n",
    "            hist_combined_list.append(index)\n",
    "\n",
    "        #//*** Add to Dictionary\n",
    "        hist_complete[index] = value\n",
    "\n",
    "    hist_ongoing = {}\n",
    "    for index, value in input_ongoing.value_counts().sort_index().items():\n",
    "        #//*** Add Unique value to the combined list\n",
    "        if index not in hist_complete.keys():\n",
    "            hist_combined_list.append(index)\n",
    "\n",
    "        #//*** Add to Dictionary\n",
    "        hist_ongoing[index] = value\n",
    "\n",
    "    #hist_combined_list = list(hist_complete_counter | hist_ongoing_counter)\n",
    "    hist_combined_list.sort()\n",
    "    \n",
    "    at_risk = len(input_complete) + len(input_ongoing)\n",
    "    \n",
    "\n",
    "    #//*** Create an empty Survival curve using the hist_comibined_list as a key\n",
    "    #//*** All values will be represented in the Survival Curve.\n",
    "    #//*** If something is missed it will be represented as a NaN\n",
    "    survival_curve = pd.Series(index=hist_combined_list,dtype='float')\n",
    "\n",
    "    #//*** Go through each value in the ongoing and complete dictionaries\n",
    "    #//*** Get the count of each, or zero if not found\n",
    "    for x in hist_combined_list:\n",
    "        \n",
    "\n",
    "        #ended = hist_complete_counter[x]\n",
    "        #censored = hist_ongoing_counter[x]\n",
    "        \n",
    "        if x in hist_complete.keys():\n",
    "            ended = hist_complete[x]\n",
    "        else:\n",
    "            ended = 0\n",
    "\n",
    "        if x in hist_ongoing.keys():\n",
    "            censored = hist_ongoing[x]\n",
    "        else:\n",
    "            censored = 0\n",
    "\n",
    "        #//*** Calculate the percentage of ended vs the remaining at risk\n",
    "        survival_curve[x] = ended / at_risk\n",
    "\n",
    "        \n",
    "        #//*** Reduced the at_risk total by the totals found\n",
    "        at_risk -= ended + censored\n",
    "\n",
    "    return survival_curve\n",
    "\n",
    "def build_survival_from_hazard(input_hazard_series):\n",
    "    #//****************************************************\n",
    "    #//**** Convert Hazard Function to Survival Function\n",
    "    #//****************************************************\n",
    "    #ts = input_hazard_series.index\n",
    "    #//*** cumprod - cumulative product. Essentially builds a CDF from hazard curve\n",
    "    #//**** (1-hazard_curve).cumprod() Survival Function (reciprocal CDF) of hazard curve\n",
    "    sf = (1 - input_hazard_series).cumprod()\n",
    "    #//****************************************************\n",
    "    \n",
    "    return (pd.Series(index=input_hazard_series.index, data=sf))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //****************************************************************************************\n",
    "# //*** Set Working Directory to thinkstats folder.\n",
    "# //*** This pseudo-relative path call should work on all Stoneburner localized projects. \n",
    "# //****************************************************************************************\n",
    "\n",
    "import os\n",
    "import sys\n",
    "workingPath = os.getcwd().replace(\"coding\", \"ThinkStats2\\\\code\")\n",
    "sys.path.insert(1, workingPath)\n",
    "os.chdir(workingPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Imports and Load Data\n",
    "import nsfg\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "import first\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**    In NSFG Cycles 6 and 7, the variable `cmdivorcx` contains the date of divorce for the respondentâ€™s first marriage, if applicable, encoded in century-months.\n",
    "\n",
    "Compute the duration of marriages that have ended in divorce, and the duration, so far, of marriages that are ongoing. Estimate the hazard and survival curve for the duration of marriage.\n",
    "\n",
    "Use resampling to take into account sampling weights, and plot data from several resamples to visualize sampling error.\n",
    "\n",
    "Consider dividing the respondents into groups by decade of birth, and possibly by age at first marriage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//****************************************\n",
    "#//*** Prepare, Clean and load the data\n",
    "#//****************************************\n",
    "\n",
    "#//*** Import data sets\n",
    "resp6 = nsfg.ReadFemResp(dct_file='2002FemResp.dct',dat_file='2002FemResp.dat.gz')\n",
    "resp7 = nsfg.ReadFemResp(dct_file='2006_2010_FemRespSetup.dct',dat_file='2006_2010_FemResp.dat.gz')\n",
    "\n",
    "#//*** Clean Data using included Thinkstsats code\n",
    "CleanData(resp6)\n",
    "CleanData(resp7)\n",
    "\n",
    "#//*** Combine 2002 and 2010 datasets\n",
    "resp = pd.concat([resp6,resp7], sort=False)#resp['notdivorced'] = resp.cmdivorcx.isnull().astype(int)\n",
    "\n",
    "#//*** There are a number of coding errors with durationsofar. A few marriages and divorces are listed \n",
    "#//*** are negative lengths. Drop these rows\n",
    "resp.drop(index=resp[ resp['durationsofar'] <= 0 ].index, inplace=True)\n",
    "resp.drop(index=resp[ resp['duration'] <= 0 ].index, inplace=True)\n",
    "\n",
    "#//*** complete is a list of marriage lengths for those that have been married\n",
    "complete = round(resp[resp.evrmarry==1]['duration'].dropna(),1)\n",
    "\n",
    "#//*** ongoing is a list of those never married. This list is filled with nan\n",
    "ongoing =  round( resp[resp.evrmarry==0]['durationsofar'],1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp['decade'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Estimate the projected hazard curve of marriage lengths of the projected lifetimes using\n",
    "#//*** kaplan meier method. Retuns Hazard Function\n",
    "hazard_curve = build_kaplan_meier_hazard_curve(complete,ongoing)\n",
    "\n",
    "#//*** Convert Kaplan Meier Hazard Function to survival function\n",
    "sf = build_survival_from_hazard(hazard_curve)\n",
    "\n",
    "#//*** Perform weighted resampling to estimate the errors\n",
    "#//*** Convert Survival function to CDF. Use the CDF for weighted resampling of complete. \n",
    "#//*** Reference: https://www.python-course.eu/weighted_choice_and_sample.php\n",
    "sf_cdf = 1-sf\n",
    "\n",
    "import random\n",
    "\n",
    "complete_len = len(complete)\n",
    "resampled_survival_curves = []\n",
    "ci_dict = {}\n",
    "#//*** Generate 100 weighted samples\n",
    "for _ in range(100):\n",
    "    \n",
    "    #//*** Generate random percentages with the range of the CDF.\n",
    "    complete_weight = [ random.uniform(sf_cdf.min(),sf_cdf.max()) for __ in range(complete_len) ]\n",
    "    \n",
    "    #//*** Convert List of Random weights into values from the CDF.\n",
    "    complete_resample = pd.Series( data=[ get_cdf_percentile(sf_cdf,__) for __ in complete_weight ] )\n",
    "    #//*** Ongoing is empty with NaN\n",
    "    ongoing_resample = pd.Series( data=[ np.nan for __ in range(len(ongoing)) ] )\n",
    "    \n",
    "    #//*** Build Estimated Lifetime Hazard Function from resampled/random data\n",
    "    resample_hazard_curve = build_kaplan_meier_hazard_curve(complete_resample,ongoing_resample)\n",
    "    \n",
    "    #//*** Convert Hazard Function to Survival Function\n",
    "    re_sample_ts = resample_hazard_curve.index\n",
    "    re_sample_ss = (1 - resample_hazard_curve).cumprod()\n",
    "    loop_series = pd.Series(index=re_sample_ts, data=re_sample_ss)\n",
    "    resampled_survival_curves.append(loop_series)\n",
    "    \n",
    "    #//*** Collect Values for each index over all resamples\n",
    "    for x in loop_series.index:\n",
    "        if x not in ci_dict.keys():\n",
    "            ci_dict[x] = [loop_series[x]]\n",
    "        else:\n",
    "            ci_dict[x].append(loop_series[x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Get resampled Hi/Low (error) for each value. This represents the resampled error for each value\n",
    "min_vals = []\n",
    "max_vals = []\n",
    "for x in ts:\n",
    "    if x in ci_dict.keys():\n",
    "        min_vals.append(pd.Series(ci_dict[x]).min() )\n",
    "        max_vals.append(pd.Series(ci_dict[x]).max() )\n",
    "\n",
    "#//*** Missing one value, add it in from the main data\n",
    "min_vals.append(ss.iloc[-1])\n",
    "max_vals.append(ss.iloc[-1])\n",
    "\n",
    "plt.plot(ts,ss,1,\"r\")\n",
    "#plt.plot(ts, min_vals, ts, max_vals, color='black')\n",
    "plt.fill_between(ts, min_vals, max_vals,color='gray')\n",
    "plt.plot(ts,ss,1,\"r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ts,ss,1,\"b\")\n",
    "plt.plot(ts, 1-ss,1,\"r\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(hazard_curve.index,hazard_curve,1,\"b\")\n",
    "plt.ylim(hazard_curve.min(),hazard_curve.max())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Chapter X, Exercise X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Chapter X, Exercise X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Chapter X, Exercise X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
