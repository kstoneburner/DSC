{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we measure Burnout in salaried Staff? What is the ratio of break time to billable time?\n",
    "Are Employees taking enough time off?\n",
    "\n",
    "Does more time off improve Productivity in salaried employees?\n",
    "\n",
    "Compare Time off hours between Salary and non-salary staff\n",
    "\n",
    "How does billable hours for customers, vs non-billable hours for customers breakdown?\n",
    "\n",
    "What are the types overhead?\n",
    "\n",
    "How do hours worked vary by day of the week?\n",
    "\n",
    "Are there days of the week where employees are more productive?\n",
    "\n",
    "What is the distribution of job types? Can it be represented with a statistical model?\n",
    "\n",
    "Examine the employee relationship with activities? Can we determine which activities employees are efficient at? and which activities an employee is more inefficient at?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Define Global Values\n",
    "g = {\n",
    "    'obfuscate': {},\n",
    "    'combined_df_filename' : 'combined.dat',\n",
    "    'days_of_week' : [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\"],\n",
    "    'person' : {}\n",
    "}\n",
    "#\"Saturday\",\"Sunday\"\n",
    "\n",
    "# //*** Load keys.json\n",
    "rawInput = \"\"\n",
    "with open('keys.json', 'r') as readfile:\n",
    "    for f in readfile.readlines():\n",
    "        rawInput = rawInput + f + \"\\n\"\n",
    "readfile.close()\n",
    "\n",
    "g['obfuscate'] = json.loads(rawInput)\n",
    "\n",
    "\n",
    "\n",
    "# //*******************************************\n",
    "# //*** Load Combined df - Master Data Frame\n",
    "# //*******************************************\n",
    "combined_df = pd.read_csv(g['combined_df_filename'])\n",
    "\n",
    "# //*** Delete First Column, I believe is a CSV artifact\n",
    "del combined_df[ combined_df.columns[0] ]\n",
    "\n",
    "# //**** Convert Local Date to Date Time Format\n",
    "# //**** Strip out exact time and keep date\n",
    "combined_df['local_date'] = combined_df['local_date'].str.replace(\" 00:00:00\",\"\")\n",
    "\n",
    "# //*** Run conversion once, ie check for timestamp property in first value\n",
    "# //*** Just a wee bit of fail safely\n",
    "if \"Timestamp\" not in str(type(combined_df['local_date'][0])):\n",
    "    # //**** Convert String to date\n",
    "    dateCol = pd.to_datetime(combined_df['local_date'], format='%Y-%m-%d')\n",
    "    \n",
    "    combined_df['local_date'] = dateCol\n",
    "    \n",
    "    \n",
    "    \n",
    "    # //*** Build Days of the Week Column as an Integer\n",
    "    combined_df['day_int'] = combined_df['local_date'].dt.dayofweek\n",
    "\n",
    "    # //*** Build Day Column as a String [ Monday ~ Sunday ]\n",
    "    # //*** Start With am empty list and convert 'day_int' column into a list of strings\n",
    "\n",
    "    day_list = []\n",
    "\n",
    "    date_dict = {0:\"Monday\",1:\"Tuesday\",2:\"Wednesday\",3:\"Thursday\",4:\"Friday\",5:\"Saturday\",6:\"Sunday\"}\n",
    "\n",
    "    for x in range(0,len(combined_df['day_int'])):\n",
    "        day_list.append(date_dict[combined_df['day_int'][x]])\n",
    "\n",
    "    # //*** Convert day_list to Series and add as 'day column'\n",
    "    combined_df['day'] = pd.Series(day_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Variables:#\n",
    "\n",
    "**Date**\n",
    "\n",
    "**hours**\n",
    "\n",
    "**Jobcode_1:** (166 unique entries) Indicates the billable customer which could be an external company, internal hours for the company, or time off\n",
    "\n",
    "**Jobcode_2:** (474 unique entries)Specific task Jobcodes. Larger jobs will have multiple entries\n",
    "\n",
    "**Activity:** (67 unique entries) Additional Task coding information\n",
    "\n",
    "**Billable:** Separately billable status (unlikely this is useful information)\n",
    "\n",
    "**Class:** (9 unique entries) Job Department Code. Reflects the different work areas of the company\n",
    "\n",
    "**Service Item:** (18 unique entries) The Type of service that is provided to the client. Some is consultuting, some is title 24. Mostly used for billing and accounting. Usefulness is suspect.\n",
    "\n",
    "**Activities**: Indicates progress in a particular activity. \n",
    "\n",
    "**emp_name**: (12 Unique entries) employee designation (EMP_1, EMP_2, etc)\n",
    "\n",
    "**Day Int:** Day of the Week as an integer, Engineered Attribute.\n",
    "\n",
    "**Day**: Day of the week as a name (Monday, Tuesday, etc.), engineered activity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      local_date  hours                    jobcode_1  \\\n",
      "0     2019-01-01   8.00                      Holiday   \n",
      "1     2019-01-02   1.75                 Gabel Energy   \n",
      "2     2019-01-02   1.08  ALTUS Architecture + Design   \n",
      "3     2019-01-02   1.58                 Gabel Energy   \n",
      "4     2019-01-02   1.25        BDE Architecture Inc.   \n",
      "...          ...    ...                          ...   \n",
      "23285 2019-12-25   8.00                      Holiday   \n",
      "23286 2019-12-26   7.20                     Vacation   \n",
      "23287 2019-12-27   7.20                     Vacation   \n",
      "23288 2019-12-30   7.20                     Vacation   \n",
      "23289 2019-12-31   7.20                     Vacation   \n",
      "\n",
      "                                      jobcode_2  \\\n",
      "0                                           NaN   \n",
      "1                                           NaN   \n",
      "2      19009 - Munson Residence and Guest House   \n",
      "3                                           NaN   \n",
      "4      17214 Walnut Creek Transit Village Phase   \n",
      "...                                         ...   \n",
      "23285                                       NaN   \n",
      "23286                                       NaN   \n",
      "23287                                       NaN   \n",
      "23288                                       NaN   \n",
      "23289                                       NaN   \n",
      "\n",
      "                                         activity billable           class  \\\n",
      "0                                             NaN      NaN             NaN   \n",
      "1      Gabel: Project Coordination (non-billable)       No        Overhead   \n",
      "2                           Energy Model/Takeoffs       No     Residential   \n",
      "3                                     Gabel: Misc       No        Overhead   \n",
      "4                           Energy Model/Takeoffs      Yes  Nonresidential   \n",
      "...                                           ...      ...             ...   \n",
      "23285                                         NaN       No        Overhead   \n",
      "23286                                         NaN       No        Overhead   \n",
      "23287                                         NaN       No        Overhead   \n",
      "23288                                         NaN       No        Overhead   \n",
      "23289                                         NaN       No        Overhead   \n",
      "\n",
      "                      service item emp_name  salary activities  day_int  \\\n",
      "0                              NaN    EMP_1       1        NaN        1   \n",
      "1                         Overhead    EMP_1       1        NaN        2   \n",
      "2      Energy Code Compliance Work    EMP_1       1        NaN        2   \n",
      "3                         Overhead    EMP_1       1        NaN        2   \n",
      "4      Energy Code Compliance Work    EMP_1       1        NaN        2   \n",
      "...                            ...      ...     ...        ...      ...   \n",
      "23285                     Overhead   EMP_12       1        NaN        2   \n",
      "23286                     Overhead   EMP_12       1        NaN        3   \n",
      "23287                     Overhead   EMP_12       1        NaN        4   \n",
      "23288                     Overhead   EMP_12       1        NaN        0   \n",
      "23289                     Overhead   EMP_12       1        NaN        1   \n",
      "\n",
      "             day  \n",
      "0        Tuesday  \n",
      "1      Wednesday  \n",
      "2      Wednesday  \n",
      "3      Wednesday  \n",
      "4      Wednesday  \n",
      "...          ...  \n",
      "23285  Wednesday  \n",
      "23286   Thursday  \n",
      "23287     Friday  \n",
      "23288     Monday  \n",
      "23289    Tuesday  \n",
      "\n",
      "[23290 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pacific Gas & Electric Co.    1760\n",
      "BDE Architecture Inc.         1562\n",
      "Jarvis Architects              404\n",
      "HOMEOWNER                      390\n",
      "NORESCO                        346\n",
      "                              ... \n",
      "C W Swenson Inc                  1\n",
      "K. Reimer & Co                   1\n",
      "Permit Drafting Solutions        1\n",
      "Keene Builders                   1\n",
      "Bamcore                          1\n",
      "Name: jobcode_1, Length: 157, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# //********************************************************************\n",
    "# //*** Pandas Frequency from dataframe\n",
    "# //********************************************************************\n",
    "# //*** Productivity Data Frame: These Jobs make the money\n",
    "billable_df = combined_df[combined_df['jobcode_2'].str.len() > 2]\n",
    "\n",
    "\n",
    "#print(combined_df['jobcode_1'].value_counts().sort_values(ascending=False).head(10))\n",
    "#print(\"######\")\n",
    "#print(billable_df['jobcode_1'].value_counts().sort_values(ascending=False).head(10))\n",
    "#print(\"######\")\n",
    "\n",
    "# //*** get a value distribution of billable jobs\n",
    "billable_value_count = billable_df['jobcode_1'].value_counts().sort_values(ascending=False)\n",
    "print(billable_value_count)\n",
    "# //********************************************************************\n",
    "# //*** Build weighted values\n",
    "# //********************************************************************\n",
    "#print(f\"{billable_value_count}\")\n",
    "#print(f\"{jobcode1_value_count.index}\")\n",
    "\n",
    "# //*** Build a list of summed hours for each jobcode category\n",
    "# //*** Loop through each billable jobcode to get the total hours for that job \n",
    "billable_hours_distribution = {}\n",
    "for x in range(0,len(billable_value_count.index)):\n",
    "    loop_key = billable_value_count.index[x]\n",
    "    \n",
    "    # //*** get total hours for each job\n",
    "    billable_hours_distribution[loop_key] = combined_df[combined_df['jobcode_1'] == loop_key ]['hours'].sum()\n",
    "\n",
    "\n",
    "# //*************************\n",
    "# //*** Sort Billable Hours\n",
    "# //*************************\n",
    "# //*** https://www.geeksforgeeks.org/python-sort-python-dictionaries-by-key-or-value/\n",
    "# //*** Builds a sorted dictionary\n",
    "billable_hours_distribution = sorted(billable_hours_distribution.items(), key = lambda kv:(kv[1], kv[0]),reverse=True)\n",
    "jobcode1_keys = []\n",
    "jobcode1_values = []\n",
    "# //*** Pull the sorted dictionary apart\n",
    "for x in billable_hours_distribution:\n",
    "    jobcode1_keys.append(x[0])\n",
    "    jobcode1_values.append(x[1])\n",
    "\n",
    "# //*** Reassemble as an ordered pandas series\n",
    "billable_hours_distribution = pd.Series(index=jobcode1_keys, data=jobcode1_values)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Plot By Job Frequency - Top 20\n",
    "billable_value_count_top_30 = billable_value_count[0:30]\n",
    "\n",
    "# //*** Histogram with matplotlib\n",
    "plt.bar(billable_value_count_top_30.index.values, billable_value_count_top_30, 1, color='b')\n",
    "#plt.tight_layout()\n",
    "\n",
    "plt.xticks(billable_value_count_top_30.index.values, billable_value_count_top_30.index, rotation='vertical')\n",
    "#plt.title(f\"Biased Distribution\\nMean: {round(resp['numkdhh'][resp['numkdhh'] > 0].mean(),2)}\")\n",
    "plt.xlabel('Top 30 Jobecodes by Frequency')\n",
    "plt.ylabel('Item Frequency')\n",
    "plt.figure(figsize=(1,500))\n",
    "plt.show()\n",
    "\n",
    "# //*** Plot by Total Job Hours - Top 20\n",
    "billable_hours_distribution_top_20 = billable_hours_distribution[0:30]\n",
    "\n",
    "# //*** Histogram with matplotlib\n",
    "plt.bar(billable_hours_distribution_top_20.index.values, billable_hours_distribution_top_20, 1, color='b')\n",
    "#plt.tight_layout()\n",
    "\n",
    "plt.xticks(billable_hours_distribution_top_20.index.values, billable_hours_distribution_top_20.index, rotation='vertical')\n",
    "#plt.title(f\"Biased Distribution\\nMean: {round(resp['numkdhh'][resp['numkdhh'] > 0].mean(),2)}\")\n",
    "plt.xlabel('Top 30 Jobcodes by Hours')\n",
    "plt.ylabel('Jobcode Hours')\n",
    "plt.figure(figsize=(1,500))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Build \n",
    "qlist = []\n",
    "for x in range(0,len(billable_hours_distribution)):\n",
    "    qlist.append(x)\n",
    "    \n",
    "# //*** Histogram with matplotlib\n",
    "plt.bar(qlist, billable_value_count, 1, color='b')\n",
    "#plt.tight_layout()\n",
    "\n",
    "#plt.xticks(qlist, billable_value_count.index, rotation='vertical')\n",
    "#plt.title(f\"Biased Distribution\\nMean: {round(resp['numkdhh'][resp['numkdhh'] > 0].mean(),2)}\")\n",
    "plt.title(f\"Jobs by Frequency\")\n",
    "plt.xlabel('Job Frequency per each client')\n",
    "plt.ylabel('Job Frequency')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# //*** Build \n",
    "qlist = []\n",
    "for x in range(0,len(billable_hours_distribution)):\n",
    "    qlist.append(x)\n",
    "# //*** Histogram with matplotlib\n",
    "plt.bar(qlist, billable_hours_distribution, 1, color='b')\n",
    "#plt.tight_layout()\n",
    "\n",
    "#plt.xticks(jobcode1_value_count_top_20.index.values, jobcode1_value_count_top_20.index, rotation='vertical')\n",
    "plt.title(f\"Jobs by Hours\")\n",
    "plt.xlabel('Unique Clients')\n",
    "plt.ylabel('Hours per each client')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Look at Customer Hours Distribution\n",
    "print(f\"Mean Billable Hours: {billable_hours_distribution.mean()}\")\n",
    "print(f\"Median Billable Hours: {billable_hours_distribution.median()}\")\n",
    "\n",
    "companies_greater_than_billable_mean = billable_hours_distribution[ billable_hours_distribution > billable_hours_distribution.mean()]\n",
    "companies_less_than_billable_mean = billable_hours_distribution[ billable_hours_distribution < billable_hours_distribution.mean()]\n",
    "companies_greater_than_billable_median = billable_hours_distribution[ billable_hours_distribution > billable_hours_distribution.median()]\n",
    "print(f\"Number of Companies greater than the mean: {len(companies_greater_than_billable_mean)}\")\n",
    "print(f\"Percentage of hours: {companies_greater_than_billable_mean.sum() / billable_hours_distribution.sum() }\")\n",
    "print(f\"Percentage of companites: { len(companies_greater_than_billable_mean) / len(billable_hours_distribution) }\")\n",
    "\n",
    "print(f\"Number of Companies greater than the median: {len(companies_greater_than_billable_median)}\")\n",
    "print(f\"{companies_greater_than_billable_mean.sum()} {companies_less_than_billable_mean.sum()} \")\n",
    "print(billable_hours_distribution.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pmf(input_series):\n",
    "    output_series = input_series.copy()\n",
    "    total_values = input_series.sum()\n",
    "    for value,freq in output_series.items():\n",
    "        #print(f\"{value} {freq} {total_values} {freq/total_values}\")\n",
    "        output_series.loc[value] = freq/total_values\n",
    "    return output_series\n",
    "\n",
    "def getName(input_string):\n",
    "    return g['obfuscate'][input_string]['fname']\n",
    "\n",
    "# //*** Container class for storing employee values\n",
    "class Person():\n",
    "    \n",
    "    def add_breaks(self,input_key,input_value):\n",
    "        self.breaks[input_key] = input_value\n",
    "    \n",
    "    def __init__(self,input_hname,input_fname):\n",
    "        self.totals = {}\n",
    "        self.breaks = {}\n",
    "        self.fname = input_fname # //**** Actual First Name\n",
    "        self.hname = input_hname # //**** Hidden Name ie EMP_?\n",
    "    def __str__(self):\n",
    "        out = \"\"\n",
    "        out += f\"{self.hname} : {self.fname}\\n\"\n",
    "        out += \"Totals:\\n\"\n",
    "        for key,value in self.totals.items():\n",
    "            # //*** Round Float values\n",
    "            if \"float64\" in str(type(value)):\n",
    "                out += f\"\\t{key} - {round(value,2)} \\n\"\n",
    "            elif \"dict\" in str(type(value)):\n",
    "                out += f\"\\t{key}: \\n\"\n",
    "                for key_lvl2, value_lvl2 in value.items():\n",
    "                    out += f\"\\t\\t{key_lvl2} - {round(value_lvl2,2)} \\n\"                    \n",
    "            else:\n",
    "                out += f\"\\t{key} - {value} \\n\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(combined_df[ combined_df['jobcode_1'].str.contains(\"Gabel\") ] ) ) \n",
    "#print(len(combined_df[ combined_df['class'].str.contains(\"Overhead\",na=False) ] ) ) \n",
    "#print(combined_df['class'].unique() ) \n",
    "#print( combined_df[ combined_df['jobcode_1'].str.contains(\"Gabel\",na=False) ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# //*** Extract Employee Breaks and Offtime.\n",
    "# //*** This was straightforward except for everyone BUT the owner, who did not classify breaks the same as\n",
    "# //*** the employees\n",
    "combined_employee_breaks = combined_df[ combined_df['activity'].isna() ]\n",
    "combined_employee_breaks = combined_employee_breaks[ combined_employee_breaks['billable'].isna()]\n",
    "combined_employee_breaks = combined_employee_breaks[ combined_employee_breaks['jobcode_1'] != \"K2D Consulting Engineers\"]\n",
    "print(combined_employee_breaks['jobcode_1'].unique())\n",
    "\n",
    "combined_employee_breaks_salary_1 = combined_employee_breaks[combined_employee_breaks['salary'] == 1 ]\n",
    "combined_employee_breaks_salary_0 = combined_employee_breaks[combined_employee_breaks['salary'] == 0 ]\n",
    "\n",
    "\n",
    "\n",
    "# //*** Unique List of Employee Names\n",
    "salary_employees = combined_employee_breaks_salary_1['emp_name'].unique()\n",
    "print(f\"salary_employees {salary_employees}\")\n",
    "\n",
    "# //*** Empkoyee offtime jodcodes\n",
    "break_jobcodes = combined_employee_breaks['jobcode_1'].unique()\n",
    "print(f\"break_jobcodes {break_jobcodes}\")\n",
    "\n",
    "employees = {'salary' : {'names' : salary_employees }, 'hourly' : {} }\n",
    "\n",
    "# //*** Get Yearly totals for salaried employees\n",
    "\n",
    "\n",
    "# //******************************\n",
    "# //*** For Each Employee as emp\n",
    "# //******************************\n",
    "for emp in salary_employees:\n",
    "    \n",
    "    # //*** Dictionary structure to hold employees combined hours for later use in some fashion\n",
    "    thisPerson = Person(emp,g['obfuscate'][emp]['fname'])\n",
    "    \n",
    "    # //*** Get Employee entries that are billable = isna  - These are break\n",
    "    loop_combined_emp = combined_employee_breaks[combined_employee_breaks['emp_name'] == emp ]\n",
    "    \n",
    "    # //*** get Employee entries for Overhead work\n",
    "    loop_gabel_df = combined_df[ combined_df['jobcode_1'].str.contains(\"Gabel\",na=False) ]\n",
    "    \n",
    "    loop_overhead_employee_df = loop_gabel_df[ loop_gabel_df['emp_name'] == emp ]\n",
    "    \n",
    "    \n",
    "    # //*** Build jobcode values per employee\n",
    "    for jobcode in break_jobcodes:\n",
    "        loop_jobcode_hours = round( loop_combined_emp[ loop_combined_emp['jobcode_1'] == jobcode]['hours'].sum(), 2)\n",
    "        #thisEmp['breaks'][jobcode] = loop_jobcode_hours\n",
    "        #thisPerson.add_breaks(jobcode,loop_jobcode_hours)\n",
    "        thisPerson.breaks[jobcode] = loop_jobcode_hours\n",
    "        \n",
    "    # //*** Combine Lunch breaks/Rest Breaks for daily breaks\n",
    "    \n",
    "    total_break_time =  thisPerson.breaks['Lunch Break'] + thisPerson.breaks['Rest Break']\n",
    "    total_vacation_time = thisPerson.breaks['Holiday'] + thisPerson.breaks['Vacation']\n",
    "    thisPerson.breaks['combined_break_time'] = total_break_time\n",
    "    thisPerson.breaks['combined_vaction'] = total_vacation_time\n",
    "    \n",
    "    \n",
    "    # //*** Build Employee Total Hours Logged\n",
    "    total_yearly_hours = combined_df[combined_df['emp_name'] == emp ]['hours'].sum()\n",
    "    \n",
    "    thisPerson.totals['hours'] = total_yearly_hours\n",
    "    \n",
    "    # //******************************************************\n",
    "    # //*** Get emp client Billable and non-billable hours\n",
    "    # //******************************************************\n",
    "    \n",
    "    # //*** Get All employee records\n",
    "    total_customer_hours_df = combined_df[combined_df['emp_name'] == emp ]\n",
    "    \n",
    "    # //*** jobcode_2 indicates productive billable customer work\n",
    "    total_customer_hours_df = total_customer_hours_df[total_customer_hours_df['jobcode_2'].str.len() > 2]\n",
    "   \n",
    "    # //*** These are hours attributed to working on customer (ie billable) hours\n",
    "    total_productive_hours = total_customer_hours_df['hours'].sum()\n",
    "    \n",
    "    #productive_hours_day_distribution = total_customer_hours_df['hours']\n",
    "    \n",
    "    # //**** Build Total Hours by Day of the Week,\n",
    "    # //*** Get All entries by Day of the week\n",
    "    \n",
    "    customer_hours_distribution = {}\n",
    "    overhead_hours_distribution = {}\n",
    "    productivity_hours_distribution = {}\n",
    "    for x in g['days_of_week']:\n",
    "        # //*** Build distribution of Customer hours by day\n",
    "        loop_customer_day_df = total_customer_hours_df[total_customer_hours_df['day'] == x ]\n",
    "        loop_customer_day_hours_sum = loop_customer_day_df['hours'].sum()\n",
    "        customer_hours_distribution[x] = loop_customer_day_hours_sum\n",
    "        \n",
    "        # //*** Build distribution of Overhead hours by day\n",
    "        loop_overhead_day_df = total_customer_hours_df[total_customer_hours_df['day'] == x ]\n",
    "        \n",
    "        loop_overhead_day_df = loop_overhead_employee_df[loop_overhead_employee_df['day'] == x ]\n",
    "        loop_overhead_day_hours_sum = loop_overhead_day_df['hours'].sum()\n",
    "        overhead_hours_distribution[x] = loop_overhead_day_hours_sum\n",
    "        \n",
    "        productivity_hours_distribution[x] = loop_overhead_day_hours_sum + loop_customer_day_hours_sum\n",
    "\n",
    "    \n",
    "    \n",
    "    #print (total_customer_hours_df['day_int'].value_counts().sort_index())\n",
    "    \n",
    "        \n",
    "    #.rename(index=[\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\"]) \n",
    "    \n",
    "    overhead_hours = total_yearly_hours - total_productive_hours - total_break_time - total_vacation_time\n",
    "\n",
    "    # //*** Convert vacation hours to days\n",
    "    vacation_days = total_vacation_time / 8\n",
    "    #260 - Work days /year\n",
    "    # //*** Measure average Productivity per day worked:\n",
    "    # //*** 260 Work Days - Vacation days\n",
    "    annual_workdays = 260 - vacation_days\n",
    "    average_workday_hours = (overhead_hours + total_productive_hours) / annual_workdays\n",
    "\n",
    "    # //*** Measure length of the work day (butt in chair time) productivity + breaks\n",
    "    \n",
    "    average_day_length_hours = (overhead_hours + total_productive_hours + total_break_time) / annual_workdays\n",
    "    \n",
    "    thisPerson.totals['productivity_hours'] = overhead_hours + total_productive_hours\n",
    "    thisPerson.totals['customer_hours'] = total_productive_hours\n",
    "    thisPerson.totals['overhead_hours'] = overhead_hours\n",
    "    thisPerson.totals['average_productive_hours'] = average_workday_hours\n",
    "    thisPerson.totals['average_day_length_hours'] = average_day_length_hours\n",
    "    thisPerson.totals['productivity_hours_distribution'] = productivity_hours_distribution\n",
    "    thisPerson.totals['customer_hours_distribution'] = customer_hours_distribution\n",
    "    thisPerson.totals['overhead_hours_distribution'] = overhead_hours_distribution\n",
    "    thisPerson.totals['vacation_hours'] = total_vacation_time\n",
    "    thisPerson.totals['break_hours'] = total_break_time\n",
    "    \n",
    "    \n",
    "    print(thisPerson)\n",
    "    \n",
    "    g['person'][emp] = thisPerson\n",
    "    \n",
    "    #//*** END Each Employee\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // *** Manager Total Productivity by Day\n",
    "manager_hour_distribution = {}\n",
    "\n",
    "for key_person, value_person in g['person'].items():\n",
    "    for key_week, value_hours in value_person.totals['productivity_hours_distribution'].items():\n",
    "        #print(f\"{key_week} : {value_hours}\")\n",
    "        if key_week not in manager_hour_distribution.keys():\n",
    "            manager_hour_distribution[key_week] = value_hours\n",
    "        else:\n",
    "            manager_hour_distribution[key_week] += value_hours\n",
    "\n",
    "manager_hour_distribution = pd.Series(index=manager_hour_distribution.keys(), data=list(manager_hour_distribution.values()))\n",
    "\n",
    "manager_hour_distribution_pmf = build_pmf(manager_hour_distribution)\n",
    "\n",
    "           \n",
    "# //*** Histogram with matplotlib\n",
    "plt.bar(manager_hour_distribution.index, manager_hour_distribution, 1, color='b')\n",
    "plt.tight_layout()\n",
    "plt.ylim(2000,2300)\n",
    "\n",
    "#plt.xticks(jobcode1_value_count_top_20.index.values, jobcode1_value_count_top_20.index, rotation='vertical')\n",
    "plt.title(f\"Managers: Productive Hour Distribution\")\n",
    "#plt.xlabel('Top 30 Jobcodes by Hours')\n",
    "plt.ylabel('Productive Hours')\n",
    "#plt.figure(figsize=(1,500))\n",
    "plt.show()\n",
    "\n",
    "# //*** Histogram with matplotlib\n",
    "plt.bar(manager_hour_distribution_pmf.index, manager_hour_distribution_pmf, 1, color='b')\n",
    "plt.tight_layout()\n",
    "plt.ylim(manager_hour_distribution_pmf.min() *.98 ,manager_hour_distribution_pmf.max() * 1.02)\n",
    "\n",
    "#plt.xticks(jobcode1_value_count_top_20.index.values, jobcode1_value_count_top_20.index, rotation='vertical')\n",
    "plt.title(f\"Managers: Productive Hour PMF\")\n",
    "#plt.xlabel('Top 30 Jobcodes by Hours')\n",
    "plt.ylabel('Productive Hours')\n",
    "#plt.figure(figsize=(1,500))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(combined_df[combined_df['day'] == \"Monday\" ] )\n",
    "\n",
    "# //*** Productivity Data Frame: These Jobs make the money\n",
    "billable_df = combined_df[combined_df['jobcode_2'].str.len() > 2]\n",
    "\n",
    "\n",
    "\n",
    "# //*** Overhead Work: It's Work that's gotta get done\n",
    "overhead_df = combined_df[ combined_df['jobcode_1'].str.contains(\"Gabel\",na=False) ]\n",
    "\n",
    "#print(productive_df['jobcode_1'].unique())\n",
    "#print(overhead_df['jobcode_1'].unique())\n",
    "\n",
    "total_employee_hours_distribution = []\n",
    "billable_employee_hours_distribution = []\n",
    "overhead_employee_hours_distribution = []\n",
    "salary_billable_hours_distribution = []\n",
    "salary_overhead_hours_distribution = []\n",
    "hourly_billable_hours_distribution = []\n",
    "hourly_overhead_hours_distribution = []\n",
    "\n",
    "for x in g['days_of_week']:\n",
    "    \n",
    "    # //*** Get income hours for all Employees by day\n",
    "    loop_billable = billable_df[billable_df['day'].str.contains(x) ]['hours'].sum()\n",
    "    loop_billable_salary_df = billable_df[billable_df['day'].str.contains(x) ]\n",
    "    \n",
    "    # //*** Salary Billable Hours\n",
    "    loop_salary_billable =loop_billable_salary_df[loop_billable_salary_df['salary'] == 1]['hours'].sum()\n",
    "\n",
    "    # //*** Hourly Billable Hours\n",
    "    loop_hourly_billable = loop_billable_salary_df[loop_billable_salary_df['salary'] == 0]['hours'].sum()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # //*** Get Overhead hours for all Employees by day\n",
    "    loop_overhead = overhead_df[overhead_df['day'].str.contains(x) ]['hours'].sum()\n",
    "    loop_overhead_df = overhead_df[overhead_df['day'].str.contains(x) ]\n",
    "\n",
    "    # //*** Salary Billable Hours by day of week\n",
    "    loop_salary_overhead =loop_overhead_df[loop_overhead_df['salary'] == 1]['hours'].sum()\n",
    "    \n",
    "    # //*** Hourly Billable Hours\n",
    "    loop_hourly_overhead =loop_overhead_df[loop_overhead_df['salary'] == 0]['hours'].sum()\n",
    "    \n",
    "    \n",
    "    #print(f\"{loop_salary_billable} - {loop_hourly_billable} : {loop_salary_overhead} - {loop_hourly_overhead}\")\n",
    "    \n",
    "    # //*** Add to the lists\n",
    "    total_employee_hours_distribution.append(loop_billable + loop_overhead)\n",
    "    billable_employee_hours_distribution.append(loop_billable)\n",
    "    overhead_employee_hours_distribution.append(loop_overhead)\n",
    "    salary_billable_hours_distribution.append(loop_salary_billable) \n",
    "    salary_overhead_hours_distribution.append(loop_salary_overhead)\n",
    "    hourly_billable_hours_distribution.append(loop_hourly_billable)\n",
    "    hourly_overhead_hours_distribution.append(loop_hourly_overhead)\n",
    "\n",
    "\n",
    "total_employee_hours_distribution = pd.Series( index=g['days_of_week'], data= total_employee_hours_distribution)\n",
    "total_employee_hours_distribution_pmf = build_pmf(total_employee_hours_distribution)\n",
    "\n",
    "billable_employee_hours_distribution = pd.Series(index=g['days_of_week'], data= billable_employee_hours_distribution)\n",
    "billable_employee_hours_distribution_pmf = build_pmf(billable_employee_hours_distribution)\n",
    "\n",
    "overhead_employee_hours_distribution = pd.Series(index=g['days_of_week'], data= overhead_employee_hours_distribution)\n",
    "overhead_employee_hours_distribution_pmf = build_pmf(overhead_employee_hours_distribution)\n",
    "\n",
    "salary_billable_hours_distribution = pd.Series(index=g['days_of_week'], data= salary_billable_hours_distribution)\n",
    "salary_billable_hours_distribution = build_pmf(salary_billable_hours_distribution)\n",
    "\n",
    "salary_overhead_hours_distribution = pd.Series(index=g['days_of_week'], data= salary_overhead_hours_distribution)\n",
    "salary_overhead_hours_distribution = build_pmf(salary_overhead_hours_distribution)\n",
    "\n",
    "hourly_billable_hours_distribution = pd.Series(index=g['days_of_week'], data= hourly_billable_hours_distribution)\n",
    "hourly_billable_hours_distribution = build_pmf(hourly_billable_hours_distribution)\n",
    "\n",
    "hourly_overhead_hours_distribution = pd.Series(index=g['days_of_week'], data= hourly_overhead_hours_distribution)\n",
    "hourly_overhead_hours_distribution = build_pmf(hourly_overhead_hours_distribution)\n",
    "\n",
    "print(total_employee_hours_distribution_pmf)\n",
    "print(billable_employee_hours_distribution_pmf)\n",
    "print(overhead_employee_hours_distribution_pmf)    \n",
    "print(salary_billable_hours_distribution)    \n",
    "print(salary_overhead_hours_distribution)    \n",
    "print(hourly_billable_hours_distribution)    \n",
    "print(hourly_overhead_hours_distribution)    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.style.use('ggplot')\n",
    "n = 5\n",
    "var1 = total_employee_hours_distribution_pmf\n",
    "var2 = billable_employee_hours_distribution_pmf\n",
    "var3 = overhead_employee_hours_distribution_pmf\n",
    "fig, ax = plt.subplots()\n",
    "index = np.arange(n)\n",
    "bar_width = 0.2\n",
    "opacity = 0.9\n",
    "ax.bar(index, var1, bar_width, alpha=opacity, color='navy',label='Total Productivity')\n",
    "                \n",
    "ax.bar(index+bar_width, var2, bar_width, alpha=opacity, color='darkcyan', label='Billable')\n",
    "ax.bar(index+(bar_width*2), var3, bar_width, alpha=opacity, color='skyblue', label='Overhead')\n",
    "plt.ylim(billable_employee_hours_distribution_pmf.min() * .95,billable_employee_hours_distribution_pmf.max() * 1.05)\n",
    "#ax.set_xlabel('Seasons')\n",
    "ax.set_ylabel('Frequencies')\n",
    "plt.title(f\"All Employee: Productivity Distribution\")\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(g['days_of_week'])\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# //*** Histogram with matplotlib\n",
    "plt.bar(total_employee_hours_distribution_pmf.index, total_employee_hours_distribution_pmf, 1, color='b')\n",
    "plt.tight_layout()\n",
    "plt.ylim(total_employee_hours_distribution_pmf.min() * .95,total_employee_hours_distribution_pmf.max() * 1.05)\n",
    "\n",
    "#plt.xticks(jobcode1_value_count_top_20.index.values, jobcode1_value_count_top_20.index, rotation='vertical')\n",
    "plt.title(f\"All Employee: Productive Hour Distribution\")\n",
    "#plt.xlabel('Top 30 Jobcodes by Hours')\n",
    "plt.ylabel('Productive Hours')\n",
    "#plt.figure(figsize=(1,500))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_rest_periods = combined_df[combined_df['billable'].isna() ]\n",
    "#print(logged_rest_periods)\n",
    "logged_rest_periods['jobcode_1'].unique()\n",
    "g['rest_period_dict'] = {}\n",
    "g['rest_period_reverse_dict'] = {}\n",
    "counter = 1\n",
    "for x in logged_rest_periods['jobcode_1'].unique():\n",
    "    g['rest_period_dict'][x] = counter\n",
    "    g['rest_period_reverse_dict'][counter] = x\n",
    "    counter = counter + 1\n",
    "\n",
    "print(g['rest_period_dict'])\n",
    "print(g['rest_period_reverse_dict'])\n",
    "\n",
    "jobID = logged_rest_periods['jobcode_1']\n",
    "\n",
    "for find,replace in g['rest_period_dict'].items():\n",
    "    print(f\"{find} {replace}\")\n",
    "    jobID = jobID.str.replace(find,str(replace))\n",
    "print(jobID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Not So Dead Ends\n",
    "#print(jobcode1_value_count.str.contains('Gabel',regex=False))\n",
    "#billable_jobs_gabel = combined_df[combined_df['jobcode_1'].str.contains('Gabel',regex=False) == False  ]\n",
    "\n",
    "#combined_df[combined_df.billable =='Yes']\n",
    "#print(billable_jobs_gabel)\n",
    "\n",
    "# //*** Billable is not a measure productivity.\n",
    "# //*** It is a matter of invoicing\n",
    "#combined_billable = combined_df[ combined_df['billable'] == 'Yes' ]\n",
    "#combined_non_billable = combined_df[ combined_df['billable'] == 'No' ]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
