{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is code to import clean and combine the time sheet datasets. The code is designed to harvest files from a subfolder titled orig. It processes all files in the folder with a CSV or an XLSX file extension.\n",
    "\n",
    "Each file is imported individually. A number of columns are removed that don't appear to be statistically significant.\n",
    "   'username', 'payroll_id', 'fname', 'lname', 'number', 'group','local_day', 'local_start_time', 'local_end_time', 'tz', 'location', 'notes', 'approved_status'.\n",
    "   \n",
    "Each cleaned file is stored individially, all clean timesheets are combined into a single dataframe which is saved separately as combined.dat.\n",
    "\n",
    "The Employee names are replaced with a unique identified EMP_1, EMP_2 etc. The employee details are stored in a separate file for later reuse. Based on additional information, the salaried employees have been identified separately and a salary variable in engineered (1 or 0) based on an employees salaried status.\n",
    "\n",
    "The final output is keys.json which is a dictionary of employee attributes and combined.dat which represents a cleaned dataframe of all significant variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Initial Data Prep and light obfuscate\n",
    "# //*** Removed Uneeded Columns\n",
    "# //*** Removed Individidual Identification\n",
    "# //*** Added EmployeeID Proxy to each Dataframe\n",
    "# //*** Added Salaried field as additional information from data source\n",
    "# //*** Combined (concatinated) All Data frames\n",
    "# //*** Saved Combined and Individual data frames separately so original files can be deleted\n",
    "import xlrd # pandas dependency\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "###\n",
    "\n",
    "# Managers - Salary, Everyone Else is Salaried\n",
    "# Ari Cynthia  Gina Marina Michelle Rosemary\n",
    "# Hourly\n",
    "# Dominique Fiona Francis Jim  Megan Micaela\n",
    "\n",
    "g = {\n",
    "    'remove_cols': ['username', 'payroll_id', 'fname', 'lname', 'number', 'group','local_day', 'local_start_time', 'local_end_time', 'tz', 'location', 'notes', 'approved_status'],\n",
    "    'obfuscate': {},\n",
    "    'df' : [],\n",
    "    'salary' : [ 'Ari', 'Cynthia', 'Gina', 'Marina', 'Michelle', 'Rosemary' ]\n",
    "    \n",
    "}\n",
    "curDir = os.getcwd()\n",
    "\n",
    "fileList = os.listdir(curDir + \"\\\\orig\")\n",
    "\n",
    "employee_counter = 0\n",
    "\n",
    "for fname in fileList:\n",
    "    valid_file = False\n",
    "    ### For each Excel File\n",
    "    if \".xlsx\" in fname:\n",
    "        valid_file = True\n",
    "        \n",
    "        # //*** Build Generic Employee value\n",
    "        employee_counter = employee_counter + 1\n",
    "\n",
    "        # //*** Each employee is EMP_ with a number\n",
    "        generic_name = f\"EMP_{employee_counter}\"\n",
    "        loop_df = pd.read_excel(curDir+\"\\\\orig\\\\\"+fname,1)\n",
    "    \n",
    "    ### For each CSV File\n",
    "    if \".csv\" in fname:\n",
    "        valid_file = True\n",
    "        \n",
    "        # //*** Build Generic Employee value\n",
    "        employee_counter = employee_counter + 1\n",
    "\n",
    "        # //*** Each employee is EMP_ with a number\n",
    "        generic_name = f\"EMP_{employee_counter}\"\n",
    "        loop_df = pd.read_csv(curDir+\"\\\\orig\\\\\"+fname)\n",
    "        \n",
    "        \n",
    "    \n",
    "    if valid_file == True:\n",
    "        salary = 0\n",
    "        \n",
    "        #print(f\"{fname} {generic_name}\")\n",
    "        \n",
    "        # //*** Classify Employee as Salaried\n",
    "        for x in g['salary']:\n",
    "            if x.lower() in fname.lower():                \n",
    "                # //*** Remove Emplyee from salary List to avoid double matches. It works well Enough.\n",
    "                g['salary'].remove(x)\n",
    "                salary = 1\n",
    "                break\n",
    "        \n",
    "        loop_user_details = {\n",
    "            'generic_name': generic_name,\n",
    "            'fname': loop_df.loc[0, 'fname'],\n",
    "            'lname': loop_df.loc[0, 'lname'],\n",
    "            'group': loop_df.loc[0, 'group'],\n",
    "            'file': generic_name + \".dat\",\n",
    "            'salary': salary\n",
    "        }\n",
    "        \n",
    "        ### Remove unneeded columns\n",
    "        loop_df = loop_df.drop(columns=g['remove_cols'])\n",
    "        \n",
    "        \n",
    "        # //*** Add Columnns based on Salary Type and Employee Name.\n",
    "        # //*** Employee name is used to find an individual in the data frame.\n",
    "        loop_new_emp_col = []\n",
    "        loop_salary_column = []\n",
    "        \n",
    "        for x in range(0, len(loop_df)):\n",
    "            loop_new_emp_col.append(generic_name)\n",
    "            loop_salary_column.append(salary)\n",
    "\n",
    "        \n",
    "        # Add Employee Generic Name to the df\n",
    "        loop_df['emp_name'] = loop_new_emp_col\n",
    "        loop_df['salary'] = loop_salary_column\n",
    "        \n",
    "        \n",
    "        loop_df.to_csv(generic_name+\".dat\")\n",
    "\n",
    "        g['obfuscate'][generic_name] = loop_user_details\n",
    "        \n",
    "        g['df'].append(loop_df)\n",
    "        \n",
    "#print(g['obfuscate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keys.json', 'w') as outfile:\n",
    "    outfile.write(json.dumps(g['obfuscate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Combine All Employees into a single Data Frame\n",
    "combined_df = pd.concat(g['df'])\n",
    "combined_df = combined_df.drop(columns=['has_flags','flag_types'])\n",
    "\n",
    "\n",
    "combined_df.to_csv(\"combined.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               local_date  hours                    jobcode_1  \\\n",
      "0     2019-01-01 00:00:00   8.00                      Holiday   \n",
      "1     2019-01-02 00:00:00   1.75                 Gabel Energy   \n",
      "2     2019-01-02 00:00:00   1.08  ALTUS Architecture + Design   \n",
      "3     2019-01-02 00:00:00   1.58                 Gabel Energy   \n",
      "4     2019-01-02 00:00:00   1.25        BDE Architecture Inc.   \n",
      "...                   ...    ...                          ...   \n",
      "2796  2019-12-25 00:00:00   8.00                      Holiday   \n",
      "2797  2019-12-26 00:00:00   7.20                     Vacation   \n",
      "2798  2019-12-27 00:00:00   7.20                     Vacation   \n",
      "2799  2019-12-30 00:00:00   7.20                     Vacation   \n",
      "2800  2019-12-31 00:00:00   7.20                     Vacation   \n",
      "\n",
      "                                     jobcode_2  \\\n",
      "0                                          NaN   \n",
      "1                                          NaN   \n",
      "2     19009 - Munson Residence and Guest House   \n",
      "3                                          NaN   \n",
      "4     17214 Walnut Creek Transit Village Phase   \n",
      "...                                        ...   \n",
      "2796                                       NaN   \n",
      "2797                                       NaN   \n",
      "2798                                       NaN   \n",
      "2799                                       NaN   \n",
      "2800                                       NaN   \n",
      "\n",
      "                                        activity billable           class  \\\n",
      "0                                            NaN      NaN             NaN   \n",
      "1     Gabel: Project Coordination (non-billable)       No        Overhead   \n",
      "2                          Energy Model/Takeoffs       No     Residential   \n",
      "3                                    Gabel: Misc       No        Overhead   \n",
      "4                          Energy Model/Takeoffs      Yes  Nonresidential   \n",
      "...                                          ...      ...             ...   \n",
      "2796                                         NaN       No        Overhead   \n",
      "2797                                         NaN       No        Overhead   \n",
      "2798                                         NaN       No        Overhead   \n",
      "2799                                         NaN       No        Overhead   \n",
      "2800                                         NaN       No        Overhead   \n",
      "\n",
      "                     service item emp_name  salary activities  \n",
      "0                             NaN    EMP_1       1        NaN  \n",
      "1                        Overhead    EMP_1       1        NaN  \n",
      "2     Energy Code Compliance Work    EMP_1       1        NaN  \n",
      "3                        Overhead    EMP_1       1        NaN  \n",
      "4     Energy Code Compliance Work    EMP_1       1        NaN  \n",
      "...                           ...      ...     ...        ...  \n",
      "2796                     Overhead   EMP_12       1        NaN  \n",
      "2797                     Overhead   EMP_12       1        NaN  \n",
      "2798                     Overhead   EMP_12       1        NaN  \n",
      "2799                     Overhead   EMP_12       1        NaN  \n",
      "2800                     Overhead   EMP_12       1        NaN  \n",
      "\n",
      "[23290 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(combined_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
