{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Initial Data Prep and light obfuscate\n",
    "# //*** Removed Uneeded Columns\n",
    "# //*** Removed Individidual Identification\n",
    "# //*** Added EmployeeID Proxy to each Dataframe\n",
    "# //*** Added Salaried field as additional information from data source\n",
    "# //*** Combined (concatinated) All Data frames\n",
    "# //*** Saved Combined and Individual data frames separately so original files can be deleted\n",
    "import xlrd # pandas dependency\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "###\n",
    "\n",
    "# Managers - Salary, Everyone Else is Salaried\n",
    "# Ari Cynthia  Gina Marina Michelle Rosemary\n",
    "# Hourly\n",
    "# Dominique Fiona Francis Jim  Megan Micaela\n",
    "\n",
    "g = {\n",
    "    'remove_cols': ['username', 'payroll_id', 'fname', 'lname', 'number', 'group','local_day', 'local_start_time', 'local_end_time', 'tz', 'location', 'notes', 'approved_status'],\n",
    "    'obfuscate': {},\n",
    "    'df' : [],\n",
    "    'salary' : [ 'Ari', 'Cynthia', 'Gina', 'Marina', 'Michelle', 'Rosemary' ]\n",
    "    \n",
    "}\n",
    "curDir = os.getcwd()\n",
    "\n",
    "fileList = os.listdir(curDir + \"\\\\orig\")\n",
    "\n",
    "employee_counter = 0\n",
    "\n",
    "for fname in fileList:\n",
    "    ### For each Excel File\n",
    "    if \".xlsx\" in fname:\n",
    "\n",
    "        # //*** Build Generic Employee value\n",
    "        employee_counter = employee_counter + 1\n",
    "\n",
    "        # //*** Each employee is EMP_ with a number\n",
    "        generic_name = f\"EMP_{employee_counter}\"\n",
    "        loop_df = pd.read_excel(curDir+\"\\\\orig\\\\\"+fname,1)\n",
    "        salary = 0\n",
    "        \n",
    "        # //*** Classify Employee as Salaried\n",
    "        for x in g['salary']:\n",
    "            if x.lower() in fname.lower():                \n",
    "                # //*** Remove Emplyee from salary List to avoid double matches. It works well Enough.\n",
    "                g['salary'].remove(x)\n",
    "                salary = 1\n",
    "                break\n",
    "\n",
    "        loop_user_details = {\n",
    "            'generic_name': generic_name,\n",
    "            'fname': loop_df.loc[0, 'fname'],\n",
    "            'lname': loop_df.loc[0, 'lname'],\n",
    "            'group': loop_df.loc[0, 'group'],\n",
    "            'file': generic_name + \".dat\",\n",
    "            'salary': salary\n",
    "        }\n",
    "        ### Remove unneeded columns\n",
    "        loop_df = loop_df.drop(columns=g['remove_cols'])\n",
    "        \n",
    "        \n",
    "        # //*** Add Columnns based on Salary Type and Employee Name.\n",
    "        # //*** Employee name is used to find an individual in the data frame.\n",
    "        loop_new_emp_col = []\n",
    "        loop_salary_column = []\n",
    "        \n",
    "        for x in range(0, len(loop_df)):\n",
    "            loop_new_emp_col.append(generic_name)\n",
    "            loop_salary_column.append(salary)\n",
    "\n",
    "        \n",
    "        # Add Employee Generic Name to the df\n",
    "        loop_df['emp_name'] = loop_new_emp_col\n",
    "        loop_df['salary'] = loop_salary_column\n",
    "        \n",
    "        \n",
    "        loop_df.to_csv(generic_name+\".dat\")\n",
    "\n",
    "        g['obfuscate'][generic_name] = loop_user_details\n",
    "        \n",
    "        g['df'].append(loop_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('keys.json', 'w') as outfile:\n",
    "    outfile.write(json.dumps(g['obfuscate']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Combine All Employees into a single Data Frame\n",
    "combined_df = pd.concat(g['df'])\n",
    "combined_df.to_csv(\"combined.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df['billable'].unique())\n",
    "#preg[preg.caseid==2298]\n",
    "print(f\"Billable Hours: {combined_df[combined_df.billable =='Yes']['hours'].sum()}\")\n",
    "print(f\"Not Billable Hours: {combined_df[combined_df.billable =='No']['hours'].sum()}\")\n",
    "print(f\"Holiday : {combined_df[combined_df.billable.isnull()]['hours'].sum()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
