{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SQL Server', 'ODBC Driver 17 for SQL Server', 'SQL Server Native Client 11.0']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#//*** This thread helped with the connection\n",
    "#//***https://stackoverflow.com/questions/37692780/error-28000-login-failed-for-user-domain-user-with-pyodbc\n",
    "\n",
    "#//**** Update the ODBC Driver\n",
    "#//**** https://docs.microsoft.com/en-us/sql/connect/odbc/download-odbc-driver-for-sql-server?view=sql-server-ver15\n",
    "import pyodbc\n",
    "import datetime\n",
    "import json\n",
    "from datetime import date, timedelta\n",
    "import pandas as pd\n",
    "print(pyodbc.drivers())\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import time\n",
    "\n",
    "#//*** Use the whole window in the IPYNB editor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#//*** Maximize columns and rows displayed by pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "server = 'tcp:OM-CASF-DB01' \n",
    "server = 'OM-CASF-DLSQL' \n",
    "# server = '10.218.97.2'\n",
    "database = 'DaletDB' \n",
    "\n",
    "with open('./ignore_folder/misc.json') as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "username = data[\"user\"] \n",
    "password = data[\"password\"]\n",
    "del data\n",
    "#cnxn = pyodbc.connect('DRIVER={ODBC Driver 17 for SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cnxn = pyodbc.connect('Trusted_Connection=yes;DRIVER={SQL Server};SERVER='+server+';DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['title_id', 'title_type_id', 'title_interface_id', 'user_id', 'title',\n",
      "       'interpret', 'author', 'client', 'duration', 'is_online', 'is_recorded',\n",
      "       'record_date', 'start_date', 'end_date', 'kill_date', 'audio_duration',\n",
      "       'use_manual_duration', 'soundfile_id', 'year', 'keywords',\n",
      "       'site_origin', 'no_overwrite', 'is_rotational_cart', 'replacement',\n",
      "       'last_words', 'is_opener', 'weight', 'beats_pm', 'master_record',\n",
      "       'compagny_id', 'compagny_disp_name', 'album_disp_name', 'package_id',\n",
      "       'album_id', 'song_id', 'day_part_rest_id', 'keep_date'],\n",
      "      dtype='object')\n",
      "Quarterly Shows :  776\n",
      "Quarterly Show Hours:  589.7785052777778\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_id</th>\n",
       "      <th>title_type_id</th>\n",
       "      <th>title</th>\n",
       "      <th>duration</th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31565121</td>\n",
       "      <td>25</td>\n",
       "      <td>5PM Weekday</td>\n",
       "      <td>1680011</td>\n",
       "      <td>2021-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31565938</td>\n",
       "      <td>25</td>\n",
       "      <td>6PM Weekday</td>\n",
       "      <td>3515979</td>\n",
       "      <td>2021-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31568612</td>\n",
       "      <td>25</td>\n",
       "      <td>11PM WEEKDAY</td>\n",
       "      <td>2113044</td>\n",
       "      <td>2021-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31569093</td>\n",
       "      <td>25</td>\n",
       "      <td>9AM Saturday</td>\n",
       "      <td>3720416</td>\n",
       "      <td>2021-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31569724</td>\n",
       "      <td>25</td>\n",
       "      <td>5AM Sunday</td>\n",
       "      <td>3477006</td>\n",
       "      <td>2021-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>33027792</td>\n",
       "      <td>25</td>\n",
       "      <td>8AM Saturday</td>\n",
       "      <td>3724420</td>\n",
       "      <td>2021-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>33028439</td>\n",
       "      <td>25</td>\n",
       "      <td>5AM Sunday</td>\n",
       "      <td>3477006</td>\n",
       "      <td>2021-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>33028926</td>\n",
       "      <td>25</td>\n",
       "      <td>6AM Sunday</td>\n",
       "      <td>3509973</td>\n",
       "      <td>2021-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>33029418</td>\n",
       "      <td>25</td>\n",
       "      <td>9AM Sunday</td>\n",
       "      <td>3569966</td>\n",
       "      <td>2021-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>33036373</td>\n",
       "      <td>25</td>\n",
       "      <td>After The Game</td>\n",
       "      <td>3504968</td>\n",
       "      <td>2021-09-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>776 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title_id  title_type_id           title  duration  start_date\n",
       "0    31565121             25     5PM Weekday   1680011  2021-07-01\n",
       "1    31565938             25     6PM Weekday   3515979  2021-07-01\n",
       "2    31568612             25    11PM WEEKDAY   2113044  2021-07-01\n",
       "3    31569093             25    9AM Saturday   3720416  2021-07-01\n",
       "4    31569724             25      5AM Sunday   3477006  2021-07-01\n",
       "..        ...            ...             ...       ...         ...\n",
       "775  33027792             25    8AM Saturday   3724420  2021-09-30\n",
       "776  33028439             25      5AM Sunday   3477006  2021-09-30\n",
       "777  33028926             25      6AM Sunday   3509973  2021-09-30\n",
       "778  33029418             25      9AM Sunday   3569966  2021-09-30\n",
       "779  33036373             25  After The Game   3504968  2021-09-30\n",
       "\n",
       "[776 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//************************************************************\n",
    "#//************************************************************\n",
    "#//*** get all Rundowns in given Quarter\n",
    "#//************************************************************\n",
    "#//************************************************************\n",
    "\n",
    "#//*** Table: titles\n",
    "#//*** Search Titles by Date to get Rundown IDs\n",
    "#//*** Titles Contains All titled Objects including scripts rundowns and MOS objects\n",
    "#//*** title_type_id = 25 <--- Rundown Objects\n",
    "#//*** duration > 900000 <--- Rundowns Longer than 15 minutes (15 * 60 Seconds * 1000 ms)\n",
    "#//***                        Automatically filters out short content like cutins\n",
    "title_cols = ['title_id','title_type_id','title','duration','start_date']\n",
    "import datetime\n",
    "\n",
    "\n",
    "tgt_year = 2021\n",
    "quarter = \"Q3\"\n",
    "\n",
    "#//*** Build the BETWEEN portion of the query based on quarter and YEAR\n",
    "\n",
    "quarter_query = \"\"\n",
    "if quarter == \"Q1\":\n",
    "    quarter_query = f\"'{tgt_year}-01-01T00:00:00' AND '{tgt_year}-03-31T23:59:59'\"\n",
    "\n",
    "elif quarter == \"Q2\":\n",
    "    quarter_query = f\"'{tgt_year}-04-01T00:00:00' AND '{tgt_year}-06-30T23:59:59'\"\n",
    "\n",
    "elif quarter == \"Q3\":\n",
    "    quarter_query = f\"'{tgt_year}-07-01T00:00:00' AND '{tgt_year}-09-30T23:59:59'\"\n",
    "\n",
    "elif quarter == \"Q4\":\n",
    "    quarter_query = f\"'{tgt_year}-09-01T00:00:00' AND '{tgt_year}-12-31T23:59:59'\"\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT *\n",
    "FROM titles \n",
    "WHERE title_type_id = 25 \n",
    "    AND duration > 900000\n",
    "    AND start_date BETWEEN {quarter_query}\n",
    "    AND title <> 'Prepak'\n",
    "    AND title <> 'Tool Kit'\n",
    "    AND title <> 'Tricaster'\n",
    "    AND title <> 'PRODUCER HOLD'\n",
    "    AND title <> 'Promo'\n",
    "    AND title <> 'Breaking News'\n",
    "    AND title <> 'Dalet OD XPression'\n",
    "    AND title <> 'PRACTICE'\n",
    "    AND title <> '7AM DIGITAL'\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "cursor.execute(query)\n",
    "results = cursor.fetchall()\n",
    "#results = cursor.fetchmany(100)\n",
    "\n",
    "all_rundowns_df = pd.read_sql(query,cnxn)\n",
    "\n",
    "print(all_rundowns_df.columns)\n",
    "\n",
    "all_rundowns_df = all_rundowns_df[title_cols]\n",
    "\n",
    "#//*** Filter out shows that SAY DO NOT USE\n",
    "all_rundowns_df = all_rundowns_df[all_rundowns_df['title'].str.contains('DO NOT USE')==False]\n",
    "\n",
    "#//*** Convert Start_Date to Date only\n",
    "all_rundowns_df['start_date'] = all_rundowns_df['start_date'].apply(lambda x: x.date())\n",
    "\n",
    "all_dates = all_rundowns_df['start_date'].unique()\n",
    "\n",
    "#//*** Pick one day to test with\n",
    "one_day_df = all_rundowns_df[all_rundowns_df['start_date'] == all_dates[-3]]\n",
    "\n",
    "\n",
    "print(\"Quarterly Shows : \", len(all_rundowns_df))\n",
    "print(\"Quarterly Show Hours: \", all_rundowns_df['duration'].sum() / 60000 / 60)\n",
    "all_rundowns_df.iloc[-40:]\n",
    "all_rundowns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-01 / 2021-09-30\n",
      "2021-07-02 / 2021-09-30\n",
      "2021-07-03 / 2021-09-30\n",
      "2021-07-04 / 2021-09-30\n",
      "2021-07-05 / 2021-09-30\n",
      "2021-07-06 / 2021-09-30\n",
      "2021-07-07 / 2021-09-30\n",
      "2021-07-08 / 2021-09-30\n",
      "2021-07-09 / 2021-09-30\n",
      "2021-07-10 / 2021-09-30\n",
      "2021-07-11 / 2021-09-30\n",
      "2021-07-12 / 2021-09-30\n",
      "2021-07-13 / 2021-09-30\n",
      "2021-07-14 / 2021-09-30\n",
      "2021-07-15 / 2021-09-30\n",
      "2021-07-16 / 2021-09-30\n",
      "2021-07-17 / 2021-09-30\n",
      "2021-07-18 / 2021-09-30\n",
      "2021-07-19 / 2021-09-30\n",
      "2021-07-20 / 2021-09-30\n",
      "2021-07-21 / 2021-09-30\n",
      "2021-07-22 / 2021-09-30\n",
      "2021-07-23 / 2021-09-30\n",
      "2021-07-24 / 2021-09-30\n",
      "2021-07-25 / 2021-09-30\n",
      "2021-07-26 / 2021-09-30\n",
      "2021-07-27 / 2021-09-30\n",
      "2021-07-28 / 2021-09-30\n",
      "2021-07-29 / 2021-09-30\n",
      "2021-07-30 / 2021-09-30\n",
      "2021-07-31 / 2021-09-30\n",
      "2021-08-01 / 2021-09-30\n",
      "2021-08-02 / 2021-09-30\n",
      "2021-08-03 / 2021-09-30\n",
      "2021-08-04 / 2021-09-30\n",
      "2021-08-05 / 2021-09-30\n",
      "2021-08-06 / 2021-09-30\n",
      "2021-08-07 / 2021-09-30\n",
      "2021-08-08 / 2021-09-30\n",
      "2021-08-09 / 2021-09-30\n",
      "2021-08-10 / 2021-09-30\n",
      "2021-08-11 / 2021-09-30\n",
      "2021-08-12 / 2021-09-30\n",
      "2021-08-13 / 2021-09-30\n",
      "2021-08-14 / 2021-09-30\n",
      "2021-08-15 / 2021-09-30\n",
      "2021-08-16 / 2021-09-30\n",
      "2021-08-17 / 2021-09-30\n",
      "2021-08-18 / 2021-09-30\n",
      "2021-08-19 / 2021-09-30\n",
      "2021-08-20 / 2021-09-30\n",
      "2021-08-21 / 2021-09-30\n",
      "2021-08-22 / 2021-09-30\n",
      "2021-08-23 / 2021-09-30\n",
      "2021-08-24 / 2021-09-30\n",
      "2021-08-25 / 2021-09-30\n",
      "2021-08-26 / 2021-09-30\n",
      "2021-08-27 / 2021-09-30\n",
      "2021-08-28 / 2021-09-30\n",
      "2021-08-29 / 2021-09-30\n",
      "2021-08-30 / 2021-09-30\n",
      "================\n",
      "NO A-Block Found\n",
      "================\n",
      "     title_id  title_type_id                      title  duration  start_date\n",
      "502  32519358             25                5PM Weekday   1680011  2021-08-30\n",
      "503  32520045             25                6PM Weekday   3515979  2021-08-30\n",
      "504  32522256             25               11PM WEEKDAY   2114045  2021-08-30\n",
      "505  32526929             25                5AM Weekday   3435031  2021-08-30\n",
      "506  32528248             25                6AM Weekday   3630093  2021-08-30\n",
      "507  32532334             25                11AM Midday   1728993  2021-08-30\n",
      "508  32533111             25             11:30AM Midday   1705970  2021-08-30\n",
      "509  32534481             25  CALDOR FIRE Breaking News   7199992  2021-08-30\n",
      "510  32535984             25        3PM Getting Answers   1799998  2021-08-30\n",
      "511  32536804             25                4PM Weekday   3674003  2021-08-30\n",
      "2021-08-31 / 2021-09-30\n",
      "2021-09-01 / 2021-09-30\n",
      "2021-09-02 / 2021-09-30\n",
      "2021-09-03 / 2021-09-30\n",
      "2021-09-04 / 2021-09-30\n",
      "2021-09-05 / 2021-09-30\n",
      "2021-09-06 / 2021-09-30\n",
      "2021-09-07 / 2021-09-30\n",
      "2021-09-08 / 2021-09-30\n",
      "2021-09-09 / 2021-09-30\n",
      "2021-09-10 / 2021-09-30\n",
      "2021-09-11 / 2021-09-30\n",
      "2021-09-12 / 2021-09-30\n",
      "2021-09-13 / 2021-09-30\n",
      "2021-09-14 / 2021-09-30\n",
      "2021-09-15 / 2021-09-30\n",
      "2021-09-16 / 2021-09-30\n",
      "2021-09-17 / 2021-09-30\n",
      "2021-09-18 / 2021-09-30\n",
      "2021-09-19 / 2021-09-30\n",
      "2021-09-20 / 2021-09-30\n",
      "2021-09-21 / 2021-09-30\n",
      "2021-09-22 / 2021-09-30\n",
      "2021-09-23 / 2021-09-30\n",
      "2021-09-24 / 2021-09-30\n",
      "2021-09-25 / 2021-09-30\n",
      "2021-09-26 / 2021-09-30\n",
      "2021-09-27 / 2021-09-30\n",
      "2021-09-28 / 2021-09-30\n",
      "2021-09-29 / 2021-09-30\n",
      "2021-09-30 / 2021-09-30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>rundown</th>\n",
       "      <th>title_id</th>\n",
       "      <th>storyslug</th>\n",
       "      <th>duration</th>\n",
       "      <th>StoryText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>5PM Weekday</td>\n",
       "      <td>31565204</td>\n",
       "      <td>5PCOLDOPEN 1</td>\n",
       "      <td>8</td>\n",
       "      <td>[[QUOTE: are you playing pop music to drown ou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>5PM Weekday</td>\n",
       "      <td>31565217</td>\n",
       "      <td>5P HELLO FRAMES</td>\n",
       "      <td>7</td>\n",
       "      <td>Good Evening,  I'm Dan Ashley.\\nand I'm Ama Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>5PM Weekday</td>\n",
       "      <td>31579703</td>\n",
       "      <td>5P FIREWORKS CONCERNS PKG</td>\n",
       "      <td>78</td>\n",
       "      <td>{***PKG***}\\nAs Bay Area families prepare to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>5PM Weekday</td>\n",
       "      <td>31579811</td>\n",
       "      <td>5P BAYVIEW INTERSECTION FLS INT</td>\n",
       "      <td>14</td>\n",
       "      <td>One of the things that neighbors told me is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>5PM Weekday</td>\n",
       "      <td>31579835</td>\n",
       "      <td>5P BAYVIEW INTERSECTION PKG</td>\n",
       "      <td>107</td>\n",
       "      <td>Neighbors began taking pictures after complain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25870</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>After The Game</td>\n",
       "      <td>33036449</td>\n",
       "      <td>ATG OREGON VS STANFORD OC</td>\n",
       "      <td>104</td>\n",
       "      <td>onto college football...stanford hosting 3rd r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25873</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>After The Game</td>\n",
       "      <td>33036454</td>\n",
       "      <td>ATG WSU VS CALIFORNIA OC</td>\n",
       "      <td>38</td>\n",
       "      <td>cal lost a heartbreaker last week, fumbling at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25877</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>After The Game</td>\n",
       "      <td>33036496</td>\n",
       "      <td>ATG PADRES VS GIANTS OC</td>\n",
       "      <td>95</td>\n",
       "      <td>the giants have won a franchise record-tying 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25879</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>After The Game</td>\n",
       "      <td>33036500</td>\n",
       "      <td>ATG PADRES VS GIANTS OC</td>\n",
       "      <td>27</td>\n",
       "      <td>so, the giants need to beat the padres tomorro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25880</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>After The Game</td>\n",
       "      <td>33036501</td>\n",
       "      <td>ATG BREWERS VS DODGERS OC</td>\n",
       "      <td>18</td>\n",
       "      <td>the giants don't have to win tomorrow if the d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10077 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       start_date         rundown  title_id                        storyslug  \\\n",
       "7      2021-07-01     5PM Weekday  31565204                     5PCOLDOPEN 1   \n",
       "8      2021-07-01     5PM Weekday  31565217                  5P HELLO FRAMES   \n",
       "12     2021-07-01     5PM Weekday  31579703        5P FIREWORKS CONCERNS PKG   \n",
       "13     2021-07-01     5PM Weekday  31579811  5P BAYVIEW INTERSECTION FLS INT   \n",
       "14     2021-07-01     5PM Weekday  31579835      5P BAYVIEW INTERSECTION PKG   \n",
       "...           ...             ...       ...                              ...   \n",
       "25870  2021-09-30  After The Game  33036449        ATG OREGON VS STANFORD OC   \n",
       "25873  2021-09-30  After The Game  33036454         ATG WSU VS CALIFORNIA OC   \n",
       "25877  2021-09-30  After The Game  33036496          ATG PADRES VS GIANTS OC   \n",
       "25879  2021-09-30  After The Game  33036500          ATG PADRES VS GIANTS OC   \n",
       "25880  2021-09-30  After The Game  33036501        ATG BREWERS VS DODGERS OC   \n",
       "\n",
       "       duration                                          StoryText  \n",
       "7             8  [[QUOTE: are you playing pop music to drown ou...  \n",
       "8             7  Good Evening,  I'm Dan Ashley.\\nand I'm Ama Da...  \n",
       "12           78  {***PKG***}\\nAs Bay Area families prepare to c...  \n",
       "13           14  One of the things that neighbors told me is th...  \n",
       "14          107  Neighbors began taking pictures after complain...  \n",
       "...         ...                                                ...  \n",
       "25870       104  onto college football...stanford hosting 3rd r...  \n",
       "25873        38  cal lost a heartbreaker last week, fumbling at...  \n",
       "25877        95  the giants have won a franchise record-tying 1...  \n",
       "25879        27  so, the giants need to beat the padres tomorro...  \n",
       "25880        18  the giants don't have to win tomorrow if the d...  \n",
       "\n",
       "[10077 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//***************************************************************************\n",
    "#//***************************************************************************\n",
    "#//*** Scrape All Stories For the Given Quarter and export to XLS\n",
    "#//***************************************************************************\n",
    "#//***************************************************************************\n",
    "qtr_df = pd.DataFrame()\n",
    "for date in all_rundowns_df['start_date'].unique():\n",
    "    one_day_df = all_rundowns_df[all_rundowns_df['start_date'] == date]\n",
    "    print(date, \"/\", all_rundowns_df['start_date'].unique()[-1])\n",
    "    for row in one_day_df.iterrows():\n",
    "        loop_rundown = row[1]\n",
    "        loop_title_id = loop_rundown['title_id']\n",
    "        #print(\"Rundown ID: \", loop_title_id, loop_rundown['title'])\n",
    "\n",
    "        #print(loop_rundown)\n",
    "        #//*** Get the Blocks associated with the Selected Rundown\n",
    "        query = f\"\"\"\n",
    "        SELECT block_id\n",
    "        FROM items \n",
    "\n",
    "        WHERE clock_id = '{loop_title_id}'\n",
    "        \"\"\"\n",
    "        loop_blocks = pd.read_sql(query,cnxn)['block_id'].unique()\n",
    "\n",
    "        #//*** Find the A-Block of Selected Rundown\n",
    "        #//**** Block Query gets just the A BLOCK from the Rundown Block\n",
    "        #//*** Combines all Blocks into a single query and returns only the A-Block\n",
    "        block_query = \"\"\n",
    "        for block_id in loop_blocks:\n",
    "            if block_id == loop_blocks[0]:\n",
    "                block_query += f\"(block_id='{block_id}' \"\n",
    "            else:\n",
    "                block_query += f\"OR block_id='{block_id}' \"\n",
    "        block_query += \") AND title='A BLOCK'\"\n",
    "\n",
    "        query = f\"\"\"\n",
    "        SELECT *\n",
    "        FROM blocks \n",
    "        WHERE {block_query}\n",
    "        \"\"\"\n",
    "\n",
    "        tdf = pd.read_sql(query,cnxn)\n",
    "        #//*** A Block of Selected Rundown\n",
    "        if len(tdf) == 0:\n",
    "            print(\"================\")\n",
    "            print(\"NO A-Block Found\")\n",
    "            print(\"================\")\n",
    "            print(one_day_df)\n",
    "            continue\n",
    "\n",
    "        a_block = tdf[\"block_id\"].values[0]\n",
    "        #print(\"A Block:\",a_block)\n",
    "\n",
    "        #//******************************\n",
    "        #//*** Get A-Block Story Titles \n",
    "        #//******************************\n",
    "        query = f\"\"\"\n",
    "        SELECT title_id\n",
    "        --SELECT block_id,item_id,title_id\n",
    "        FROM spots \n",
    "        WHERE block_id = '{a_block}'\n",
    "        \"\"\"\n",
    "\n",
    "        title_id_list = pd.read_sql(query,cnxn)['title_id'].values\n",
    "\n",
    "\n",
    "        #//****************************************************\n",
    "        #//*** Get title_id, Story Slug, and Duration\n",
    "        #//*** Only get Stories with Greater than 0 Duration\n",
    "        #//****************************************************\n",
    "\n",
    "        #//*** Build Single Query to get all Titles from Selected Rundown\n",
    "\n",
    "        title_id_query = \"\"\n",
    "        for title_id in title_id_list:\n",
    "            if title_id == title_id_list[0]:\n",
    "                title_id_query += f\"title_id='{title_id}' \"\n",
    "            else:\n",
    "                title_id_query += f\"OR title_id='{title_id}' \"\n",
    "\n",
    "        query = f\"\"\"\n",
    "        SELECT title_id,title_type_id,title,duration\n",
    "        FROM titles \n",
    "        WHERE {title_id_query}\n",
    "        \"\"\"\n",
    "\n",
    "        titles_df = pd.read_sql(query,cnxn)\n",
    "\n",
    "        #//*** Remove Stories with Zero Duration\n",
    "        #//*** This Removes stories with no text\n",
    "        titles_df = titles_df[titles_df['duration'] > 0]\n",
    "\n",
    "        #//*** Remove stories with the word tease in slug\n",
    "        titles_df = titles_df[titles_df['title'].str.lower().str.contains('tease') == False]\n",
    "        #print(titles_df)\n",
    "        #//*** Get StoryBody Text\n",
    "        story_id_list = titles_df['title_id'].values\n",
    "        story_id_query = \"\"\n",
    "        for story_id in story_id_list:\n",
    "            if story_id == story_id_list[0]:\n",
    "                story_id_query += f\"TitleId='{story_id}' \"\n",
    "            else:\n",
    "                story_id_query += f\"OR TitleId='{story_id}' \"\n",
    "\n",
    "        query = f\"\"\"\n",
    "        SELECT TitleId,StoryText\n",
    "        FROM StoryContent\n",
    "        WHERE {story_id_query}\n",
    "        \"\"\"\n",
    "\n",
    "        text_df = pd.read_sql(query,cnxn)\n",
    "        #print(text_df)\n",
    "\n",
    "        #//*** Build Stories_df List of all Stories in show with Text and Title\n",
    "        #//*** Merge titles_df and text_df \n",
    "        stories_df = titles_df.merge(text_df,left_on='title_id',right_on='TitleId')\n",
    "\n",
    "        #//*** Delete the duplicate column\n",
    "        del stories_df['TitleId']\n",
    "\n",
    "        #//********************\n",
    "        #//*** Clean the Text\n",
    "        #//********************\n",
    "\n",
    "        #//*** Remove Brackets [[ ]]\n",
    "        stories_df['StoryText'] = stories_df['StoryText'].str.replace('\\[\\[\\*\\*\\*.*?\\*\\*\\*\\]\\]','\\\\n',regex=True)\n",
    "\n",
    "        #//*** Remove paranthesis (( ))\n",
    "        stories_df['StoryText'] = stories_df['StoryText'].str.replace('\\(\\(.*?\\)\\)','\\\\n',regex=True)\n",
    "\n",
    "        #//*** Covert \\r\\n to \\n\n",
    "        stories_df['StoryText'] = stories_df['StoryText'].str.replace('\\\\r\\\\n','\\\\n',regex=True)\n",
    "\n",
    "        #//*** Convert Multiple \\n to single \\n\n",
    "        stories_df['StoryText'] = stories_df['StoryText'].str.replace('\\\\n\\\\W*\\\\n','\\\\n',regex=True)\n",
    "\n",
    "        #//*** Delete leading \\n\n",
    "        stories_df['StoryText'] = stories_df['StoryText'].str.replace('^\\\\W*\\\\n','',regex=True)\n",
    "        #print(stories_df.iloc[7]['StoryText'])\n",
    "\n",
    "        #//*** Rename title column to storyslug\n",
    "        stories_df.columns = ['storyslug' if x=='title' else x for x in list(stories_df.columns)]\n",
    "\n",
    "\n",
    "        #//*** Start Date, Title, from the current rundown. This Column will have the same value for all rows.\n",
    "        static_cols = ['start_date','title']\n",
    "\n",
    "        for col in static_cols:\n",
    "            stories_df[col] = loop_rundown[col]\n",
    "\n",
    "        #//*** Shift the static_cols to the beginning of the column list for readability\n",
    "        cols = (static_cols + list(stories_df.columns))[:(len(static_cols)*-1)]\n",
    "\n",
    "        stories_df = stories_df[cols]\n",
    "\n",
    "\n",
    "        #//*** Rename title column to storyslug\n",
    "        stories_df.columns = ['rundown' if x=='title' else x for x in list(stories_df.columns)]\n",
    "\n",
    "\n",
    "        #print(cols)\n",
    "        #print(stories_df)\n",
    "        qtr_df = pd.concat([qtr_df,stories_df],ignore_index=True)\n",
    "        #//*** End Get Single Rundown Stories\n",
    "    \n",
    "    #//*** End Each Day of Rundowns\n",
    "\n",
    "#//*** Remove Stories with 0 length Text\n",
    "qtr_df['StoryText'] = qtr_df['StoryText'].astype(str)\n",
    "qtr_df['length'] = qtr_df['StoryText'].apply(lambda x : len(x))\n",
    "qtr_df = qtr_df[qtr_df['length'] > 20]\n",
    "\n",
    "if 'title_type_id' in qtr_df.columns:\n",
    "    del qtr_df['title_type_id']\n",
    "    \n",
    "if 'length' in qtr_df.columns:\n",
    "    del qtr_df['length']\n",
    "tdf = qtr_df\n",
    "tdf['duration'] = (tdf['duration'] /1000).astype(int)    \n",
    "\n",
    "#qtr_df.to_csv(\"2021_Q4_Stories.csv\")  \n",
    "\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(f'{tgt_year}_{quarter}_Stories.xlsx', engine='xlsxwriter')\n",
    "qtr_df.to_excel(writer,sheet_name='sheet1')\n",
    "writer.save()\n",
    "\n",
    "qtr_df\n",
    "#print(\"Done\")\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "qtr_df = pd.read_excel(f'{tgt_year}_{quarter}_Stories.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "qtr_df = pd.read_excel(f'{tgt_year}_{quarter}_Stories.xlsx')\n",
    "\n",
    "#//*** Trim unnamed First Column (original Index)\n",
    "del qtr_df[qtr_df.columns[0]]\n",
    "\n",
    "print(f\"Begin tfidf....\")\n",
    "start_time = time.time()\n",
    "#tfidf = TfidfVectorizer(ngram_range=(1,3),max_features=10000)\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,1), stop_words={'english'},)\n",
    "tfidf_matrix = tfidf.fit_transform(qtr_df['StoryText'])\n",
    "print(f\"tfidf Built: {round(time.time()-start_time,2)}s\")\n",
    "\n",
    "\n",
    "qtr_df = pd.merge(qtr_df, pd.DataFrame(tfidf_matrix,columns=[\"tfidf\"]), left_index=True, right_index=True)\n",
    "qtr_df\n",
    "\n",
    "#all_text = remove_stop_words(tokenize_series(mr_clean_text(pd.Series( ' '.join(list(qtr_df[\"StoryText\"]))))))\n",
    "\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5962005\n",
      "5021119\n",
      "                                  TF-IDF\n",
      "and wherever you stream         0.281582\n",
      "hulu live and wherever          0.268408\n",
      "live and wherever you           0.268408\n",
      "abc hulu live and               0.267997\n",
      "on abc hulu live                0.267997\n",
      "you re watchg abc               0.194308\n",
      "re watchg abc news              0.139968\n",
      "watchg abc news at              0.135439\n",
      "here on abc hulu                0.105387\n",
      "abc dot com slash               0.081510\n",
      "dot com slash vacce             0.080275\n",
      "more an ousand acres            0.070395\n",
      "dot com slash vote              0.067925\n",
      "abc news dot com                0.067514\n",
      "news reporter cornell barnard   0.062162\n",
      "abc news reporter cornell       0.061339\n",
      "sze you re watchg               0.055987\n",
      "krt sze you re                  0.055575\n",
      "abc morngs on abc               0.054340\n",
      "re watchg abc morngs            0.054340\n",
      "watchg abc morngs on            0.054340\n",
      "morngs on abc hulu              0.054340\n",
      "if you have questions           0.051047\n",
      "re watchg mid live              0.049400\n",
      "you re watchg mid               0.049400\n",
      "you have questions about        0.048577\n",
      "dan ashley you re               0.046930\n",
      "ashley you re watchg            0.046930\n",
      "news reporter stephanie sierra  0.046930\n",
      "abc news reporter stephanie     0.046930\n",
      "watchg mid live on              0.045695\n",
      "live on abc hulu                0.045695\n",
      "mid live on abc                 0.045695\n",
      "five here on abc                0.045284\n",
      "news at five here               0.044872\n",
      "at five here on                 0.044872\n",
      "abc news at five                0.044872\n",
      "abc news at six                 0.040344\n",
      "wherever you stream we          0.039932\n",
      "wherever you stream let         0.039109\n",
      "good evg ama daetz              0.038285\n",
      "vacces you can ask              0.038285\n",
      "burned more an ousand           0.037874\n",
      "go dot com slash                0.037050\n",
      "evg ama daetz and               0.036639\n",
      "abc news reporter amy           0.033757\n",
      "abc news vacce team             0.033757\n",
      "news reporter amy hollyfield    0.033345\n",
      "and krt sze you                 0.032934\n",
      "ama daetz and dan               0.032934\n",
      "daetz and dan ashley            0.032934\n",
      "you can ask abc                 0.032110\n",
      "has burned more an              0.031699\n",
      "have questions about covid      0.030875\n",
      "six here on abc                 0.030464\n",
      "can ask abc news                0.030464\n",
      "at six here on                  0.030464\n",
      "news at six here                0.030464\n",
      "news reporter dust dorsey       0.030464\n",
      "ask abc news vacce              0.030464\n",
      "questions about covid vacces    0.030052\n",
      "slash vacce and click           0.030052\n",
      "com slash vacce and             0.030052\n",
      "vacce and click on              0.030052\n",
      "ad lib wear ad                  0.030052\n",
      "lib wear ad lib                 0.030052\n",
      "part our vacce team             0.029640\n",
      "abc news reporter dust          0.029640\n",
      "webse abc news dot              0.029229\n",
      "our webse abc news              0.029229\n",
      "you stream we re                0.028817\n",
      "and dan ashley you              0.028405\n",
      "dion you re watchg              0.028405\n",
      "news reporter melanie woodrow   0.028405\n",
      "abc news reporter melanie       0.028405\n"
     ]
    }
   ],
   "source": [
    "all_text =pd.Series(( ' '.join(list(qtr_df[\"StoryText\"]))))\n",
    "\n",
    "custom_stop_words = ['quote','the','abc7','news','new',\n",
    "                     'to','get','live','say','says','be','bay','be','0','1','2','3','4','5','6','7','8','9',\n",
    "                     'day','is','in','en','are','th','of','im','it','sot','not','that','reporter'\n",
    "                    ]\n",
    "#custom_stop_words = []\n",
    "print(len(all_text[0]))\n",
    "for word in custom_stop_words:\n",
    "    all_text[0] = all_text[0].replace(word, '')\n",
    "\n",
    "print(len(all_text[0]))\n",
    "\n",
    "#tfidf = TfidfVectorizer(ngram_range=(1,3),max_features=10000)\n",
    "#tfIdfVectorizer=TfidfVectorizer(ngram_range=(1,3),use_idf=True)\n",
    "tfIdfVectorizer=TfidfVectorizer(ngram_range=(4,4),use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(all_text)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672942\n",
      "Index(['sot adrienne bechelli deputy director for emergency services sfdem 00',\n",
      "       'back this year across the bay area abc7 news reporter',\n",
      "       'epidemiologist who explains why you should keep it on in',\n",
      "       'team and spoke to ucsf epidemiologist who explains why you',\n",
      "       'and spoke to ucsf epidemiologist who explains why you should',\n",
      "       'spoke to ucsf epidemiologist who explains why you should keep',\n",
      "       'explains why you should keep it on in some cases',\n",
      "       'year across the bay area abc7 news reporter matt boone',\n",
      "       'who explains why you should keep it on in some',\n",
      "       'our vaccine team and spoke to ucsf epidemiologist who explains',\n",
      "       'to ucsf epidemiologist who explains why you should keep it',\n",
      "       'part of our vaccine team and spoke to ucsf epidemiologist',\n",
      "       'ucsf epidemiologist who explains why you should keep it on',\n",
      "       'fireworks are back this year across the bay area abc7',\n",
      "       'of our vaccine team and spoke to ucsf epidemiologist who',\n",
      "       'this year across the bay area abc7 news reporter matt',\n",
      "       'are back this year across the bay area abc7 news',\n",
      "       'vaccine team and spoke to ucsf epidemiologist who explains why',\n",
      "       'is part of our vaccine team and spoke to ucsf',\n",
      "       'fourth of july lots of people excited to come to',\n",
      "       'care providers are preparing for busy weekend the consumer product',\n",
      "       'bay area connected app download it now for your apple',\n",
      "       'goal is to make sure everyone is safe who come',\n",
      "       'product safety commission just released report saying fireworks related injuries',\n",
      "       'the east bay would receive less service than san francisco',\n",
      "       'safe who come for the fourth of july lots of',\n",
      "       'of july lots of people excited to come to san',\n",
      "       'your apple tv android tv amazon fire tv or roku',\n",
      "       'area connected app download it now for your apple tv',\n",
      "       'that the east bay would receive less service than san',\n",
      "       'providers are preparing for busy weekend the consumer product safety',\n",
      "       'busy weekend the consumer product safety commission just released report',\n",
      "       'called total recalled on our abc7 bay area connected app',\n",
      "       'it unacceptable that the east bay would receive less service',\n",
      "       'is safe who come for the fourth of july lots',\n",
      "       'our goal is to make sure everyone is safe who',\n",
      "       'abc7 bay area connected app download it now for your',\n",
      "       'come for the fourth of july lots of people excited',\n",
      "       'everyone is safe who come for the fourth of july',\n",
      "       'consumer product safety commission just released report saying fireworks related',\n",
      "       'connected app download it now for your apple tv android',\n",
      "       'on our abc7 bay area connected app download it now',\n",
      "       'unacceptable that the east bay would receive less service than',\n",
      "       'weekend the consumer product safety commission just released report saying',\n",
      "       'preparing for busy weekend the consumer product safety commission just',\n",
      "       'health care providers are preparing for busy weekend the consumer',\n",
      "       'download it now for your apple tv android tv amazon',\n",
      "       'for your apple tv android tv amazon fire tv or',\n",
      "       'professional fireworks displays as opposed to putting on their own',\n",
      "       'attend professional fireworks displays as opposed to putting on their',\n",
      "       'for busy weekend the consumer product safety commission just released',\n",
      "       'think it unacceptable that the east bay would receive less',\n",
      "       'to make sure everyone is safe who come for the',\n",
      "       'total recalled on our abc7 bay area connected app download',\n",
      "       'recall called total recalled on our abc7 bay area connected',\n",
      "       'july lots of people excited to come to san francisco',\n",
      "       'app download it now for your apple tv android tv',\n",
      "       'safety commission just released report saying fireworks related injuries and',\n",
      "       'our abc7 bay area connected app download it now for',\n",
      "       'make sure everyone is safe who come for the fourth',\n",
      "       'injuries take sot yvonne karanas santa clara valley medical center',\n",
      "       'are preparing for busy weekend the consumer product safety commission',\n",
      "       'is to make sure everyone is safe who come for',\n",
      "       'to attend professional fireworks displays as opposed to putting on',\n",
      "       'says she has seen too many people come into the',\n",
      "       'for the fourth of july lots of people excited to',\n",
      "       'it now for your apple tv android tv amazon fire',\n",
      "       'the consumer product safety commission just released report saying fireworks',\n",
      "       'sure everyone is safe who come for the fourth of',\n",
      "       'who come for the fourth of july lots of people',\n",
      "       'commission just released report saying fireworks related injuries and deaths',\n",
      "       'recalled on our abc7 bay area connected app download it',\n",
      "       'the fourth of july lots of people excited to come',\n",
      "       'now for your apple tv android tv amazon fire tv',\n",
      "       'jumping cornhole and even axe throwing and as part of',\n",
      "       'service for fans who want to stay for the post',\n",
      "       'on abc7 news com fewer than dozen bay area cities',\n",
      "       'like tonight fireworks shows should we be wearing mask abc7',\n",
      "       'the rise the mayor is urging visitors to keep valuables',\n",
      "       'city hall starting at this morning the festival runs from',\n",
      "       'its fireworks show sunday night it could draw 100 thousand',\n",
      "       'ahead of tonight game at the coliseum it over lack',\n",
      "       'abc7 news if you don want to deal with traffic',\n",
      "       'it requires lot of extra staffing you can still take',\n",
      "       'francisco and the south bay and sf bay ferry will',\n",
      "       'embarcadero station at 10 40 caltrain will also offer late',\n",
      "       'blanket and stuffed cat means anything to the person who',\n",
      "       'who plan on watching the fireworks in san francisco bus',\n",
      "       'vote by mail ballot which counties will send out in',\n",
      "       'told abc7 news reporter stone it frustrating because bart provided',\n",
      "       'provided special service for the giants fireworks show last week',\n",
      "       'fans who want to stay for the post game fireworks',\n",
      "       'of visitors this 4th of july weekend the city is',\n",
      "       'event service for fans who want to stay for the',\n",
      "       'transit because it doesn have enough parking the ended up',\n",
      "       'anything to the person who stole it return it please',\n",
      "       'matt boone has look at what crews are doing to',\n",
      "       'times on abc7 news com fewer than dozen bay area',\n",
      "       'abc7 news reporter matt boone joins us live at sfo',\n",
      "       'about why the timing could be good news for the'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "qtr_df = pd.read_excel(f'{tgt_year}_{quarter}_Stories.xlsx')\n",
    "\n",
    "#//*** Trim unnamed First Column (original Index)\n",
    "del qtr_df[qtr_df.columns[0]]\n",
    "\n",
    "qtr_df = qtr_df[qtr_df['StoryText'].str.lower().str.contains(\"major fires across the state and track\")==False]\n",
    "\n",
    "#all_text =pd.Series(( ' '.join(list(qtr_df[\"StoryText\"]))))\n",
    "all_text = []\n",
    "\n",
    "ngrams = 10\n",
    "\n",
    "custom_stop_words = ['sot in person interview', '0','1','2','3','4','5','6','7','8','9','\\'','\"','\\n','\\t',',','.',',','-',':',\n",
    "                    'sot in person', ]\n",
    "custom_stop_words = []\n",
    "\n",
    "for group in qtr_df.groupby('start_date'):\n",
    "    loop_text = ' '.join(list(group[1]['StoryText']))\n",
    "    \n",
    "    for word in custom_stop_words:\n",
    "        loop_text = loop_text.replace(word,\" \")\n",
    "    \n",
    "    all_text.append(loop_text)\n",
    "    \n",
    "tfIdfVectorizer=TfidfVectorizer(ngram_range=(ngrams,ngrams),use_idf=True,smooth_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(all_text)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print(len(df))\n",
    "print (df[:100].index)\n",
    "#print (df[1000:1100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9272\n",
      "                        TF-IDF\n",
      "holiday travel        0.318003\n",
      "fireworks transit     0.214538\n",
      "july eve              0.196563\n",
      "fourth covid          0.196563\n",
      "covid concern         0.183810\n",
      "breed waterfront      0.178782\n",
      "sfo holiday           0.178782\n",
      "fireworks concerns    0.143025\n",
      "coco fireworks        0.131042\n",
      "travel holiday        0.131042\n",
      "recall ctv            0.122540\n",
      "taylor swift          0.107269\n",
      "eve july              0.107269\n",
      "as fireworks          0.107269\n",
      "rental car            0.107269\n",
      "newsom total          0.107269\n",
      "fireworks illegal     0.107269\n",
      "swift deputy          0.107269\n",
      "bayview intersection  0.107269\n",
      "total recall          0.107269\n",
      "oakland as            0.107269\n",
      "recall newsom         0.102055\n",
      "fireworks demo        0.098282\n",
      "hmb parade            0.098282\n",
      "retail crime          0.098282\n",
      "other fireworks       0.098282\n",
      "concern fourth        0.098282\n",
      "fireworks web         0.098282\n",
      "gg ferries            0.091905\n",
      "sf fireworks          0.091905\n",
      "delta variant         0.091905\n",
      "illegal fireworks     0.086959\n",
      "sf retail             0.086959\n",
      "parade other          0.071513\n",
      "variant gatherings    0.071513\n",
      "concern gg            0.071513\n",
      "kaval dispute         0.071513\n",
      "delta protection      0.071513\n",
      "car waits             0.071513\n",
      "intersection bayview  0.071513\n",
      "emeryville traffic    0.071513\n",
      "military leaves       0.071513\n",
      "lyanne coco           0.071513\n",
      "fireworks concern     0.071513\n",
      "leaves bagram         0.071513\n",
      "ferries hmb           0.071513\n",
      "us military           0.071513\n",
      "fireworks rental      0.071513\n",
      "bart kaval            0.071513\n",
      "eve fourth            0.071513\n",
      "fireworks safety      0.071513\n",
      "jose fireworks        0.071513\n",
      "waits holiday         0.071513\n",
      "jj vax                0.071513\n",
      "san jose              0.067554\n",
      "aggressive coyotes    0.065521\n",
      "travel sfo            0.065521\n",
      "crime sf              0.065521\n",
      "vax delta             0.065521\n",
      "expensive gas         0.065521\n",
      "4th of                0.061270\n",
      "of july               0.061270\n",
      "gov recall            0.061270\n",
      "bay fireworks         0.055278\n",
      "open 5atoss           0.051027\n",
      "5acold open           0.043853\n",
      "cold open             0.036943\n",
      "questions gas         0.035756\n",
      "car prices            0.035756\n",
      "stop recall           0.035756\n",
      "sj 87                 0.035756\n",
      "deputy bart           0.035756\n",
      "changes vax           0.035756\n",
      "deputy taylor         0.035756\n",
      "deputy valleo         0.035756\n",
      "charges oakland       0.035756\n",
      "jobina jj             0.035756\n",
      "emeryville lyanne     0.035756\n",
      "txl sfo               0.035756\n",
      "intersection taylor   0.035756\n",
      "protection weather    0.035756\n",
      "collapse fourth       0.035756\n",
      "mannys reopening      0.035756\n",
      "fireworks recall      0.035756\n",
      "parade july           0.035756\n",
      "florida building      0.035756\n",
      "fireworks ice         0.035756\n",
      "concern oakland       0.035756\n",
      "concerns delta        0.035756\n",
      "party free            0.035756\n",
      "concerns cold         0.035756\n",
      "magic makers          0.035756\n",
      "concerns bayview      0.035756\n",
      "open breed            0.035756\n",
      "street closure        0.035756\n",
      "concern trump         0.035756\n",
      "concern mannys        0.035756\n",
      "demo sfo              0.035756\n",
      "eve gg                0.035756\n",
      "service delta         0.035756\n",
      "                        TF-IDF\n",
      "makers cold           0.035756\n",
      "prices dui            0.035756\n",
      "road trip             0.035756\n",
      "us leaves             0.035756\n",
      "fireworks coco        0.035756\n",
      "rides 5acold          0.035756\n",
      "concerns fireworks    0.035756\n",
      "and cornell           0.035756\n",
      "acold us              0.035756\n",
      "tax vax               0.035756\n",
      "demo holiday          0.035756\n",
      "open 4th              0.035756\n",
      "demo coco             0.035756\n",
      "gas rental            0.035756\n",
      "87 traffic            0.035756\n",
      "target 3oc            0.035756\n",
      "gas tax               0.035756\n",
      "ctv transit           0.035756\n",
      "target hours          0.035756\n",
      "lyanne fireworks      0.035756\n",
      "gathering 3oc         0.035756\n",
      "cargo plane           0.035756\n",
      "gatherings delta      0.035756\n",
      "carri 3oc             0.035756\n",
      "tossweather stop      0.035756\n",
      "gatherings gov        0.035756\n",
      "fireworks florida     0.035756\n",
      "capitol covid         0.035756\n",
      "dispute recall        0.035756\n",
      "crime lyanne          0.035756\n",
      "shooting bart         0.035756\n",
      "3oc 4pm               0.035756\n",
      "transit recall        0.035756\n",
      "transit jobina        0.035756\n",
      "3oc gathering         0.035756\n",
      "transit fireworks     0.035756\n",
      "3oc sha               0.035756\n",
      "recall emeryville     0.035756\n",
      "transit changes       0.035756\n",
      "transit 4th           0.035756\n",
      "crash map             0.035756\n",
      "valleo shooting       0.035756\n",
      "matt cargo            0.035756\n",
      "train target          0.035756\n",
      "matt sf               0.035756\n",
      "matt sfo              0.035756\n",
      "recall fireworks      0.035756\n",
      "trip fireworks        0.035756\n",
      "force air             0.035756\n",
      "closure gov           0.035756\n",
      "exploratorium disney  0.035756\n",
      "transit rides         0.035756\n",
      "transit sf            0.035756\n",
      "transit us            0.035756\n",
      "fire thrive           0.035756\n",
      "travel emeryville     0.035756\n",
      "travel gas            0.035756\n",
      "travel coliseum       0.035756\n",
      "travel cold           0.035756\n",
      "travel jj             0.035756\n",
      "travel breed          0.035756\n",
      "july july             0.035756\n",
      "coyotes capitol       0.035756\n",
      "coyotes aggressive    0.035756\n",
      "july road             0.035756\n",
      "masks exploratorium   0.035756\n",
      "travel 5acold         0.035756\n",
      "ferries other         0.035756\n",
      "reopening acold       0.035756\n",
      "leaves afghanistan    0.035756\n",
      "shooting live         0.035756\n",
      "variant sf            0.035756\n",
      "recall candidates     0.035756\n",
      "jose traffic          0.035756\n",
      "johnson breed         0.035756\n",
      "toll traffic          0.035756\n",
      "trump org             0.035756\n",
      "thrive party          0.035756\n",
      "web sfo               0.035756\n",
      "web street            0.035756\n",
      "5pcoldopen fireworks  0.035756\n",
      "ctv aggressive        0.035756\n",
      "ctv breed             0.035756\n",
      "waterfront oakland    0.035756\n",
      "waterfront jobina     0.035756\n",
      "cases vallejo         0.035756\n",
      "dispute bart          0.035756\n",
      "waterfront fireworks  0.035756\n",
      "traffic travel        0.035756\n",
      "waterfront breed      0.035756\n",
      "sfo lava              0.035756\n",
      "disney magic          0.035756\n",
      "waterfront and        0.035756\n",
      "map target            0.035756\n",
      "bagram weather        0.035756\n",
      "bagram cold           0.035756\n",
      "ctv matt              0.035756\n",
      "candidates lyanne     0.035756\n",
      "jobina us             0.035756\n",
      "sha carri             0.035756\n"
     ]
    }
   ],
   "source": [
    "qtr_df = pd.read_excel(f'{tgt_year}_{quarter}_Stories.xlsx')\n",
    "\n",
    "#//*** Trim unnamed First Column (original Index)\n",
    "del qtr_df[qtr_df.columns[0]]\n",
    "\n",
    "qtr_df = qtr_df[qtr_df['StoryText'].str.lower().str.contains(\"major fires across the state and track\")==False]\n",
    "\n",
    "#all_text =pd.Series(( ' '.join(list(qtr_df[\"StoryText\"]))))\n",
    "all_text = []\n",
    "\n",
    "ngrams = 2\n",
    "\n",
    "custom_stop_words = ['sot in person interview', '0','1','2','3','4','5','6','7','8','9','\\'','\"','\\n','\\t',',','.',',','-',':',\n",
    "                    'sot in person', ]\n",
    "custom_stop_words = ['4p','5a','5p','6a','6p','8a','8p','9a','9p','11a','11p',\n",
    "                     'anchor','acoldopen',\n",
    "                     'coldopen',\n",
    "                     \n",
    "                     'fs','fr','frames','fls','fr1',\n",
    "                     'hello',\n",
    "                     'int','intro',\n",
    "                     'liz',\n",
    "                     'oc',\n",
    "                     'pkg','preshow','qa1',\n",
    "                     'ra','rem',\n",
    "                     'setup','sotvo','sv','sv1',\n",
    "                     'toss','tag','t1',\n",
    "                     'update',\n",
    "                     'vo',\n",
    "                     'wrap',\n",
    "                    ]\n",
    "remove_characters = [\"-\",\":\",\"\\xa0\",\"+\"]\n",
    "all_text = []\n",
    "\n",
    "for group in qtr_df.groupby('start_date'):\n",
    "    loop_text = ' '.join(list(group[1]['storyslug'])).lower().split(\" \")\n",
    "\n",
    "    for word in loop_text:\n",
    "        for find in remove_characters:\n",
    "            if find in word:\n",
    "                #print(find,word)\n",
    "                loop_text.remove(word)\n",
    "            \n",
    "    \n",
    "    for word in custom_stop_words:\n",
    "        while word in loop_text:\n",
    "            loop_text.remove(word)\n",
    "        \n",
    "    loop_text = ' '.join(loop_text)\n",
    "    all_text.append(loop_text)\n",
    "    \n",
    "tfIdfVectorizer=TfidfVectorizer(ngram_range=(2,2),use_idf=True,smooth_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(all_text)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print(len(df))\n",
    "print (df[:100])\n",
    "print (df[100:200])\n",
    "#print (df[1000:1100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vax 383\n",
      "fire 372\n",
      "covid 332\n",
      "weather 214\n",
      "recall 181\n",
      "sf 177\n",
      "amy 154\n",
      "cold 153\n",
      "afghanistan 132\n",
      "newsom 128\n",
      "vaccine 122\n",
      "masks 120\n",
      "open 119\n",
      "jobina 119\n",
      "t1 109\n",
      "caldor 108\n",
      "booster 107\n",
      "school 107\n",
      "questions 99\n",
      "web 98\n",
      "webpc 98\n",
      "biden 97\n",
      "oakland 90\n",
      "wildfire 90\n",
      "coronavirus 90\n",
      "bay 88\n",
      "stephanie 87\n",
      "fireworks 85\n",
      "acold 85\n",
      "wx 85\n",
      "mask 84\n",
      "ca 81\n",
      "dixie 80\n",
      "latest 80\n",
      "mandate 79\n",
      "sj 76\n",
      "ctv 72\n",
      "and 70\n",
      "san 69\n",
      "oak 68\n",
      "delta 67\n",
      "tahoe 67\n",
      "boosters 66\n",
      "headlines 66\n",
      "schools 65\n",
      "wildfires 63\n",
      "cornell 60\n",
      "travel 59\n",
      "shooting 58\n",
      "smoke 58\n",
      "air 53\n",
      "first 52\n",
      "search 51\n",
      "vaccines 51\n",
      "marin 50\n",
      "lyanne 49\n",
      "reax 49\n",
      "txl 48\n",
      "phil 48\n",
      "afghan 47\n",
      "theft 47\n",
      "testing 47\n",
      "crime 46\n",
      "drought 46\n",
      "tracker 46\n",
      "kate 45\n",
      "quake 45\n",
      "atg 45\n",
      "atoss 45\n",
      "5pcoldopen 44\n",
      "theranos 44\n",
      "water 43\n",
      "fires 43\n",
      "ida 43\n",
      "variant 42\n",
      "coco 41\n",
      "map 40\n",
      "sot 40\n",
      "pleasanton 39\n",
      "east 39\n",
      "cdc 39\n",
      "shot 39\n",
      "gov 38\n",
      "help 38\n",
      "coverage 38\n",
      "bart 37\n",
      "giants 37\n",
      "back 36\n",
      "napa 35\n",
      "push 35\n",
      "luz 35\n",
      "pfizer 34\n",
      "vote 34\n",
      "studio 33\n",
      "new 33\n",
      "elsa 33\n",
      "5atoss 32\n",
      "cases 32\n",
      "team 32\n",
      "dr 32\n",
      "county 32\n",
      "sfusd 31\n",
      "wayne 31\n",
      "elder 30\n",
      "proof 30\n",
      "return 30\n",
      "shots 30\n",
      "breed 29\n",
      "psps 29\n",
      "fda 29\n",
      "shoot 29\n",
      "violence 29\n",
      "santa 29\n",
      "warning 29\n",
      "alert 29\n",
      "ax 29\n",
      "la 28\n",
      "lightning 28\n",
      "vs 28\n",
      "poll 27\n",
      "viewer 27\n",
      "sonoma 27\n",
      "opd 27\n",
      "haiti 27\n",
      "vta 26\n",
      "drew 26\n",
      "laura 26\n",
      "action 26\n",
      "car 25\n",
      "traffic 25\n",
      "day 25\n",
      "howard 25\n",
      "local 25\n",
      "health 25\n",
      "lake 25\n",
      "antioch 25\n",
      "mandates 25\n",
      "heat 25\n",
      "terminal 25\n",
      "5acold 24\n",
      "quality 24\n",
      "7p 24\n",
      "rally 24\n",
      "to 24\n",
      "kids 24\n",
      "ousd 24\n",
      "park 24\n",
      "5pm 24\n",
      "crash 23\n",
      "hospital 23\n",
      "breakthrough 23\n",
      "patel 23\n",
      "fourth 22\n",
      "of 22\n",
      "service 22\n",
      "tossweather 22\n",
      "climate 22\n",
      "pge 22\n",
      "strike 22\n",
      "special 21\n",
      "election 21\n",
      "kid 21\n",
      "aco 21\n",
      "business 21\n",
      "leslie 21\n",
      "power 21\n",
      "sfo 20\n",
      "hall 20\n",
      "hwy 20\n",
      "voting 20\n",
      "flex 20\n",
      "roots 20\n",
      "closed 20\n",
      "outage 20\n",
      "natl 20\n",
      "outages 20\n",
      "appts 20\n",
      "july 19\n"
     ]
    }
   ],
   "source": [
    "freq = {}\n",
    "\n",
    "for word in ' '.join(list(df.index)).split(' '):\n",
    "    if word in freq.keys():\n",
    "        freq[word] += 1\n",
    "    else:\n",
    "        freq[word] = 1\n",
    "\n",
    "#sorted(month, key=numbermap.__getitem__)\n",
    "\n",
    "reverseDict = {}\n",
    "for key in sorted(freq, key=freq.get, reverse=True):\n",
    "    print(key,freq[key])\n",
    "    if freq[key] < 20:\n",
    "        break\n",
    "    #oldKey_newValue = key\n",
    "    #newKey_oldValue = input_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fire 729\n",
      "vax 686\n",
      "covid 513\n",
      "open 284\n",
      "weather 255\n",
      "cold 248\n",
      "recall 230\n",
      "sf 225\n",
      "first 216\n",
      "studio 197\n",
      "school 193\n",
      "bay 177\n",
      "afghanistan 170\n",
      "caldor 170\n",
      " 159\n",
      "questions 158\n",
      "newsom 156\n",
      "amy 156\n",
      "traffic 151\n",
      "masks 150\n",
      "wx 149\n",
      "dixie 143\n",
      "latest 141\n",
      "vaccine 133\n",
      "wildfire 131\n",
      "booster 129\n",
      "tracker 128\n",
      "mandate 120\n",
      "webpc 119\n",
      "headlines 117\n",
      "mask 115\n",
      "tahoe 111\n",
      "web 109\n",
      "jobina 109\n",
      "and 106\n",
      "fireworks 98\n",
      "to 96\n",
      "ca 94\n",
      "boosters 87\n",
      "oakland 85\n",
      "san 84\n",
      "biden 83\n",
      "air 82\n",
      "ctv 81\n",
      "stephanie 80\n",
      "smoke 79\n",
      "east 75\n",
      "coronavirus 74\n",
      "of 73\n",
      "sj 73\n",
      "search 73\n",
      "afghan 72\n",
      "testing 71\n",
      "wildfires 70\n",
      "delta 67\n",
      "schools 67\n",
      "top 66\n",
      "pleasanton 64\n",
      "a 63\n",
      "txl 63\n",
      "travel 62\n",
      "q 61\n",
      "marin 61\n",
      "area 59\n",
      "oak 58\n",
      "atg 56\n",
      "acold 55\n",
      "quality 55\n",
      "back 54\n",
      "shooting 53\n",
      "theft 53\n",
      "quad 53\n",
      "1 52\n",
      "pfizer 51\n",
      "ida 51\n",
      "cases 50\n",
      "quake 50\n",
      "q&a 49\n",
      "heat 46\n",
      "coco 45\n",
      "day 45\n",
      "shots 45\n",
      "vaccines 44\n",
      "water 43\n",
      "proof 43\n",
      "5pcoldopen 42\n",
      "map 42\n",
      "giants 41\n",
      "reax 41\n",
      "crime 40\n",
      "fires 40\n",
      "coverage 40\n",
      "county 40\n",
      "help 40\n",
      "peace 39\n",
      "lyanne 38\n",
      "variant 38\n",
      "phil 38\n",
      "dr 38\n",
      "sfusd 38\n",
      "tamarack 38\n",
      "vote 38\n",
      "cornell 37\n",
      "home 37\n",
      "safe 37\n",
      "appts 36\n",
      "gov 35\n",
      "take 35\n",
      "action 35\n",
      "return 34\n",
      "push 34\n",
      "alert 34\n",
      "app 34\n",
      "local 34\n",
      "fda 34\n",
      "cdc 33\n",
      "la 33\n",
      "roots 33\n",
      "team 32\n",
      "viewer 32\n",
      "drought 32\n",
      "new 32\n",
      "breakthrough 32\n",
      "bart 31\n",
      "strike 31\n",
      "ax 31\n",
      "santa 30\n",
      "shot 29\n",
      "howard 29\n",
      "terminal 29\n",
      "election 29\n",
      "virus 29\n",
      "breed 28\n",
      "violence 28\n",
      "warning 28\n",
      "kids 28\n",
      "sot 27\n",
      "mandates 27\n",
      "napa 26\n",
      "vta 26\n",
      "atoss 26\n",
      "vaccinate 26\n",
      "fake 26\n",
      "hospital 26\n",
      "cache 26\n",
      "theranos 26\n",
      "5atoss 25\n",
      "retail 25\n",
      "poll 25\n",
      "luz 25\n",
      "work 25\n",
      "elder 25\n",
      "shoot 25\n",
      "natl 25\n",
      "sites 25\n",
      "haiti 25\n",
      "wayne 25\n",
      "jose 24\n",
      "lake 24\n",
      "patel 24\n",
      "kate 24\n",
      "health 24\n",
      "the 24\n",
      "opd 24\n",
      "tourism 24\n",
      "power 24\n",
      "kid 24\n",
      "outages 24\n",
      "hall 23\n",
      "5acold 23\n",
      "fourth 23\n",
      "elsa 23\n",
      "alameda 23\n",
      "on 23\n",
      "chinatown 23\n",
      "sonoma 23\n",
      "voting 23\n",
      "vs 23\n",
      "surge 23\n",
      "attack 22\n",
      "race 22\n",
      "indoor 22\n",
      "lightning 22\n",
      "bar 22\n",
      "gas 21\n",
      "city 21\n",
      "holiday 21\n",
      "danger 21\n",
      "5pm 21\n",
      "flex 21\n",
      "cal 21\n",
      "park 21\n",
      "rally 21\n",
      "psps 21\n",
      "ousd 21\n",
      "escape 21\n",
      "lafayette 21\n",
      "live 20\n",
      "service 20\n",
      "car 20\n",
      "july 20\n",
      "full 20\n",
      "tossweather 20\n",
      "beckwourth 20\n",
      "antioch 20\n",
      "western 20\n",
      "main 20\n",
      "fawn 20\n",
      "gfx 19\n"
     ]
    }
   ],
   "source": [
    "freq = {}\n",
    "\n",
    "for word in ' '.join(all_text).split(' '):\n",
    "    if word in freq.keys():\n",
    "        freq[word] += 1\n",
    "    else:\n",
    "        freq[word] = 1\n",
    "\n",
    "#sorted(month, key=numbermap.__getitem__)\n",
    "\n",
    "reverseDict = {}\n",
    "for key in sorted(freq, key=freq.get, reverse=True):\n",
    "    print(key,freq[key])\n",
    "    #oldKey_newValue = key\n",
    "    #newKey_oldValue = input_dict[key]\n",
    "    if freq[key] < 20:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19052\n",
      "                                                      TF-IDF\n",
      "july eve july eve fourth covid concern fourth c...  0.098670\n",
      "other fireworks illegal fireworks rental car wa...  0.098670\n",
      "eve july eve fourth covid concern fourth covid ...  0.098670\n",
      "fireworks rental car waits holiday travel holid...  0.098670\n",
      "fireworks illegal fireworks rental car waits ho...  0.098670\n",
      "july eve fourth covid concern fourth covid conc...  0.098670\n",
      "illegal fireworks rental car waits holiday trav...  0.098670\n",
      "traffic sj 87 traffic travel coliseum fireworks...  0.049335\n",
      "stop recall fireworks web sf retail crime sf re...  0.049335\n",
      "covid concern fourth covid concern gg ferries o...  0.049335\n",
      "covid concern fourth covid concern gg ferries h...  0.049335\n",
      "holiday travel sfo holiday travel bay bridge to...  0.049335\n",
      "emeryville traffic sj 87 traffic travel coliseu...  0.049335\n",
      "emeryville traffic san jose traffic matt cargo ...  0.049335\n",
      "emeryville lyanne fireworks concerns cold open ...  0.049335\n",
      "sfo lava fire thrive party free transit rides 5...  0.049335\n",
      "fireworks concerns fireworks concerns delta var...  0.049335\n",
      "fireworks concerns delta variant gatherings del...  0.049335\n",
      "ctv breed waterfront jobina us military leaves ...  0.049335\n",
      "cases vallejo shooting bart service delta varia...  0.049335\n",
      "fireworks concerns cold open breed waterfront b...  0.049335\n",
      "total recall ctv matt sf fireworks transit us l...  0.049335\n",
      "makers cold open fireworks san jose fireworks s...  0.049335\n",
      "total recall ctv breed waterfront jobina us mil...  0.049335\n",
      "prices dui task force air travel sfo lava fire ...  0.049335\n",
      "total recall ctv aggressive coyotes aggressive ...  0.049335\n",
      "prices expensive gas expensive gas rental car p...  0.049335\n",
      "fireworks concerns bayview intersection bayview...  0.049335\n",
      "ice cream fireworks florida building collapse f...  0.049335\n",
      "fireworks concern trump org charges oakland as ...  0.049335\n",
      "other fireworks illegal fireworks ice cream fir...  0.049335\n",
      "sfo holiday travel sfo holiday travel bay bridg...  0.049335\n",
      "sfo holiday travel breed waterfront fireworks c...  0.049335\n",
      "sfo holiday travel jj vax delta protection weat...  0.049335\n",
      "fireworks demo holiday travel gas prices expens...  0.049335\n",
      "fireworks east bay fireworks coco fireworks dem...  0.049335\n",
      "lyanne fireworks concerns cold open breed water...  0.049335\n",
      "ctv aggressive coyotes aggressive coyotes capit...  0.049335\n",
      "jose fireworks safety san jose fireworks safety...  0.049335\n",
      "lyanne lyanne coco fireworks demo coco firework...  0.049335\n",
      "jose fireworks safety pleasanton fire east bay ...  0.049335\n",
      "san jose traffic matt cargo plane crash map tar...  0.049335\n",
      "traffic studio jobina sf fireworks transit fire...  0.049335\n",
      "fireworks demo sfo holiday travel emeryville tr...  0.049335\n",
      "covid cases vallejo shooting bart service delta...  0.049335\n",
      "first wx studio gfx full first traffic studio t...  0.049335\n",
      "sfo holiday travel emeryville traffic sj 87 tra...  0.049335\n",
      "fireworks demo coco fireworks demo sfo holiday ...  0.049335\n",
      "san jose fireworks safety san jose fireworks sa...  0.049335\n",
      "san jose fireworks safety pleasanton fire east ...  0.049335\n",
      "johnson breed waterfront oakland as fireworks t...  0.049335\n",
      "waits holiday travel holiday travel holiday tra...  0.049335\n",
      "waits holiday travel holiday travel holiday tra...  0.049335\n",
      "johnson and johnson breed waterfront oakland as...  0.049335\n",
      "sfo holiday travel bay bridge toll traffic emer...  0.049335\n",
      "magic makers cold open fireworks san jose firew...  0.049335\n",
      "tossweather stop recall fireworks web sf retail...  0.049335\n",
      "fireworks concern oakland as fireworks transit ...  0.049335\n",
      "covid concern fourth covid concern mannys reope...  0.049335\n",
      "lyanne coco fireworks demo coco fireworks demo ...  0.049335\n",
      "recall ctv matt sf fireworks transit us leaves ...  0.049335\n",
      "holiday travel holiday travel 5acold open 5atos...  0.049335\n",
      "sha carri 3oc gathering 3oc 4pm cold open tossw...  0.049335\n",
      "holiday travel gas prices expensive gas expensi...  0.049335\n",
      "holiday travel emeryville traffic sj 87 traffic...  0.049335\n",
      "holiday travel cold open 4th of july july eve july  0.049335\n",
      "traffic studio txl sfo holiday travel breed wat...  0.049335\n",
      "holiday travel breed waterfront fireworks conce...  0.049335\n",
      "holiday travel bay bridge toll traffic emeryvil...  0.049335\n",
      "holiday travel 5acold open 5atoss july eve july...  0.049335\n",
      "recall ctv aggressive coyotes aggressive coyote...  0.049335\n",
      "recall ctv breed waterfront jobina us military ...  0.049335\n",
      "hmb parade other fireworks illegal fireworks re...  0.049335\n",
      "org charges oakland as fireworks transit recall...  0.049335\n",
      "recall ctv transit changes vax questions gas ta...  0.049335\n",
      "hmb parade other fireworks illegal fireworks ic...  0.049335\n",
      "hmb parade july eve july eve fourth covid conce...  0.049335\n",
      "cornell fireworks concerns fireworks concerns d...  0.049335\n",
      "87 traffic travel coliseum fireworks recall can...  0.049335\n",
      "florida building collapse fourth covid concern ...  0.049335\n",
      "jobina jj vax delta protection recall newsom to...  0.049335\n",
      "exploratorium disney magic makers cold open fir...  0.049335\n",
      "cornell cornell fireworks concerns fireworks co...  0.049335\n",
      "retail crime lyanne lyanne coco fireworks demo ...  0.049335\n",
      "train target hours fireworks web street closure...  0.049335\n",
      "holiday travel holiday travel holiday travel 5a...  0.049335\n",
      "jobina sf fireworks transit fireworks concern t...  0.049335\n",
      "ctv matt sf fireworks transit us leaves afghani...  0.049335\n",
      "covid concern mannys reopening acold us militar...  0.049335\n",
      "fireworks coco fireworks demo holiday travel ga...  0.049335\n",
      "covid concern gg ferries hmb parade other firew...  0.049335\n",
      "cold open fireworks san jose fireworks safety s...  0.049335\n",
      "covid concern gg ferries other fireworks illega...  0.049335\n",
      "progress web t1 taylor swift deputy bart kaval ...  0.049335\n",
      "questions gas tax vax progress web t1 taylor sw...  0.049335\n",
      "gov recall recall ctv transit changes vax quest...  0.049335\n",
      "gov recall emeryville lyanne fireworks concerns...  0.049335\n",
      "safety san jose fireworks safety pleasanton fir...  0.049335\n",
      "safety pleasanton fire east bay fireworks east ...  0.049335\n",
      "web t1 taylor swift deputy bart kaval dispute b...  0.049335\n"
     ]
    }
   ],
   "source": [
    "qtr_df = pd.read_excel(f'{tgt_year}_{quarter}_Stories.xlsx')\n",
    "\n",
    "#//*** Trim unnamed First Column (original Index)\n",
    "del qtr_df[qtr_df.columns[0]]\n",
    "\n",
    "qtr_df = qtr_df[qtr_df['StoryText'].str.lower().str.contains(\"major fires across the state and track\")==False]\n",
    "\n",
    "#all_text =pd.Series(( ' '.join(list(qtr_df[\"StoryText\"]))))\n",
    "all_text = []\n",
    "\n",
    "ngrams = 10\n",
    "\n",
    "custom_stop_words = ['sot in person interview', '0','1','2','3','4','5','6','7','8','9','\\'','\"','\\n','\\t',',','.',',','-',':',\n",
    "                    'sot in person', ]\n",
    "custom_stop_words = ['4p','5a','5p','6a','6p','8a','8p','9a','11a','11p',\n",
    "                     'anchor','acoldopen',\n",
    "                     'coldopen',\n",
    "                     \n",
    "                     'fs','fr','frames','fls','fr1',\n",
    "                     'hello',\n",
    "                     'int','intro',\n",
    "                     'liz',\n",
    "                     'oc',\n",
    "                     'pkg','preshow','qa1',\n",
    "                     'ra','rem',\n",
    "                     'setup','sotvo','sv','sv1',\n",
    "                     'toss','tag','t1',\n",
    "                     'update',\n",
    "                     'vo',\n",
    "                     'wrap',\n",
    "                    ]\n",
    "remove_characters = [\"-\",\":\",\"\\xa0\",\"+\"]\n",
    "all_text = []\n",
    "\n",
    "for group in qtr_df.groupby('start_date'):\n",
    "    loop_text = ' '.join(list(group[1]['storyslug'])).lower().split(\" \")\n",
    "\n",
    "    for word in loop_text:\n",
    "        for find in remove_characters:\n",
    "            if find in word:\n",
    "                #print(find,word)\n",
    "                loop_text.remove(word)\n",
    "            \n",
    "    \n",
    "    for word in custom_stop_words:\n",
    "        while word in loop_text:\n",
    "            loop_text.remove(word)\n",
    "        \n",
    "    loop_text = ' '.join(loop_text)\n",
    "    all_text.append(loop_text)\n",
    "    \n",
    "tfIdfVectorizer=TfidfVectorizer(ngram_range=(ngrams,ngrams),use_idf=True,smooth_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(all_text)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print(len(df))\n",
    "print (df[:100])\n",
    "#print (df[1000:1100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vax 384\n",
      "fire 373\n",
      "covid 332\n",
      "weather 214\n",
      "recall 182\n",
      "sf 177\n",
      "amy 154\n",
      "cold 154\n",
      "afghanistan 132\n",
      "newsom 129\n",
      "vaccine 122\n",
      "masks 120\n",
      "jobina 119\n",
      "open 119\n",
      "t1 109\n",
      "caldor 108\n",
      "booster 107\n",
      "school 107\n",
      "questions 99\n",
      "webpc 98\n",
      "web 98\n",
      "biden 97\n",
      "coronavirus 92\n",
      "wildfire 90\n",
      "oakland 90\n",
      "bay 88\n",
      "stephanie 87\n",
      "fireworks 85\n",
      "acold 85\n",
      "wx 85\n",
      "mask 84\n",
      "ca 81\n",
      "dixie 80\n",
      "latest 80\n",
      "mandate 79\n",
      "sj 76\n",
      "ctv 72\n",
      "san 70\n",
      "and 70\n",
      "oak 68\n",
      "tahoe 67\n",
      "delta 67\n",
      "boosters 66\n",
      "headlines 66\n",
      "schools 65\n",
      "wildfires 63\n",
      "cornell 60\n",
      "travel 59\n",
      "smoke 58\n",
      "shooting 56\n",
      "9p 53\n",
      "air 53\n",
      "first 52\n",
      "search 51\n",
      "vaccines 51\n",
      "marin 50\n",
      "reax 49\n",
      "lyanne 49\n",
      "phil 48\n",
      "txl 48\n",
      "afghan 47\n",
      "theft 47\n",
      "testing 47\n",
      "drought 46\n",
      "tracker 46\n",
      "crime 46\n",
      "kate 45\n",
      "atoss 45\n",
      "quake 45\n",
      "atg 45\n",
      "theranos 44\n",
      "5pcoldopen 44\n",
      "water 43\n",
      "fires 43\n",
      "ida 43\n",
      "variant 42\n",
      "coco 41\n",
      "sot 40\n",
      "map 40\n",
      "pleasanton 39\n",
      "cdc 39\n",
      "east 39\n",
      "shot 39\n",
      "coverage 38\n",
      "help 38\n",
      "gov 38\n",
      "giants 37\n",
      "bart 37\n",
      "back 36\n",
      "napa 35\n",
      "push 35\n",
      "vote 35\n",
      "luz 35\n",
      "pfizer 34\n",
      "new 33\n",
      "elsa 33\n",
      "studio 33\n",
      "team 32\n",
      "5atoss 32\n",
      "cases 32\n",
      "county 32\n",
      "wayne 31\n",
      "sfusd 31\n",
      "elder 30\n",
      "breed 30\n",
      "dr 30\n",
      "proof 30\n",
      "return 30\n",
      "shots 30\n",
      "psps 29\n",
      "warning 29\n",
      "alert 29\n",
      "fda 29\n",
      "shoot 29\n",
      "santa 29\n",
      "violence 29\n",
      "ax 29\n",
      "la 28\n",
      "lightning 28\n",
      "vs 28\n",
      "poll 27\n",
      "sonoma 27\n",
      "opd 27\n",
      "haiti 27\n",
      "viewer 27\n",
      "vta 26\n",
      "laura 26\n",
      "drew 26\n",
      "action 26\n",
      "howard 25\n",
      "local 25\n",
      "car 25\n",
      "day 25\n",
      "health 25\n",
      "antioch 25\n",
      "lake 25\n",
      "mandates 25\n",
      "heat 25\n",
      "traffic 25\n",
      "terminal 25\n",
      "5acold 24\n",
      "rally 24\n",
      "quality 24\n",
      "7p 24\n",
      "to 24\n",
      "ousd 24\n",
      "park 24\n",
      "kids 24\n",
      "5pm 24\n",
      "hospital 23\n",
      "breakthrough 23\n",
      "crash 23\n",
      "patel 23\n",
      "climate 22\n",
      "of 22\n",
      "pge 22\n",
      "service 22\n",
      "strike 22\n",
      "fourth 22\n",
      "tossweather 22\n",
      "election 21\n",
      "special 21\n",
      "business 21\n",
      "leslie 21\n",
      "kid 21\n",
      "aco 21\n",
      "power 21\n",
      "voting 20\n",
      "hwy 20\n",
      "flex 20\n",
      "roots 20\n",
      "outages 20\n",
      "sfo 20\n",
      "outage 20\n",
      "natl 20\n",
      "closed 20\n",
      "appts 20\n",
      "hall 20\n",
      "july 19\n",
      "babba 19\n",
      "bar 19\n",
      "tamarack 19\n",
      "city 19\n",
      "safe 19\n",
      "work 19\n",
      "other 19\n",
      "weekend 19\n",
      "peace 19\n",
      "veil 19\n",
      "plan 19\n",
      "preps 19\n",
      "arrest 19\n",
      "attack 18\n",
      "muni 18\n",
      "11 18\n",
      "fake 18\n",
      "take 18\n",
      "tourism 18\n",
      "stanford 18\n",
      "capitol 18\n",
      "stadium 18\n",
      "live 18\n",
      "ad 18\n",
      "3oc 18\n",
      "fatal 18\n",
      "moderna 18\n",
      "area 18\n",
      "911 17\n",
      "virus 17\n",
      "red 17\n",
      "protest 17\n",
      "cal 17\n",
      "california 17\n",
      "missing 17\n",
      "eviction 17\n",
      "surge 17\n",
      "break 17\n",
      "state 16\n",
      "alameda 16\n",
      "alco 16\n",
      "oes 16\n",
      "berkeley 16\n",
      "race 16\n",
      "infrastructure 16\n",
      "western 16\n",
      "knp 16\n",
      "fawn 16\n",
      "on 16\n",
      "harris 16\n",
      "mt 16\n",
      "vaccinate 16\n",
      "johnson 16\n",
      "steph 16\n",
      "crisis 16\n",
      "aftermath 16\n",
      "lafayette 15\n",
      "rdr 15\n",
      "dreamforce 15\n",
      "restaurant 15\n",
      "cache 15\n",
      "protection 15\n",
      "rescue 15\n",
      "disney 15\n",
      "vallejo 15\n",
      "indoor 15\n",
      "gma 15\n",
      "labor 15\n",
      "olympics 15\n",
      "fremont 15\n",
      "google 15\n",
      "teacher 15\n",
      "week 15\n",
      "police 15\n",
      "evacuation 15\n",
      "liccardo 15\n",
      "jj 15\n",
      "collapse 15\n",
      "transit 15\n",
      "escape 15\n",
      "holiday 14\n",
      "bottlerock 14\n",
      "taliban 14\n",
      "response 14\n",
      "reopening 14\n",
      "firefighter 14\n",
      "reduction 14\n",
      "amanda 14\n",
      "quad 14\n",
      "gas 14\n",
      "interview 14\n",
      "the 14\n",
      "sideshow 14\n",
      "matt 14\n",
      "beckwourth 14\n",
      "site 14\n",
      "complex 14\n",
      "events 14\n",
      "danger 14\n",
      "exit 13\n",
      "kamala 13\n",
      "rate 13\n",
      "reopen 13\n",
      "dry 13\n",
      "youth 13\n",
      "benicia 13\n",
      "brentwood 13\n",
      "timeline 13\n",
      "chase 13\n",
      "sierra 13\n",
      "edd 13\n",
      "evacuations 13\n",
      "petito 13\n",
      "town 13\n",
      "parking 13\n",
      "evacs 13\n",
      "in 13\n",
      "jr 13\n",
      "app 13\n",
      "drive 13\n",
      "hate 13\n",
      "space 12\n",
      "real 12\n",
      "exemptions 12\n",
      "flag 12\n",
      "qa 12\n",
      "warriors 12\n",
      "third 12\n",
      "unemployment 12\n",
      "fed 12\n",
      "highway 12\n",
      "hurricane 12\n",
      "deputy 12\n",
      "child 12\n",
      "flash 12\n",
      "restrictions 12\n",
      "earthquake 12\n",
      "3m 12\n",
      "home 12\n",
      "storms 12\n",
      "chief 12\n",
      "us 12\n",
      "guidance 12\n",
      "festival 12\n",
      "how 12\n",
      "approval 12\n",
      "sky7 12\n",
      "guest 12\n",
      "sites 12\n",
      "clinic 12\n",
      "vaccinations 12\n",
      "wachter 12\n",
      "transmission 12\n",
      "faulconer 11\n",
      "tim 11\n",
      "tz 11\n",
      "larry 11\n",
      "reform 11\n",
      "time 11\n",
      "west 11\n",
      "chris 11\n",
      "contact 11\n",
      "kaiser 11\n",
      "transition 11\n",
      "baseball 11\n",
      "code 11\n",
      "britney 11\n",
      "outbreak 11\n",
      "national 11\n",
      "bayview 11\n",
      "north 11\n",
      "shortage 11\n",
      "pa 11\n",
      "united 11\n",
      "sandhya 11\n",
      "co 11\n",
      "death 11\n",
      "game 11\n",
      "ocvo 11\n",
      "smoky 11\n",
      "guidelines 11\n",
      "49ers 11\n",
      "sports 11\n",
      "vo1 11\n",
      "centers 11\n",
      "sr 11\n",
      "impact 11\n",
      "surfside 11\n",
      "smith 11\n",
      "force 11\n",
      "bu 11\n",
      "csu 10\n",
      "dustin 10\n",
      "remembrance 10\n",
      "apple 10\n",
      "tree 10\n",
      "neiman 10\n",
      "football 10\n",
      "jose 10\n",
      "save 10\n",
      "matier 10\n",
      "visit 10\n",
      "nicholas 10\n",
      "chp 10\n",
      "bust 10\n",
      "cam 10\n",
      "building 10\n",
      "beach 10\n",
      "northeast 10\n",
      "main 10\n",
      "concord 10\n",
      "berk 10\n",
      "moratorium 10\n",
      "cuomo 10\n",
      "cards 10\n",
      "spread 10\n",
      "holmes 10\n",
      "ethics 10\n",
      "community 10\n",
      "wave 10\n",
      "8pm 10\n",
      "fair 10\n",
      "ghaly 10\n",
      "leak 10\n",
      "digital 9\n",
      "deadline 9\n",
      "updates 9\n",
      "pelosi 9\n",
      "rates 9\n",
      "unified 9\n",
      "bingham 9\n",
      "learning 9\n",
      "social 9\n",
      "refugees 9\n",
      "retail 9\n",
      "midday 9\n",
      "freeway 9\n",
      "richmond 9\n",
      "family 9\n",
      "pursuit 9\n",
      "rob 9\n",
      "rail 9\n",
      "boxer 9\n",
      "cable 9\n",
      "night 9\n",
      "pier 9\n",
      "housing 9\n",
      "entertainment 9\n",
      "safety 9\n",
      "sfpd 9\n",
      "sherman 9\n",
      "results 9\n",
      "governor 9\n",
      "greenville 9\n",
      "sideshows 9\n",
      "stats 9\n",
      "street 9\n",
      "train 9\n",
      "chinatown 9\n",
      "truck 9\n",
      "gun 9\n",
      "misinformation 9\n",
      "media 9\n",
      "memorial 9\n",
      "driving 9\n",
      "lines 9\n",
      "pd 9\n",
      "evac 9\n",
      "unvaccinated 9\n",
      "student 9\n",
      "skies 9\n",
      "concerns 9\n",
      "concern 9\n",
      "afghans 9\n",
      "elex 8\n",
      "one 8\n",
      "ucsf 8\n",
      "2oc 8\n",
      "millennium 8\n",
      "doctor 8\n",
      "relief 8\n",
      "tomorrow 8\n",
      "report 8\n",
      "high 8\n",
      "zogg 8\n",
      "great 8\n",
      "rural 8\n",
      "anti 8\n",
      "chevron 8\n",
      "4pm 8\n",
      "up 8\n",
      "office 8\n",
      "atd 8\n",
      "vandalism 8\n",
      "sunnyvale 8\n",
      "ride 8\n",
      "rules 8\n",
      "ryan 8\n",
      "study 8\n",
      "no 8\n",
      "mateo 8\n",
      "scc 8\n",
      "wfh 8\n",
      "council 8\n",
      "outdoor 8\n",
      "fauci 8\n",
      "spencer 8\n",
      "blm 8\n",
      "chinese 8\n",
      "later 8\n",
      "mayors 8\n",
      "preview 8\n",
      "coyotes 8\n",
      "shutoff 8\n",
      "illegal 8\n",
      "eb 8\n",
      "outreach 8\n",
      "efforts 8\n",
      "dose 8\n",
      "info 8\n",
      "wiggins 8\n",
      "funding 8\n",
      "kabul 8\n",
      "fest 8\n",
      "sick 8\n",
      "show 8\n",
      "temps 8\n",
      "apology 8\n",
      "kristen 8\n",
      "dancing 8\n",
      "cox 8\n",
      "look 8\n",
      "ballots 7\n",
      "challengers 7\n",
      "stab 7\n",
      "voter 7\n",
      "bathroom 7\n",
      "bonta 7\n",
      "soma 7\n",
      "mandatory 7\n",
      "religious 7\n",
      "rent 7\n",
      "airline 7\n",
      "sc 7\n",
      "uber 7\n",
      "20 7\n",
      "richard 7\n",
      "coyote 7\n",
      "river 7\n",
      "bootleg 7\n",
      "evander 7\n",
      "hotel 7\n",
      "tn 7\n",
      "gg 7\n",
      "rollout 7\n",
      "lava 7\n",
      "vaccination 7\n",
      "workplace 7\n",
      "pop 7\n",
      "robbery 7\n",
      "homeless 7\n",
      "food 7\n",
      "dow 7\n",
      "texas 7\n",
      "jail 7\n",
      "oakley 7\n",
      "gop 7\n",
      "campaign 7\n",
      "house 7\n",
      "presser 7\n",
      "blue 7\n",
      "medical 7\n",
      "bus 7\n",
      "monterey 7\n",
      "abc 7\n",
      "valley 7\n",
      "staffing 7\n",
      "teen 7\n",
      "hearing 7\n",
      "biz 7\n",
      "john 7\n",
      "explainer 7\n",
      "lawsuit 7\n",
      "predator 7\n",
      "origin 7\n",
      "big 7\n",
      "opener 7\n",
      "thrive 7\n",
      "healdsburg 7\n",
      "card 7\n",
      "vacation 7\n",
      "disaster 7\n",
      "hopkins 7\n",
      "threat 7\n",
      "center 7\n",
      "today 7\n",
      "henri 7\n",
      "ash 7\n",
      "evacuees 7\n",
      "cars 7\n",
      "demo 7\n",
      "garlic 7\n",
      "7oys 7\n",
      "aerials 7\n",
      "kane 7\n",
      "ferries 7\n",
      "total 6\n",
      "countdown 6\n",
      "passenger 6\n",
      "natvo 6\n",
      "companies 6\n",
      "flavored 6\n",
      "qr 6\n",
      "prepare 6\n",
      "tsunami 6\n",
      "man 6\n",
      "protesters 6\n",
      "folsom 6\n",
      "uc 6\n",
      "andrew 6\n",
      "nightlife 6\n",
      "racing 6\n",
      "mobile 6\n",
      "bradford 6\n",
      "alamo 6\n",
      "dan 6\n",
      "case 6\n",
      "cleanup 6\n",
      "general 6\n",
      "secretary 6\n",
      "shine 6\n",
      "cdph 6\n",
      "sjpd 6\n",
      "small 6\n",
      "concert 6\n",
      "rock 6\n",
      "road 6\n",
      "rv 6\n",
      "ban 6\n",
      "smart 6\n",
      "explosion 6\n",
      "schaaf 6\n",
      "clara 6\n",
      "cruz 6\n",
      "niners 6\n",
      "closure 6\n",
      "norcal 6\n",
      "ofd 6\n",
      "spill 6\n",
      "wed 6\n",
      "hamilton 6\n",
      "caltrain 6\n",
      "airport 6\n",
      "sm 6\n",
      "soccer 6\n",
      "solano 6\n",
      "parade 6\n",
      "this 6\n",
      "enforcement 6\n",
      "advice 6\n",
      "at 6\n",
      "moc 6\n",
      "infastructure 6\n",
      "pets 6\n",
      "view 6\n",
      "moon 6\n",
      "fillmore 6\n",
      "thanks 6\n",
      "black 6\n",
      "pregnant 6\n",
      "4th 6\n",
      "hayward 6\n",
      "6atoss 6\n",
      "pc 6\n",
      "groundwater 6\n",
      "palo 6\n",
      "trial 6\n",
      "deaf 6\n",
      "incentive 6\n",
      "vaxxed 6\n",
      "uk 6\n",
      "gabby 6\n",
      "canada 6\n",
      "talk 6\n",
      "thurmond 6\n",
      "hawaii 6\n",
      "watch 6\n",
      "waterfront 6\n",
      "amtrak 6\n",
      "kcra 6\n",
      "government 6\n",
      "hospitals 6\n",
      "stimulus 6\n",
      "fans 6\n",
      "line 6\n",
      "court 6\n",
      "compare 6\n",
      "evaucee 6\n",
      "tue 6\n",
      "tests 6\n",
      "test 6\n",
      "hong 6\n",
      "event 6\n",
      "cfb 6\n",
      "buvo 6\n",
      "breakin 6\n",
      "helicopter 6\n",
      "delay 6\n",
      "finney 6\n",
      "ahead 6\n",
      "eve 5\n",
      "emeryville 5\n",
      "folo 5\n",
      "daca 5\n",
      "roundtable 5\n",
      "ready 5\n",
      "ransomware 5\n",
      "remote 5\n",
      "spare 5\n",
      "veteran 5\n",
      "cellphone 5\n",
      "kreycik 5\n",
      "rental 5\n",
      "tracking 5\n",
      "pizza 5\n",
      "exemption 5\n",
      "recommendation 5\n",
      "full 5\n",
      "livermore 5\n",
      "gilroy 5\n",
      "psychology 5\n",
      "lands 5\n",
      "windy 5\n",
      "scott 5\n",
      "aapi 5\n",
      "driveway 5\n",
      "security 5\n",
      "bars 5\n",
      "budget 5\n",
      "mv 5\n",
      "convention 5\n",
      "headquarters 5\n",
      "peterson 5\n",
      "science 5\n",
      "nats 5\n",
      "equipment 5\n",
      "coliseum 5\n",
      "closures 5\n",
      "resume 5\n",
      "restaurants 5\n",
      "tracing 5\n",
      "mack 5\n",
      "care 5\n",
      "salt 5\n",
      "practice 5\n",
      "murder 5\n",
      "mural 5\n",
      "ne 5\n",
      "nevada 5\n",
      "neumann 5\n",
      "evan 5\n",
      "farmworker 5\n",
      "underground 5\n",
      "numbers 5\n",
      "now 5\n",
      "storm 5\n",
      "wnba 5\n",
      "market 5\n",
      "camp 5\n",
      "daly 5\n",
      "arson 5\n",
      "wcc 5\n",
      "mon 5\n",
      "plane 5\n",
      "move 5\n",
      "extreme 5\n",
      "lassen 5\n",
      "morgan 5\n",
      "medicaid 5\n",
      "meeting 5\n",
      "melanie 5\n",
      "merck 5\n",
      "bank 5\n",
      "guns 5\n",
      "plus 5\n",
      "promo 5\n",
      "point 5\n",
      "airbnb 5\n",
      "perspective 5\n",
      "procession 5\n",
      "protect 5\n",
      "illegitimate 5\n",
      "9acold 5\n",
      "districts 5\n",
      "herd 5\n",
      "free 5\n",
      "fleas 5\n",
      "trials 5\n",
      "verify 5\n",
      "faith 5\n",
      "latino 5\n",
      "block 5\n",
      "cooling 5\n",
      "airlines 5\n",
      "fears 5\n",
      "future 5\n",
      "square 5\n",
      "walmart 5\n",
      "ghost 5\n",
      "after 5\n",
      "stabbed 5\n",
      "jobs 5\n",
      "statement 5\n",
      "sunday 5\n",
      "sirhan 5\n",
      "hit 5\n",
      "campbell 5\n",
      "shutdown 5\n",
      "south 5\n",
      "bear 5\n",
      "deploy 5\n",
      "tobacco 5\n",
      "travis 5\n",
      "into 5\n",
      "camera 5\n",
      "layfield 5\n",
      "ice 5\n",
      "teachers 5\n",
      "anxiety 5\n",
      "thu 5\n",
      "crackdown 5\n",
      "college 5\n",
      "homicide 5\n",
      "declaration 5\n",
      "hope 5\n",
      "bad 5\n",
      "24 5\n",
      "immunity 5\n",
      "fuel 5\n",
      "heroes 5\n",
      "jury 5\n",
      "knapp 5\n",
      "drill 5\n",
      "facebook 4\n",
      "daily 4\n",
      "gnr 4\n",
      "broadway 4\n",
      "list 4\n",
      "roundup 4\n",
      "ramon 4\n",
      "firework 4\n",
      "tsa 4\n",
      "multifaith 4\n",
      "caldecott 4\n",
      "requirements 4\n",
      "cross 4\n",
      "flags 4\n",
      "recruits 4\n",
      "recycled 4\n",
      "recology 4\n",
      "workers 4\n",
      "goodbye 4\n",
      "dui 4\n",
      "register 4\n",
      "support 4\n",
      "tj 4\n",
      "advisory 4\n",
      "hercules 4\n",
      "infection 4\n",
      "public 4\n",
      "purse 4\n",
      "tech 4\n",
      "inn 4\n",
      "r1 4\n",
      "sequoia 4\n",
      "gap 4\n",
      "rafael 4\n",
      "nhra 4\n",
      "quentin 4\n",
      "cpuc 4\n",
      "acso 4\n",
      "seton 4\n",
      "burn 4\n",
      "london 4\n",
      "marathon 4\n",
      "mayor 4\n",
      "cams 4\n",
      "bottle 4\n",
      "thieves 4\n",
      "sfgh 4\n",
      "wharf 4\n",
      "shelter 4\n",
      "sheriff 4\n",
      "thurdmond 4\n",
      "ridership 4\n",
      "rides 4\n",
      "nest 4\n",
      "rush 4\n",
      "rick 4\n",
      "klein 4\n",
      "large 4\n",
      "pregnancy 4\n",
      "returns 4\n",
      "retaliation 4\n",
      "connector 4\n",
      "supplies 4\n",
      "electric 4\n",
      "schellville 4\n",
      "fl 4\n",
      "schiff 4\n",
      "angwin 4\n",
      "am 4\n",
      "flooding 4\n",
      "maxwell 4\n",
      "news 4\n",
      "life 4\n",
      "summer 4\n",
      "forests 4\n",
      "ocean 4\n",
      "dolcini 4\n",
      "anniversary 4\n",
      "lambda 4\n",
      "greg 4\n",
      "cruise 4\n",
      "as 4\n",
      "30pm 4\n",
      "drug 4\n",
      "damage 4\n",
      "killed 4\n",
      "martinez 4\n",
      "cancer 4\n",
      "branson 4\n",
      "teens 4\n",
      "money 4\n",
      "muir 4\n",
      "for 4\n",
      "lion 4\n",
      "forum 4\n",
      "tower 4\n",
      "leaves 4\n",
      "mill 4\n",
      "art 4\n",
      "mental 4\n",
      "pick 4\n",
      "41 4\n",
      "down 4\n",
      "academies 4\n",
      "prices 4\n",
      "prison 4\n",
      "walnut 4\n",
      "program 4\n",
      "prop 4\n",
      "pool 4\n",
      "long 4\n",
      "policy 4\n",
      "powell 4\n",
      "prep 4\n",
      "wasserman 4\n",
      "ormsby 4\n",
      "boudin 4\n",
      "party 4\n",
      "cameras 4\n",
      "influencers 4\n",
      "pandemic 4\n",
      "outbreaks 4\n",
      "urgency 4\n",
      "swalwell 4\n",
      "vonew 4\n",
      "turnout 4\n",
      "verdict 4\n",
      "880 4\n",
      "armstrong 4\n",
      "unsigned 4\n",
      "bills 4\n",
      "unarmed 4\n",
      "fares 4\n",
      "broiler 4\n",
      "hesitancy 4\n",
      "julian 4\n",
      "washington 4\n",
      "welcome 4\n",
      "kxtv 4\n",
      "discovery 4\n",
      "sjsu 4\n",
      "marches 4\n",
      "world 4\n",
      "worst 4\n",
      "fashion 4\n",
      "stoppage 4\n",
      "coop 4\n",
      "walensky 4\n",
      "topics 4\n",
      "carson 4\n",
      "all 4\n",
      "tesla 4\n",
      "cliff 4\n",
      "stephen 4\n",
      "gaines 4\n",
      "check 4\n",
      "stop 4\n",
      "tosses 4\n",
      "dad 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spot 4\n",
      "sunsets 4\n",
      "680 4\n",
      "superspreader 4\n",
      "summit 4\n",
      "stuck 4\n",
      "barbara 4\n",
      "loan 4\n",
      "signs 4\n",
      "sinks 4\n",
      "sky 4\n",
      "slingshot 4\n",
      "kirker 4\n",
      "deter 4\n",
      "combat 4\n",
      "side 4\n",
      "effects 4\n",
      "southwest 4\n",
      "ama 4\n",
      "dion 4\n",
      "speier 4\n",
      "launch 4\n",
      "bill 4\n",
      "interpreter 4\n",
      "topic 4\n",
      "crew 4\n",
      "derailment 4\n",
      "target 4\n",
      "trafficking 4\n",
      "changes 4\n",
      "taylor 4\n",
      "evacuee 4\n",
      "chowchilla 4\n",
      "dog 4\n",
      "change 4\n",
      "coldopen2 4\n",
      "hmb 4\n",
      "clinch 4\n",
      "athletics 4\n",
      "doordash 4\n",
      "leaders 4\n",
      "brawl 4\n",
      "foil 4\n",
      "jenner 4\n",
      "calfire 4\n",
      "fastbreak 4\n",
      "cruises 4\n",
      "florida 4\n",
      "aggressive 4\n",
      "cpap 4\n",
      "deaths 4\n",
      "fri 4\n",
      "icus 4\n",
      "lee 4\n",
      "late 4\n",
      "boost 4\n",
      "anc 4\n",
      "discuss 4\n",
      "illness 4\n",
      "heimlich 4\n",
      "drone 4\n",
      "fight 4\n",
      "grubhub 4\n",
      "kabc 3\n",
      "chat 3\n",
      "sharks 3\n",
      "reaction 3\n",
      "head 3\n",
      "mlb 3\n",
      "albany 3\n",
      "renter 3\n",
      "remembrancer 3\n",
      "reopens 3\n",
      "van 3\n",
      "resigns 3\n",
      "require 3\n",
      "recalled 3\n",
      "refusal 3\n",
      "refugee 3\n",
      "follow 3\n",
      "headlands 3\n",
      "psaki 3\n",
      "govt 3\n",
      "punched 3\n",
      "punches 3\n",
      "ballot 3\n",
      "belmont 3\n",
      "james 3\n",
      "set 3\n",
      "carwash 3\n",
      "online 3\n",
      "sea 3\n",
      "levels 3\n",
      "seach 3\n",
      "moscone 3\n",
      "petaluma 3\n",
      "laundrie 3\n",
      "pet 3\n",
      "light 3\n",
      "ship 3\n",
      "rwc 3\n",
      "run 3\n",
      "ruling 3\n",
      "rohnert 3\n",
      "restraints 3\n",
      "northbay 3\n",
      "problem 3\n",
      "salmon 3\n",
      "cops 3\n",
      "wild 3\n",
      "pablo 3\n",
      "salesforce 3\n",
      "czu 3\n",
      "noaa 3\n",
      "out 3\n",
      "nfl 3\n",
      "drag 3\n",
      "congress 3\n",
      "ag 3\n",
      "bam 3\n",
      "zealand 3\n",
      "newark 3\n",
      "unvacinated 3\n",
      "navy 3\n",
      "task 3\n",
      "learn 3\n",
      "ong 3\n",
      "betty 3\n",
      "st 3\n",
      "nurse 3\n",
      "burnout 3\n",
      "notice 3\n",
      "teeter 3\n",
      "maynard 3\n",
      "yelp 3\n",
      "molnupiravir 3\n",
      "manfred 3\n",
      "monument 3\n",
      "misison 3\n",
      "med 3\n",
      "walk 3\n",
      "messaging 3\n",
      "merritt 3\n",
      "grizzly 3\n",
      "fix 3\n",
      "pill 3\n",
      "pitch 3\n",
      "part 3\n",
      "pittsburg 3\n",
      "poc 3\n",
      "planes 3\n",
      "pkgbkup 3\n",
      "arnold 3\n",
      "stress 3\n",
      "chin 3\n",
      "pediatrician 3\n",
      "ped 3\n",
      "peak 3\n",
      "pg 3\n",
      "expensive 3\n",
      "prevention 3\n",
      "suicide 3\n",
      "diversion 3\n",
      "prevent 3\n",
      "oracle 3\n",
      "22 3\n",
      "top 3\n",
      "bezos 3\n",
      "order 3\n",
      "5th 3\n",
      "denver 3\n",
      "garage 3\n",
      "parks 3\n",
      "parents 3\n",
      "outside 3\n",
      "overview 3\n",
      "alto 3\n",
      "outlook 3\n",
      "vasco 3\n",
      "statewide 3\n",
      "sushi 3\n",
      "effort 3\n",
      "data 3\n",
      "hardly 3\n",
      "johns 3\n",
      "anderson 3\n",
      "visas 3\n",
      "blood 3\n",
      "simone 3\n",
      "tropical 3\n",
      "veg 3\n",
      "virgin 3\n",
      "galactic 3\n",
      "suit 3\n",
      "cost 3\n",
      "use 3\n",
      "dates 3\n",
      "tuition 3\n",
      "gatherings 3\n",
      "imapct 3\n",
      "announcement 3\n",
      "efficacy 3\n",
      "expiring 3\n",
      "toyota 3\n",
      "weddings 3\n",
      "libby 3\n",
      "alaska 3\n",
      "burned 3\n",
      "wccusd 3\n",
      "finder 3\n",
      "wallensky 3\n",
      "immunize 3\n",
      "draft 3\n",
      "spca 3\n",
      "clayton 3\n",
      "llnl 3\n",
      "ggb 3\n",
      "fifth 3\n",
      "start 3\n",
      "benefits 3\n",
      "tirade 3\n",
      "strictly 3\n",
      "icu 3\n",
      "bb 3\n",
      "biles 3\n",
      "siskiyou 3\n",
      "germany 3\n",
      "forecast 3\n",
      "totter 3\n",
      "tok 3\n",
      "toll 3\n",
      "tik 3\n",
      "tulare 3\n",
      "tule 3\n",
      "elk 3\n",
      "tues 3\n",
      "amazon 3\n",
      "human 3\n",
      "cans 3\n",
      "gavin 3\n",
      "teamwork 3\n",
      "fruitvale 3\n",
      "calfor 3\n",
      "tickets 3\n",
      "fundraiser 3\n",
      "chesa 3\n",
      "flaring 3\n",
      "clemency 3\n",
      "commission 3\n",
      "auburn 3\n",
      "bailey 3\n",
      "breach 3\n",
      "bridge 3\n",
      "canceled 3\n",
      "cancellations 3\n",
      "caitlyn 3\n",
      "laurie 3\n",
      "dangers 3\n",
      "arrests 3\n",
      "impacts 3\n",
      "dam 3\n",
      "courts 3\n",
      "iteam 3\n",
      "kiosk 3\n",
      "endemic 3\n",
      "assembly 3\n",
      "backpacks 3\n",
      "hazy 3\n",
      "intersection 3\n",
      "idaho 3\n",
      "backlog 3\n",
      "bagram 3\n",
      "friends 3\n",
      "loans 3\n",
      "bkup 3\n",
      "board 3\n",
      "donations 3\n",
      "international 3\n",
      "inequities 3\n",
      "lawsuits 3\n",
      "hose 3\n",
      "enforce 3\n",
      "kindness 3\n",
      "dispute 3\n",
      "final 3\n",
      "dine 3\n",
      "downtown 3\n",
      "devil 3\n",
      "friday 3\n",
      "00pm 2\n",
      "candidates 2\n",
      "assault 2\n",
      "telosa 2\n",
      "two 2\n",
      "tx 2\n",
      "udpate 2\n",
      "ausd 2\n",
      "haitian 2\n",
      "estate 2\n",
      "harvey 2\n",
      "huntington 2\n",
      "rem1 2\n",
      "assistance 2\n",
      "rescued 2\n",
      "animals 2\n",
      "reservoirs 2\n",
      "resistance 2\n",
      "resort 2\n",
      "name 2\n",
      "resources 2\n",
      "responder 2\n",
      "repairs 2\n",
      "reporters 2\n",
      "repeat 2\n",
      "gray 2\n",
      "reproductive 2\n",
      "requirement 2\n",
      "reena 2\n",
      "refund 2\n",
      "recent 2\n",
      "record 2\n",
      "recovery 2\n",
      "recruit 2\n",
      "referral 2\n",
      "regeneron 2\n",
      "refugges 2\n",
      "reg 2\n",
      "regan 2\n",
      "shooter 2\n",
      "regret 2\n",
      "refill 2\n",
      "3p 2\n",
      "fwy 2\n",
      "ana 2\n",
      "qb 2\n",
      "shuffle 2\n",
      "index 2\n",
      "murphys 2\n",
      "possible 2\n",
      "ps5 2\n",
      "pumpkin 2\n",
      "spice 2\n",
      "puppy 2\n",
      "purchase 2\n",
      "limits 2\n",
      "purifier 2\n",
      "quinta 2\n",
      "quinto 2\n",
      "billionaire 2\n",
      "racial 2\n",
      "chabot 2\n",
      "rack 2\n",
      "battery 2\n",
      "biochar 2\n",
      "question 2\n",
      "jonathan 2\n",
      "quarry 2\n",
      "campground 2\n",
      "autonomous 2\n",
      "castro 2\n",
      "kern 2\n",
      "marine 2\n",
      "monster 2\n",
      "colusa 2\n",
      "desantis 2\n",
      "non 2\n",
      "seven 2\n",
      "trees 2\n",
      "aids 2\n",
      "lockdown 2\n",
      "senate 2\n",
      "sequence 2\n",
      "np 2\n",
      "harvest 2\n",
      "cabin 2\n",
      "pretrial 2\n",
      "libraries 2\n",
      "deputies 2\n",
      "end 2\n",
      "scvwa 2\n",
      "screen 2\n",
      "seat 2\n",
      "pkgnew 2\n",
      "n6 2\n",
      "shop 2\n",
      "flood 2\n",
      "trash 2\n",
      "sha 2\n",
      "carri 2\n",
      "shaking 2\n",
      "briana 2\n",
      "torture 2\n",
      "reusable 2\n",
      "coronavirs 2\n",
      "tip 2\n",
      "robberies 2\n",
      "attempted 2\n",
      "robert 2\n",
      "durst 2\n",
      "roblox 2\n",
      "trip 2\n",
      "riverstage 2\n",
      "rideshare 2\n",
      "rig 2\n",
      "overturn 2\n",
      "rights 2\n",
      "showdown 2\n",
      "riot 2\n",
      "thrower 2\n",
      "rp 2\n",
      "rutherford 2\n",
      "rodney 2\n",
      "alcala 2\n",
      "ron 2\n",
      "rosa 2\n",
      "four 2\n",
      "tourists 2\n",
      "restoration 2\n",
      "restored 2\n",
      "resurgence 2\n",
      "reveal 2\n",
      "reyes 2\n",
      "whale 2\n",
      "rich 2\n",
      "aloha 2\n",
      "fairfield 2\n",
      "retun 2\n",
      "commuters 2\n",
      "lunch 2\n",
      "schoolfls 2\n",
      "francisco 2\n",
      "antonio 2\n",
      "carlos 2\n",
      "diego 2\n",
      "sanctioned 2\n",
      "sac 2\n",
      "sacto 2\n",
      "yolo 2\n",
      "sandbags 2\n",
      "scenic 2\n",
      "bump 2\n",
      "satellite 2\n",
      "backfires 2\n",
      "saturday 2\n",
      "saved 2\n",
      "phone 2\n",
      "sound 2\n",
      "lgbtq 2\n",
      "forest 2\n",
      "george 2\n",
      "gutman 2\n",
      "klobuchar 2\n",
      "unions 2\n",
      "nightline 2\n",
      "nihonmachi 2\n",
      "nile 2\n",
      "nina 2\n",
      "nj 2\n",
      "millbrae 2\n",
      "confidence 2\n",
      "lockdowns 2\n",
      "forfeit 2\n",
      "visits 2\n",
      "newvo 2\n",
      "nicks 2\n",
      "oxbow 2\n",
      "nas 2\n",
      "nations 2\n",
      "fleet 2\n",
      "sutter 2\n",
      "musk 2\n",
      "naacp 2\n",
      "employees 2\n",
      "uniforms 2\n",
      "marcus 2\n",
      "hero 2\n",
      "nba 2\n",
      "playeres 2\n",
      "ness 2\n",
      "essential 2\n",
      "off 2\n",
      "balcony 2\n",
      "ocfs 2\n",
      "officers 2\n",
      "oncene 2\n",
      "month 2\n",
      "cop 2\n",
      "ohio 2\n",
      "oil 2\n",
      "old 2\n",
      "transbay 2\n",
      "olmpics 2\n",
      "oberg 2\n",
      "nyc 2\n",
      "alarm 2\n",
      "church 2\n",
      "noyes 2\n",
      "homicides 2\n",
      "nordstrom 2\n",
      "norwegian 2\n",
      "novato 2\n",
      "zoo 2\n",
      "violent 2\n",
      "hills 2\n",
      "tv 2\n",
      "warehouse 2\n",
      "maviglio 2\n",
      "pharmacy 2\n",
      "exploratorium 2\n",
      "levis 2\n",
      "cargo 2\n",
      "guidlines 2\n",
      "fear 2\n",
      "ymca 2\n",
      "mars 2\n",
      "brush 2\n",
      "masking 2\n",
      "moments 2\n",
      "monica 2\n",
      "ghandi 2\n",
      "greece 2\n",
      "mission 2\n",
      "mitchell 2\n",
      "jam 2\n",
      "moving 2\n",
      "mouse 2\n",
      "movie 2\n",
      "goers 2\n",
      "diablo 2\n",
      "moses 2\n",
      "dies 2\n",
      "mtg 2\n",
      "mountain 2\n",
      "timelapse 2\n",
      "moritorium 2\n",
      "hill 2\n",
      "waste 2\n",
      "meetings 2\n",
      "hotels 2\n",
      "mcguire 2\n",
      "lil 2\n",
      "mdt1 2\n",
      "medal 2\n",
      "ceremonies 2\n",
      "military 2\n",
      "milk 2\n",
      "crate 2\n",
      "minorities 2\n",
      "mirikitani 2\n",
      "misinfo 2\n",
      "milestone 2\n",
      "michigan 2\n",
      "merkel 2\n",
      "michelin 2\n",
      "met 2\n",
      "gala 2\n",
      "meteor 2\n",
      "shower 2\n",
      "meters 2\n",
      "trains 2\n",
      "mexico 2\n",
      "mi 2\n",
      "aqui 2\n",
      "michael 2\n",
      "pianos 2\n",
      "cheeseburger 2\n",
      "pic 2\n",
      "picks 2\n",
      "pickup 2\n",
      "piedmont 2\n",
      "pills 2\n",
      "photo 2\n",
      "pkg 2\n",
      "player 2\n",
      "plug 2\n",
      "podcast 2\n",
      "smc 2\n",
      "taco 2\n",
      "competitors 2\n",
      "pentagon 2\n",
      "peoples 2\n",
      "perseid 2\n",
      "person 2\n",
      "peter 2\n",
      "kristin 2\n",
      "falcon 2\n",
      "colored 2\n",
      "kidst 2\n",
      "oral 2\n",
      "academy 2\n",
      "price 2\n",
      "increase 2\n",
      "pride 2\n",
      "private 2\n",
      "manzaninta 2\n",
      "wwii 2\n",
      "prescription 2\n",
      "president 2\n",
      "woolly 2\n",
      "usf 2\n",
      "progress 2\n",
      "progression 2\n",
      "project 2\n",
      "prompter 2\n",
      "polls 2\n",
      "eosa 2\n",
      "port 2\n",
      "pot 2\n",
      "worries 2\n",
      "precita 2\n",
      "eyes 2\n",
      "powerball 2\n",
      "ppic 2\n",
      "prayer 2\n",
      "split 2\n",
      "oroville 2\n",
      "oregon 2\n",
      "oscar 2\n",
      "grant 2\n",
      "cities 2\n",
      "org 2\n",
      "charges 2\n",
      "ordinance 2\n",
      "orders 2\n",
      "treatment 2\n",
      "orange 2\n",
      "orchard 2\n",
      "champion 2\n",
      "current 2\n",
      "adam 2\n",
      "liz 2\n",
      "jean 2\n",
      "fla 2\n",
      "our 2\n",
      "allies 2\n",
      "flying 2\n",
      "fees 2\n",
      "jfk 2\n",
      "taped 2\n",
      "passing 2\n",
      "passports 2\n",
      "patients 2\n",
      "paul 2\n",
      "pay 2\n",
      "path 2\n",
      "patient 2\n",
      "panetta 2\n",
      "arrival 2\n",
      "overall 2\n",
      "padres 2\n",
      "pages 2\n",
      "outreah 2\n",
      "giacomo 2\n",
      "dining 2\n",
      "soskin 2\n",
      "states 2\n",
      "status 2\n",
      "timing 2\n",
      "tam 2\n",
      "environment 2\n",
      "expansion 2\n",
      "fairfax 2\n",
      "dallas 2\n",
      "deadlines 2\n",
      "fly 2\n",
      "lottery 2\n",
      "golden 2\n",
      "explain 2\n",
      "vomarin 2\n",
      "vo2 2\n",
      "visiting 2\n",
      "vista 2\n",
      "kansas 2\n",
      "tcu 2\n",
      "unvax 2\n",
      "votes 2\n",
      "vendors 2\n",
      "venus 2\n",
      "victim 2\n",
      "video 2\n",
      "games 2\n",
      "worth 2\n",
      "vegas 2\n",
      "victims 2\n",
      "trust 2\n",
      "videos 2\n",
      "interruptor 2\n",
      "vip 2\n",
      "villegas 2\n",
      "vikings 2\n",
      "village 2\n",
      "conversation 2\n",
      "uptick 2\n",
      "university 2\n",
      "haight 2\n",
      "usc 2\n",
      "vaccinated 2\n",
      "students 2\n",
      "bosa 2\n",
      "cpmc 2\n",
      "leon 2\n",
      "jelani 2\n",
      "un 2\n",
      "under 2\n",
      "430 2\n",
      "ucla 2\n",
      "vanderbilt 2\n",
      "valleo 2\n",
      "billonaire 2\n",
      "615 2\n",
      "disabilities 2\n",
      "starbucks 2\n",
      "whats 2\n",
      "wheels 2\n",
      "white 2\n",
      "tattleware 2\n",
      "weeks 2\n",
      "weight 2\n",
      "loss 2\n",
      "weinstein 2\n",
      "detection 2\n",
      "trackers 2\n",
      "sizzle 2\n",
      "arrested 2\n",
      "lukewarm 2\n",
      "licardo 2\n",
      "encore 2\n",
      "front 2\n",
      "hoiday 2\n",
      "inmate 2\n",
      "glass 2\n",
      "ctr 2\n",
      "your 2\n",
      "ally 2\n",
      "yasaman 2\n",
      "stabbing 2\n",
      "zones 2\n",
      "years 2\n",
      "yang 2\n",
      "windsor 2\n",
      "wine 2\n",
      "arena 2\n",
      "womens 2\n",
      "illinois 2\n",
      "women 2\n",
      "mammoth 2\n",
      "corridor 2\n",
      "wsu 2\n",
      "50th 2\n",
      "worker 2\n",
      "waymo 2\n",
      "ikea 2\n",
      "tender 2\n",
      "wasters 2\n",
      "astrazeneca 2\n",
      "11am 2\n",
      "creek 2\n",
      "warm 2\n",
      "warn 2\n",
      "walgreens 2\n",
      "closing 2\n",
      "waits 2\n",
      "wash 2\n",
      "watchr 2\n",
      "gym 2\n",
      "tagboard 2\n",
      "eu 2\n",
      "hillary 2\n",
      "hochul 2\n",
      "bennett 2\n",
      "stevie 2\n",
      "stern 2\n",
      "grove 2\n",
      "steven 2\n",
      "checks 2\n",
      "stockton 2\n",
      "drowned 2\n",
      "alliance 2\n",
      "concerts 2\n",
      "stateline 2\n",
      "sue 2\n",
      "stamp 2\n",
      "coach 2\n",
      "agave 2\n",
      "store 2\n",
      "suns 2\n",
      "sunset 2\n",
      "supreme 2\n",
      "stuff 2\n",
      "subscribe 2\n",
      "sundance 2\n",
      "surcharge 2\n",
      "demolition 2\n",
      "swift 2\n",
      "crocodile 2\n",
      "suspect 2\n",
      "close 2\n",
      "stringer 2\n",
      "gfx 2\n",
      "87 2\n",
      "silicon 2\n",
      "dust 2\n",
      "bts 2\n",
      "deadly 2\n",
      "sjc 2\n",
      "grads 2\n",
      "5p 2\n",
      "hillview 2\n",
      "homelessness 2\n",
      "alternative 2\n",
      "instagram 2\n",
      "coldopencaldor 2\n",
      "sotvo1 2\n",
      "cancel 2\n",
      "batt 2\n",
      "flights 2\n",
      "speed 2\n",
      "dogs 2\n",
      "flight 2\n",
      "spears 2\n",
      "helps 2\n",
      "couny 2\n",
      "smfta 2\n",
      "towing 2\n",
      "buildings 2\n",
      "smash 2\n",
      "song 2\n",
      "sobering 2\n",
      "toys 2\n",
      "tosswx 2\n",
      "before 2\n",
      "title 2\n",
      "42 2\n",
      "tornado 2\n",
      "toss 2\n",
      "tossfinney 2\n",
      "tosswayne 2\n",
      "coldopenred 2\n",
      "emmys 2\n",
      "traveling 2\n",
      "tutors 2\n",
      "tweet 2\n",
      "africa 2\n",
      "trump 2\n",
      "ts 2\n",
      "australia 2\n",
      "expand 2\n",
      "trail 2\n",
      "independence 2\n",
      "equity 2\n",
      "hours 2\n",
      "tassajara 2\n",
      "tax 2\n",
      "taxi 2\n",
      "taxis 2\n",
      "ted 2\n",
      "las 2\n",
      "tempers 2\n",
      "tennant 2\n",
      "guggenheim 2\n",
      "janice 2\n",
      "jon 2\n",
      "kelly 2\n",
      "benefit 2\n",
      "blocking 2\n",
      "tackles 2\n",
      "intruder 2\n",
      "bell 2\n",
      "cuba 2\n",
      "then 2\n",
      "internet 2\n",
      "ti 2\n",
      "tiers 2\n",
      "autopilot 2\n",
      "bidne 2\n",
      "gw 2\n",
      "th0 2\n",
      "eft 2\n",
      "abortion 2\n",
      "borer 2\n",
      "dropout 2\n",
      "cruiser 2\n",
      "crossing 2\n",
      "10pm 2\n",
      "chamber 2\n",
      "chambers 2\n",
      "chicago 2\n",
      "herrera 2\n",
      "leronne 2\n",
      "classroom 2\n",
      "clean 2\n",
      "christian 2\n",
      "arana 2\n",
      "cinema 2\n",
      "comedy 2\n",
      "cats 2\n",
      "jewelry 2\n",
      "chair 2\n",
      "coldopen1 2\n",
      "colfax 2\n",
      "mannys 2\n",
      "company 2\n",
      "literacy 2\n",
      "clipper 2\n",
      "eric 2\n",
      "book 2\n",
      "bupkg 2\n",
      "burglar 2\n",
      "burlingame 2\n",
      "burnett 2\n",
      "busan 2\n",
      "buck 2\n",
      "lucy 2\n",
      "bye 2\n",
      "by 2\n",
      "buy 2\n",
      "butte 2\n",
      "festivals 2\n",
      "island 2\n",
      "boy 2\n",
      "cool 2\n",
      "brewers 2\n",
      "longhaulers 2\n",
      "caravan 2\n",
      "candidate 2\n",
      "fencing 2\n",
      "candlestick 2\n",
      "crypto 2\n",
      "border 2\n",
      "echo 2\n",
      "cajon 2\n",
      "campaigns 2\n",
      "crimes 2\n",
      "guards 2\n",
      "fall 2\n",
      "apps 2\n",
      "kevin 2\n",
      "cream 2\n",
      "cosco 2\n",
      "delays 2\n",
      "facts 2\n",
      "homeroom 2\n",
      "dc 2\n",
      "depression 2\n",
      "zynga 2\n",
      "cupertino 2\n",
      "curfew 2\n",
      "davis 2\n",
      "corte 2\n",
      "madera 2\n",
      "dewormer 2\n",
      "costs 2\n",
      "cornel 2\n",
      "embarcadero 2\n",
      "conference 2\n",
      "golf 2\n",
      "halftime 2\n",
      "id 2\n",
      "extremism 2\n",
      "expert 2\n",
      "19 2\n",
      "bob 2\n",
      "evictions 2\n",
      "emails 2\n",
      "etch 2\n",
      "helping 2\n",
      "insurance 2\n",
      "address 2\n",
      "americas 2\n",
      "alex 2\n",
      "blinken 2\n",
      "evacuate 2\n",
      "guard 2\n",
      "finds 2\n",
      "best 2\n",
      "krispy 2\n",
      "japantown 2\n",
      "gender 2\n",
      "5pp 2\n",
      "federal 2\n",
      "2vo 2\n",
      "apollo 2\n",
      "lights 2\n",
      "11preshow 2\n",
      "15pm 2\n",
      "1st 2\n",
      "50 2\n",
      "45pm 2\n",
      "anne 2\n",
      "3mvo 2\n",
      "gathering 2\n",
      "abduction 2\n",
      "abuse 2\n",
      "ac 2\n",
      "9pm 2\n",
      "7pm 2\n",
      "7th 2\n",
      "80 2\n",
      "express 2\n",
      "68th 2\n",
      "6acold 2\n",
      "bike 2\n",
      "italy 2\n",
      "euro 2\n",
      "e12th 2\n",
      "grandcolas 2\n",
      "letters 2\n",
      "exec 2\n",
      "incident 2\n",
      "berman 2\n",
      "barge 2\n",
      "listening 2\n",
      "kaval 2\n",
      "luke 2\n",
      "jack 2\n",
      "hs 2\n",
      "booser 2\n",
      "booker 2\n",
      "facilitating 2\n",
      "bomb 2\n",
      "flea 2\n",
      "jackie 2\n",
      "anza 2\n",
      "hot 2\n",
      "grab 2\n",
      "dunsmore 2\n",
      "angelo 2\n",
      "edu 2\n",
      "laquinta 2\n",
      "grand 2\n",
      "avenue 2\n",
      "jrue 2\n",
      "kerry 2\n",
      "glance 2\n",
      "fund 2\n",
      "maps 2\n",
      "dubs 2\n",
      "hospitalizations 2\n",
      "explodes 2\n",
      "destruction 2\n",
      "jacobo 2\n",
      "madison 2\n",
      "jones 2\n",
      "dunk 2\n",
      "getreu 2\n",
      "grill 2\n",
      "jackson 2\n",
      "donlon 2\n",
      "england 2\n",
      "intv 2\n",
      "fung 2\n",
      "jesse 2\n",
      "jet 2\n",
      "job 2\n",
      "distance 2\n",
      "guitar 2\n",
      "laws 2\n",
      "firefighters 2\n",
      "heads 2\n",
      "hispanic 2\n",
      "heroics 2\n",
      "honda 2\n",
      "healthcare 2\n",
      "feinstein 2\n",
      "marc 2\n",
      "lucas 2\n",
      "lz 2\n",
      "magic 2\n",
      "makers 2\n",
      "level 2\n",
      "expectancy 2\n",
      "fema 2\n",
      "disneyland 2\n",
      "kirkwood 2\n",
      "kreme 2\n",
      "freebie 2\n",
      "kingdom 2\n",
      "lahs 2\n",
      "lanes 2\n",
      "kuminga 2\n",
      "expenses 2\n",
      "find 2\n",
      "farm 2\n",
      "flower 2\n",
      "drop 2\n",
      "gandhi 2\n",
      "giannis 2\n",
      "die 2\n",
      "elizabeth 2\n",
      "guevin 2\n",
      "fraud 2\n",
      "drugstore 2\n",
      "egg 2\n",
      "educators 2\n",
      "effect 2\n",
      "frames1 2\n",
      "frvo 2\n",
      "fridays 2\n",
      "grooming 2\n",
      "gate 2\n",
      "gma3 2\n",
      "snatchers 1\n",
      "recommendations 1\n",
      "dodgers 1\n"
     ]
    }
   ],
   "source": [
    "tfIdfVectorizer=TfidfVectorizer(ngram_range=(2,2),use_idf=True,smooth_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(df.index)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "\n",
    "freq = {}\n",
    "\n",
    "for word in ' '.join(list(df.index)).split(' '):\n",
    "    if word in freq.keys():\n",
    "        freq[word] += 1\n",
    "    else:\n",
    "        freq[word] = 1\n",
    "\n",
    "#sorted(month, key=numbermap.__getitem__)\n",
    "\n",
    "reverseDict = {}\n",
    "for key in sorted(freq, key=freq.get, reverse=True):\n",
    "    print(key,freq[key])\n",
    "    #oldKey_newValue = key\n",
    "    #newKey_oldValue = input_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         TF-IDF\n",
      "music to               0.424547\n",
      "turns up               0.221713\n",
      "office turns           0.221713\n",
      "off youtube            0.221713\n",
      "conversation sergeant  0.221713\n",
      "you playing            0.212273\n",
      "his face               0.212273\n",
      "pop music              0.212273\n",
      "quote are              0.212273\n",
      "playing pop            0.212273\n",
      "to drown               0.212273\n",
      "sergeant with          0.205576\n",
      "drown out              0.200381\n",
      "face off               0.192548\n",
      "the music              0.184245\n",
      "keep his               0.178137\n",
      "the conversation       0.168108\n",
      "the alameda            0.151971\n",
      "sheriff office         0.147727\n",
      "county sheriff         0.136424\n",
      "alameda county         0.126590\n",
      "are you                0.126590\n",
      "up the                 0.118424\n",
      "out the                0.114620\n",
      "to keep                0.104527\n",
      "with the               0.075352\n",
      "questions joining      0.000000\n",
      "questions infectious   0.000000\n",
      "quarters damage        0.000000\n",
      "questions information  0.000000\n",
      "questions is           0.000000\n",
      "questions jasmine      0.000000\n",
      "questions just         0.000000\n",
      "questions head         0.000000\n",
      "questions left         0.000000\n",
      "questions like         0.000000\n",
      "questions literacy     0.000000\n",
      "questions lot          0.000000\n",
      "questions may          0.000000\n",
      "questions now          0.000000\n",
      "questions of           0.000000\n",
      "questions on           0.000000\n",
      "questions over         0.000000\n",
      "questions pfizer       0.000000\n",
      "questions please       0.000000\n",
      "questions in           0.000000\n",
      "quaters so             0.000000\n",
      "questions go           0.000000\n",
      "questions from         0.000000\n",
      "questionnaire trial    0.000000\n"
     ]
    }
   ],
   "source": [
    "#all_text =pd.Series(( ' '.join(list(qtr_df[\"StoryText\"]))))\n",
    "all_text = []\n",
    "\n",
    "custom_stop_words = ['0','1','2','3','4','5','6','7','8','9','\\'','\"','\\n','\\t',',','.',',','-',':']\n",
    "\n",
    "for row in qtr_df.iterrows():\n",
    "    #loop_text = ' '.join(list(row[1]['StoryText']))\n",
    "    loop_text = row[1]['StoryText']\n",
    "    \n",
    "    for word in custom_stop_words:\n",
    "        loop_text = loop_text.replace(word,\" \")\n",
    "    \n",
    "    all_text.append(loop_text)\n",
    "    \n",
    "tfIdfVectorizer=TfidfVectorizer(ngram_range=(2,2),use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(all_text)\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-29d9e51ad7c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtfidf_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tfidf_matrix' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//***************************************\n",
    "#//*** Apply Common Cleanup operations\n",
    "#//***************************************\n",
    "#//*** In anticpation that I'll be re-using text cleanup code. I'm adding some robustness to the function.\n",
    "#//*** Adding kwargs to disable features that default to true.\n",
    "#//*** Whether an action is skipped or executed is based on a boolean value stored in action_dict.\n",
    "#//*** Key values will default to true. If code needs to be defaulted to False, a default_false list can be added later\n",
    "#//*** All Boolean kwarg keya are stored in kwarg list. This speeds up the coding of the action_dict.\n",
    "#//*** As Kwargs are added \n",
    "def mr_clean_text(input_series, input_options={}):\n",
    "    \n",
    "    #//*** import time library\n",
    "    try:\n",
    "        type(time)\n",
    "    except:\n",
    "        import time\n",
    "    \n",
    "    #//*** Start Timing the process\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #//*** Add some data validation. I'm preparing this function for additional use. I'm checking if future users (ie future me)\n",
    "    #//*** may throw some garbage at this function. Experience has taught me to fail safely wherever possible.\n",
    "\n",
    "    #//*** All kwargs are listed here. These initialize TRUE by default.\n",
    "    key_list = [ \"lower\", \"newline\", \"html\", \"remove_empty\", \"punctuation\" ]\n",
    "    \n",
    "    #//*** Build Action Dictionary\n",
    "    action_dict = { } \n",
    "    \n",
    "    #//*** Build the keys from kwarg_list and default them to TRUE\n",
    "    for key in key_list:\n",
    "        action_dict[key] = True\n",
    "        \n",
    "    #//*** Loop through the input kwargs (if any). Assign the action_dict values based on the kwargs:\n",
    "    for key,value in input_options.items():\n",
    "        print(key,value)\n",
    "        action_dict[key] = value\n",
    "    \n",
    "    \n",
    "    #//*************************************************************************\n",
    "    #//*** The Cleanup/Processing code is a straight lift from DSC550 - Week02\n",
    "    #//*************************************************************************\n",
    "    #//*** Convert to Lower Case, Default to True\n",
    "    if action_dict[\"lower\"]:\n",
    "        input_series = input_series.str.lower()\n",
    "    \n",
    "   \n",
    "    #//*** Remove New Lines\n",
    "    if action_dict[\"newline\"]:\n",
    "        #//*** Rmove \\r\\n\n",
    "        input_series = input_series.str.replace(r'\\r?\\n',\"\")\n",
    "\n",
    "        #//*** Remove \\n new lines\n",
    "        input_series = input_series.str.replace(r'\\n',\"\")\n",
    "\n",
    "    #//*** Remove html entities, observed entities are &gt; and &lt;. All HTML entities begin with & and end with ;.\n",
    "    #//*** Let's use regex to remove html entities\n",
    "    if action_dict[\"html\"]:\n",
    "        input_series = input_series.str.replace(r'&.*;',\"\")\n",
    "\n",
    "    #//*** Remove the empty lines\n",
    "    if action_dict[\"remove_empty\"]:\n",
    "        input_series = input_series[ input_series.str.len() > 0]\n",
    "\n",
    "    #//*** Remove punctuation\n",
    "    if action_dict[\"punctuation\"]:\n",
    "        #//*** Load libraries for punctuation if not already loaded.\n",
    "        #//*** Wrapping these in a try, no sense in importing libraries that already exist.\n",
    "        #//*** Unsure of the cost of reimporting libraries (if any). But testing if library is already loaded feels\n",
    "        #//*** like a good practice\n",
    "        try:\n",
    "            type(sys)\n",
    "        except:\n",
    "            import sys\n",
    "\n",
    "        try:\n",
    "            type(unicodedata)\n",
    "        except:\n",
    "            import unicodedata\n",
    "        \n",
    "        #//*** replace Comma and Period with a space.\n",
    "        for punct in [\",\",\".\",\"$\"]:\n",
    "            input_series = input_series.str.replace(punct,\" \")\n",
    "\n",
    "        #//*** Remove punctuation using the example from the book\n",
    "        punctuation = dict.fromkeys(i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P') )\n",
    "        input_series = input_series.str.translate(punctuation)\n",
    "\n",
    "    print(f\"Text Cleaning Time: {time.time() - start_time}\")\n",
    "\n",
    "    return input_series\n",
    "#//*** Remove Stop words from the input list\n",
    "def remove_stop_words(input_series):\n",
    "    \n",
    "    #//*** This function removes stop_words from a series.\n",
    "    #//*** Works with series.apply()\n",
    "    def apply_stop_words(input_list):\n",
    "\n",
    "        #//*** Load Stopwords   \n",
    "        for word in input_list:\n",
    "            if word in stop_words:\n",
    "                input_list.remove(word)\n",
    "        return input_list\n",
    "\n",
    "    #//*** import nltk if needed\n",
    "    try:\n",
    "        type(nltk)\n",
    "    except:\n",
    "        import nltk\n",
    "        \n",
    "    stopwords = nltk.corpus.stopwords\n",
    "\n",
    "    #//*** Stopwords requires an additional download\n",
    "    try:\n",
    "        type(stopwords)\n",
    "    except:\n",
    "        nltk.download('stopwords')\n",
    "\n",
    "\n",
    "    #//*** import time library\n",
    "    try:\n",
    "        type(time)\n",
    "    except:\n",
    "        import time\n",
    "\n",
    "    #//*** Start Timing the process\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    #//*** The stop_words include punctuation. Stop Word Contractions will not be filtered out.\n",
    "    stop_words = []\n",
    "\n",
    "    #//*** Remove apostrophies from the stop_words\n",
    "    for stop in stopwords.words('english'):\n",
    "        stop_words.append(stop.replace(\"'\",\"\"))\n",
    "\n",
    "    \n",
    "    #//*** Remove Stop words from the tokenized strings in the 'process' column\n",
    "    #input_series = input_series.apply(remove_stop_words,stop_words)\n",
    "    \n",
    "    input_series = input_series.apply(apply_stop_words)\n",
    "\n",
    "    print(f\"Stop Words Time: {time.time() - start_time}\")\n",
    "    \n",
    "    return input_series\n",
    "#//*** Tokenize a Series containing Strings.\n",
    "#//*** Breaking this out into it's own function for later reuse.\n",
    "#//*** Not a lot of code here, but it helps to keep the libraries localized. This creates standarization for future\n",
    "#//*** Stoneburner projects. Also has the ability to add functionality as needed.\n",
    "\n",
    "def tokenize_series(input_series):\n",
    "    \n",
    "    try:\n",
    "        type(nltk)\n",
    "    except:\n",
    "        import nltk\n",
    "    \n",
    "    word_tokenize = nltk.tokenize.word_tokenize \n",
    "    \n",
    "    #//*** import time library\n",
    "    try:\n",
    "        type(time)\n",
    "    except:\n",
    "        import time\n",
    "    \n",
    "    #//*** Start Timing the process\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        input_series = input_series.apply(word_tokenize)\n",
    "    except:\n",
    "        #//*** Try again is punkt not downloaded\n",
    "        nltk.download('punkt')\n",
    "        input_series = input_series.apply(word_tokenize)\n",
    "        \n",
    "    \n",
    "    print(f\"Tokenize Time: {time.time() - start_time}\")\n",
    "    \n",
    "    return input_series\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
