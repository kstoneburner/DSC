{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ad90e15",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/data-science-skills-web-scraping-javascript-using-python-97a29738353f\n",
    "\n",
    "https://exceptionshub.com/selenium-cant-click-element-because-other-element-obscures-it.html\n",
    "\n",
    "https://www.toolsqa.com/selenium-webdriver/handle-iframes-in-selenium/\n",
    "\n",
    "https://www.selenium.dev/documentation/webdriver/elements/finders/\n",
    "\n",
    "https://www.selenium.dev/selenium/docs/api/javascript/module/selenium-webdriver/index_exports_By.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0473787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d6e2c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import time, datetime, requests,random, os, hashlib\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import pandas as pd\n",
    "#//*** install xlsxwriter for pandas\n",
    "#pip install xlsxwriter\n",
    "\n",
    "#//*********************************************************\n",
    "#//*** Build the tgt_date from the slected Quarter and Year\n",
    "#//*********************************************************\n",
    "tgt_year = 2022\n",
    "quarter = \"Q3\"\n",
    "\n",
    "if quarter == \"Q1\":\n",
    "    tgt_date = f\"{tgt_year}-01-01\"\n",
    "elif quarter == \"Q2\": \n",
    "    tgt_date = f\"{tgt_year}-04-01\"\n",
    "elif quarter == \"Q3\": \n",
    "    tgt_date = f\"{tgt_year}-07-01\"\n",
    "elif quarter == \"Q4\": \n",
    "    tgt_date = f\"{tgt_year}-10-01\"\n",
    "\n",
    "tgt_date = datetime.datetime.strptime(tgt_date, \"%Y-%m-%d\")\n",
    "\n",
    "print(tgt_date)\n",
    "\n",
    "#//*** Get Filename for dataframe Cache\n",
    "cache_filepath =  f\"{tgt_year}_{quarter}_scripts.dat\"\n",
    "current_dir = Path(os.getcwd()).absolute()\n",
    "cache_filepath = current_dir.joinpath(cache_filepath)\n",
    "\n",
    "#//*** If Cache File Exists Load it. Else Start a Fresh DataFrame\n",
    "if os.path.exists(cache_filepath):\n",
    "    cache_df = pd.read_pickle(cache_filepath)\n",
    "else:\n",
    "    cache_df = pd.DataFrame()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cb8b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Parses a \n",
    "def get_scripts(source_urls,headless=True):\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    #//*** Initialize Headless Firefox options \n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument('-headless')   \n",
    "    \n",
    "    if headless:\n",
    "\n",
    "\n",
    "        #//*** Span Headless Instance\n",
    "        page_driver = webdriver.Firefox(options=options)\n",
    "    else:\n",
    "        # run firefox webdriver from executable path of your choice\n",
    "        page_driver = webdriver.Firefox()\n",
    "\n",
    "    \n",
    "    \n",
    "    for i,url in enumerate(source_urls):\n",
    "        \n",
    "        print(f\"({i+1}/{len(source_urls)}) - {url}\")\n",
    "        try:\n",
    "            page_driver.get(url)\n",
    "        except:\n",
    "            print(\"Problem Getting Page...Skipping\")\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        try:\n",
    "        \n",
    "            loop_story = {\n",
    "                \"url\" : url,\n",
    "                \"headline\" : page_driver.find_elements(By.CLASS_NAME,\"headline\")[0].text,\n",
    "                \"time_text\" : page_driver.find_elements(By.CLASS_NAME,\"lastmodified\")[0].text,\n",
    "                \"body_text\" : page_driver.find_elements(By.CLASS_NAME,\"body-text\")[0].text,\n",
    "            }\n",
    "            #//*** Split the Date\n",
    "            loop_story['time_date'] = loop_story['time_text'].split()\n",
    "\n",
    "            #//*** Rebuild Date string using only the first four fields. Drop the extra time\n",
    "            loop_story['time_date'] = \" \".join(loop_story['time_date'][:4])\n",
    "\n",
    "            loop_story['time_date'] = datetime.datetime.strptime(loop_story['time_date'], \"%A, %B %d, %Y\")\n",
    "        except:\n",
    "            print(\"Problem Processing Story. Skipping\")\n",
    "            continue\n",
    "        out.append(loop_story)\n",
    "        \n",
    "        #wait between 1/2 to 3 seconds\n",
    "        time.sleep(random.randint(500, 3000)/1000)                                                              \n",
    "\n",
    "    page_driver.quit()\n",
    "                                                                        \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b701b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    \n",
    "def get_all_urls_in_page(source_url,tgt_date,headless=True):\n",
    "\n",
    "    #//*** Keep all classnames in a dictionary\n",
    "    g = {\n",
    "        #//*** Classname for the Show More Button\n",
    "        \"class_more_button\" : \"show-button-more\",\n",
    "        \n",
    "        #//*** Grid Classname that contains the linked stories\n",
    "        \"story_grid\" : \"grid3\",\n",
    "        \n",
    "        #//*** Story Classes that contain the href Links\n",
    "        \"story_link_class\" : \"AnchorLink\",\n",
    "        \n",
    "    }\n",
    "    \n",
    "    #//*** Initialize Headless Firefox options \n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument('-headless')   \n",
    "    \n",
    "    if headless:\n",
    "\n",
    "\n",
    "        #//*** Span Headless Instance\n",
    "        driver = webdriver.Firefox(options=options)\n",
    "    else:\n",
    "        # run firefox webdriver from executable path of your choice\n",
    "        driver = webdriver.Firefox()\n",
    "\n",
    "\n",
    "    # Load Web Page\n",
    "    driver.get(source_url)\n",
    "    \n",
    "    # execute script to scroll down the page\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "\n",
    "\n",
    "    #//*****************************************************\n",
    "    #//*** Wait until the Show More Button is loaded\n",
    "    #//*****************************************************\n",
    "    elements = []\n",
    "    control = 0\n",
    "    while len(elements) == 0:\n",
    "\n",
    "        #//*** Page is Loaded when class_more_button is displayed\n",
    "        #elements = driver.find_elements_by_class_name(g[\"class_more_button\"])\n",
    "        elements = driver.find_elements(By.CLASS_NAME,g[\"class_more_button\"])\n",
    "\n",
    "        control += 1\n",
    "        #//*** Wait if element not found\n",
    "        if len(elements) == 0:\n",
    "            time.sleep(1)\n",
    "\n",
    "        if control > 15:\n",
    "            print(\"Show More Button Not Loaded!\")\n",
    "            return\n",
    "            break\n",
    "\n",
    "    #//*************************************************\n",
    "    #//*** The first elements is the button to click\n",
    "    #//*************************************************\n",
    "    elem_show_more = elements[0]\n",
    "\n",
    "    #actions = ActionChains(driver)\n",
    "    #actions.move_to_element(element).perform()\n",
    "\n",
    "    print(elem_show_more.is_displayed())\n",
    "    print(elem_show_more.location['y'])\n",
    "    \n",
    "    #results = driver.find_elements_by_class_name(g[\"story_grid\"])[0].find_elements_by_class_name(g[\"story_link_class\"])\n",
    "    results = driver.find_elements(By.CLASS_NAME,g[\"story_grid\"])[0].find_elements(By.CLASS_NAME,g[\"story_link_class\"])\n",
    "\n",
    "    if len(results) > 0:\n",
    "        print(\"Last Page: \", results[0].get_property('href'))\n",
    "\n",
    "    \n",
    "    \n",
    "    #print(results[-1].get_property('href'))\n",
    "\n",
    "    \n",
    "    #print(story_time,tgt_date, story_time < tgt_date)\n",
    "                                                                        \n",
    "    #//*** Get the last url to check in stories are within the quarter\n",
    "    last_url = results[-1].get_property('href')\n",
    "    \n",
    "    try:\n",
    "        #//*** Download the last script\n",
    "        last_script = get_scripts([last_url])[0]\n",
    "    except:\n",
    "        print(\"Problem getting last script\")\n",
    "        print(\"Last url: \", last_url)\n",
    "        print(\"get Scripts: \", get_scripts([last_url]))\n",
    "        print(\"Skipping..\")\n",
    "        return []\n",
    "    last_date = last_script['time_date']\n",
    "    print(\"Last Script: \", last_script['headline'],\"\\n\",last_script[\"time_text\"])\n",
    "    print(\"Last Script: \", last_script['time_date'] < tgt_date)\n",
    "    \n",
    "    #//*** Maximum number of while loops.\n",
    "    maxDepth = 20\n",
    "    depth = 0\n",
    "    \n",
    "    #//*** Click Show More until Last Story is older than the tgt_date\n",
    "    while last_date > tgt_date:\n",
    "        depth += 1\n",
    "        \n",
    "        #//*** Scroll to Bottom of page\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var lenOfPage=document.body.scrollHeight;return lenOfPage;\")\n",
    "        \n",
    "        print(f\"Clicking More Depth: {depth}\")\n",
    "        #print(dir(elem_show_more))\n",
    "        while elem_show_more.is_displayed() == False:\n",
    "            print(\"Is Displayed:\",str(elem_show_more.is_displayed()))\n",
    "            time.sleep(1)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            #//*** Click Show More\n",
    "            elem_show_more.click()\n",
    "        except:\n",
    "            iframes = driver.find_elements_by_tag_name(\"iframe\")\n",
    "            for iframe in iframes:\n",
    "                print(iframe.get_property(\"name\"))\n",
    "                \n",
    "                \n",
    "                driver.execute_script(\"arguments[0].style.visibility='hidden'\", iframe)\n",
    "            #//*** Click Show More\n",
    "            elem_show_more.click()\n",
    "                \n",
    "        #    return\n",
    "\n",
    "    \n",
    "        #//*** Get Updated Results\n",
    "        #results = driver.find_elements_by_class_name(g[\"story_grid\"])[0].find_elements_by_class_name(g[\"story_link_class\"])        \n",
    "        results = driver.find_elements(By.CLASS_NAME,g[\"story_grid\"])[0].find_elements(By.CLASS_NAME,g[\"story_link_class\"])        \n",
    "        \n",
    "        #//*** Get the last url to check in stories are within the quarter\n",
    "        last_url = results[-1].get_property('href')\n",
    "\n",
    "        #//*** Download the last script\n",
    "        last_script = get_scripts([last_url])[0]\n",
    "        last_date = last_script['time_date']\n",
    "        print(\"Last Script: \", last_script['headline'],\"\\n\",last_script[\"time_text\"])\n",
    "        print(\"Last Script: \", last_script['time_date'] < tgt_date)\n",
    "\n",
    "        if depth > maxDepth:\n",
    "            print(\"Maximum Depth Reached on Clicking Show More\")\n",
    "            break\n",
    "        \n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    for result in results:\n",
    "        out.append(result.get_property('href'))\n",
    "    \n",
    "    #//*** Shut down main scrape\n",
    "    driver.quit()\n",
    "    \n",
    "    \n",
    "\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d3156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Hash url list and compare to cache_df\n",
    "#//*** returns a tuple of urls (orig_urls,dupe_urls)\n",
    "def keep_original_urls(urls,cache_df):\n",
    "    orig_urls = []\n",
    "    dupe_urls = []\n",
    "    \n",
    "    tdf = pd.DataFrame()\n",
    "    tdf['urls'] = urls\n",
    "    \n",
    "    tdf['hash'] = pd.util.hash_pandas_object(tdf['urls'])\n",
    "\n",
    "\n",
    "    #//*** Check for Duplicates\n",
    "    tdf['dupe'] = tdf['hash'].isin(cache_df['hash'])\n",
    "    #tdf['dupe'] = tdf['urls'].isin(cache_df['urls'])\n",
    "    \n",
    "    #//*** Keep Only False Stories, which are not duplicates\n",
    "    #//*** This means a story can have only a single category.\n",
    "    #//*** May have to handle multiple categories at a future time\n",
    "    #print(f\"Length Before: {len(tdf)} \")\n",
    "\n",
    "    orig_urls = list(tdf[tdf['dupe'] == False]['urls'])\n",
    "    dupe_urls = list(tdf[tdf['dupe'] == True]['urls'])\n",
    "\n",
    "    \n",
    "    \n",
    "    return orig_urls,dupe_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88fc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82db4a2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1797\n",
      "Last Page:  https://abc7news.com/president-joe-biden-climate-change-emergency-declaration-combating/12061980/\n",
      "(1/1) - https://abc7news.com/marine-heat-wave-norcal-cal-academy-of-sciences-life-ocean/11818189/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/marine-heat-wave-norcal-cal-academy-of-sciences-life-ocean/11818189/\n",
      "(1/1) - https://abc7news.com/marine-heat-wave-norcal-cal-academy-of-sciences-life-ocean/11818189/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Climate\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1797\n",
      "Last Page:  https://abc7news.com/california-drought-water-always-wins-erica-gies-controlling-destructive-flooding-solutions/11999408/\n",
      "(1/1) - https://abc7news.com/california-drought-santa-cruz-county-seawater-intrusion-soquel-creek-water-district/11869614/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/california-drought-santa-cruz-county-seawater-intrusion-soquel-creek-water-district/11869614/\n",
      "(1/1) - https://abc7news.com/california-drought-santa-cruz-county-seawater-intrusion-soquel-creek-water-district/11869614/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Environment\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1766\n",
      "Last Page:  https://abc7news.com/recession-economy-jerome-powell-labor-market/12079275/\n",
      "(1/1) - https://abc7news.com/california-great-america-closing-to-close-in-11-years-ca-land-sold-greatpro-logis/11999946/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/california-great-america-closing-to-close-in-11-years-ca-land-sold-greatpro-logis/11999946/\n",
      "(1/1) - https://abc7news.com/california-great-america-closing-to-close-in-11-years-ca-land-sold-greatpro-logis/11999946/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Economy\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1797\n",
      "Last Page:  https://abc7news.com/abc7-harassment-sexual-workplace/3143891/\n",
      "(1/1) - https://abc7news.com/remote-work-changing-workplace-pandemic-benefits-company-paying-for-student-loans/11790069/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/remote-work-changing-workplace-pandemic-benefits-company-paying-for-student-loans/11790069/\n",
      "(1/1) - https://abc7news.com/remote-work-changing-workplace-pandemic-benefits-company-paying-for-student-loans/11790069/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Jobs\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1797\n",
      "Last Page:  https://abc7news.com/what-is-rape-sexual-assault-definition-harassment/4305758/\n",
      "(1/1) - https://abc7news.com/sf-pride-sfpd-police-chief-parade-safety/11993953/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/sf-pride-sfpd-police-chief-parade-safety/11993953/\n",
      "(1/1) - https://abc7news.com/sf-pride-sfpd-police-chief-parade-safety/11993953/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Safety\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1823\n",
      "Last Page:  https://abc7news.com/bay-area-local-heroes-suney-park-mostly-old-guys-united/7945/\n",
      "(1/1) - https://abc7news.com/travis-barker-hospitalized-pancreatitis-kourtney-kardashians/12014232/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/travis-barker-hospitalized-pancreatitis-kourtney-kardashians/12014232/\n",
      "(1/1) - https://abc7news.com/travis-barker-hospitalized-pancreatitis-kourtney-kardashians/12014232/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Health\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1796\n",
      "Last Page:  https://abc7news.com/sfusd-ann-hsu-san-francisco-admonish-racially-insensitive-comments/12094767/\n",
      "(1/1) - https://abc7news.com/roe-v-wade-overturned-abortion-access-impact-on-college-students-supreme-court-decision-application-process/12007009/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/roe-v-wade-overturned-abortion-access-impact-on-college-students-supreme-court-decision-application-process/12007009/\n",
      "(1/1) - https://abc7news.com/roe-v-wade-overturned-abortion-access-impact-on-college-students-supreme-court-decision-application-process/12007009/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Education\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1807\n",
      "Last Page:  https://abc7news.com/aapi-aanhpi-asian-american-and-pacific-islander-how-to-help/10580778/\n",
      "(1/1) - https://abc7news.com/juneteenth-galveston-texas-freedom-walk-emancipation-proclamation/11970627/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/juneteenth-galveston-texas-freedom-walk-emancipation-proclamation/11970627/\n",
      "(1/1) - https://abc7news.com/juneteenth-galveston-texas-freedom-walk-emancipation-proclamation/11970627/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Race\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1818\n",
      "Last Page:  https://abc7news.com/east-bay-mud-gender-discrimination-lawsuit-ebmud-workplace-allegation-area-utility/11945717/\n",
      "(1/1) - https://abc7news.com/jp-morgan-chase-bank-discrimination-lawsuit/11532589/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/jp-morgan-chase-bank-discrimination-lawsuit/11532589/\n",
      "(1/1) - https://abc7news.com/jp-morgan-chase-bank-discrimination-lawsuit/11532589/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Discrimination\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1804\n",
      "Last Page:  https://abc7news.com/nyc-subway-shooting-frank-james-fbi-civil-rights/11801180/\n",
      "(1/1) - https://abc7news.com/title-ix-protections-transgender-department-of-education-for-students/10797768/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/title-ix-protections-transgender-department-of-education-for-students/10797768/\n",
      "(1/1) - https://abc7news.com/title-ix-protections-transgender-department-of-education-for-students/10797768/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: Civil Rights\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1797\n",
      "Last Page:  https://abc7news.com/safe-injection-sites-california-sb-57-newsom-sf-drug-site/12096838/\n",
      "(1/1) - https://abc7news.com/disability-pride-month-mental-health-ableism-hidden-disabilities/12079231/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/disability-pride-month-mental-health-ableism-hidden-disabilities/12079231/\n",
      "(1/1) - https://abc7news.com/disability-pride-month-mental-health-ableism-hidden-disabilities/12079231/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: BABBA\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1807\n",
      "Last Page:  https://abc7news.com/zelle-scam-bank-of-america-impostor-scammers-get-personal-information/12079118/\n",
      "(1/1) - https://abc7news.com/amazon-prime-day-sale-deals-membership/12033229/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/amazon-prime-day-sale-deals-membership/12033229/\n",
      "(1/1) - https://abc7news.com/amazon-prime-day-sale-deals-membership/12033229/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: 7OYS\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1807\n",
      "Last Page:  https://abc7news.com/covid-ba5-variant-ucsf-infectious-diseases-specialist-dr-peter-chin-hong-omicron-transmission/12102247/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/1) - https://abc7news.com/starbread-bakery-pittsburg-east-bay-attacked-covid-guidelines/12067950/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/starbread-bakery-pittsburg-east-bay-attacked-covid-guidelines/12067950/\n",
      "(1/1) - https://abc7news.com/starbread-bakery-pittsburg-east-bay-attacked-covid-guidelines/12067950/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: COVID\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n",
      "True\n",
      "1818\n",
      "Last Page:  https://abc7news.com/san-mateo-county-sheriff-carlos-bolanos-batmobile-raid-indiana-fiberglass-freaks-of-logansport-factory-raided/12094674/\n",
      "(1/1) - https://abc7news.com/daily-harvest-lentil-crumble-recall-ceo-rachel-drori-customer-hospitalized/12010257/\n",
      "Problem Processing Story. Skipping\n",
      "Problem getting last script\n",
      "Last url:  https://abc7news.com/daily-harvest-lentil-crumble-recall-ceo-rachel-drori-customer-hospitalized/12010257/\n",
      "(1/1) - https://abc7news.com/daily-harvest-lentil-crumble-recall-ceo-rachel-drori-customer-hospitalized/12010257/\n",
      "Problem Processing Story. Skipping\n",
      "get Scripts:  []\n",
      "Skipping..\n",
      "=====================\n",
      "Category: I-TEAM\n",
      "=====================\n",
      "DL Items: 0 - Duplicate: 0\n",
      "No New Items to Download!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url_items = [\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/climate-change/\",\n",
    "        \"cat\" : \"Climate\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/environment/\",\n",
    "        \"cat\" : \"Environment\"\n",
    "    },\n",
    " \n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/economy/\",\n",
    "        \"cat\" : \"Economy\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/jobs/\",\n",
    "        \"cat\" : \"Jobs\"\n",
    "    },    \n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/safety/\",\n",
    "        \"cat\" : \"Safety\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/health/\",\n",
    "        \"cat\" : \"Health\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/education/\",\n",
    "        \"cat\" : \"Education\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/race-and-culture/\",\n",
    "        \"cat\" : \"Race\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/discrimination/\",\n",
    "        \"cat\" : \"Discrimination\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/civil-rights/\",\n",
    "        \"cat\" : \"Civil Rights\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/building-a-better-bay-area/\",\n",
    "        \"cat\" : \"BABBA\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/7onyourside/\",\n",
    "        \"cat\" : \"7OYS\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/covid-19/\",\n",
    "        \"cat\" : \"COVID\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/iteam/\",\n",
    "        \"cat\" : \"I-TEAM\"\n",
    "    },\n",
    "    \n",
    "\n",
    "    \n",
    "]\n",
    "urlpages = ['https://abc7news.com/education/',\n",
    "            'https://abc7news.com/tag/building-a-better-bay-area/',\n",
    "            'https://abc7news.com/7onyourside/',\n",
    "            'https://abc7news.com/tag/covid-19/',\n",
    "            'https://abc7news.com/tag/climate-change/',\n",
    "            'https://abc7news.com/iteam/'\n",
    "           ]\n",
    "\n",
    "#urlpage ='https://abc7news.com/education/'\n",
    "#urls = get_all_urls_in_page(urlpages[1],tgt_date,False)\n",
    "#print(urlpage)\n",
    "\n",
    "#//*** Loop through top level url_items\n",
    "for item in url_items:\n",
    "    cat_url = item['url']\n",
    "    cat = item['cat']\n",
    "    \n",
    "    #//*** Download the ctageory URLs\n",
    "    urls = get_all_urls_in_page(cat_url,tgt_date,False)\n",
    "    \n",
    "    #//*** Get non-duplicate urls to download and a list of the duplicate urls\n",
    "    #//*** We may need to incorporate duplicates with different categories...later\n",
    "    if len(cache_df) > 0:\n",
    "        urls_to_dl,dupe_urls = keep_original_urls(urls,cache_df)\n",
    "    else:\n",
    "        #//*** There is no cache initialize and move one\n",
    "        urls_to_dl = urls\n",
    "        dupe_urls = []\n",
    "    print(\"=====================\")\n",
    "    print(f\"Category: {cat}\")\n",
    "    print(\"=====================\")\n",
    "    print(f\"DL Items: {len(urls_to_dl)} - Duplicate: {len(dupe_urls)}\")\n",
    "    \n",
    "    if len(urls_to_dl) == 0:\n",
    "        print(\"No New Items to Download!\")\n",
    "    \n",
    "    if len(urls_to_dl) > 0:\n",
    "        scripts = get_scripts(urls_to_dl)\n",
    "        \n",
    "        #//*** Convert Scripts to DataFrame\n",
    "        df = pd.DataFrame()\n",
    "        #df['urls'] = urls_to_dl\n",
    "\n",
    "        s = {}\n",
    "\n",
    "        #//*** Get each script value as a list\n",
    "        for script in scripts:\n",
    "\n",
    "            for key,value in script.items():\n",
    "                if key not in s.keys():\n",
    "                    s[key] = []\n",
    "                s[key].append(value)\n",
    "\n",
    "        #//*** build Urls field\n",
    "        #//*** Use the Story URL in case an url was skipped.\n",
    "        df['urls'] = s['url']\n",
    "        df['hash'] = pd.util.hash_pandas_object(df['urls'])\n",
    "        df['cat'] = cat\n",
    "\n",
    "        #//*** Add lists of script values as columns\n",
    "        for key,value in s.items():\n",
    "            df[key] = value\n",
    "\n",
    "        #//*** Combine cache_df and df\n",
    "        cache_df = pd.concat([cache_df,df])\n",
    "\n",
    "\n",
    "#//*** Everything is Gathered. Write Cache_df to disk\n",
    "#//*** Write DF to file\n",
    "pd.to_pickle(cache_df,cache_filepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4638fe5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(last_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f6375ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (Temp/ipykernel_15040/1988613226.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\stonk013\\AppData\\Local\\Temp/ipykernel_15040/1988613226.py\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    print(\"Length Before de-dupe:\",len(cache_df)\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "#cache_df['time_date'] = cache_df['time_date'].dt.date\n",
    "#print(\"Length Before de-dupe:\",len(cache_df)\n",
    "cache_df = cache_df.drop_duplicates(subset=\"url\")\n",
    "      \n",
    "print(\"Length Before de-dupe:\",len(cache_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d3c36ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022_Q3_Collected_Stories.xlsx\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\Selenium\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3621\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3622\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Selenium\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Selenium\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cat'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15040/2513959672.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msheet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl_item\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cat'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mtdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msheet\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'urls'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'time_date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'time_text'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'headline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'body_text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time_date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Selenium\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3504\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3505\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3506\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3507\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\Selenium\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3622\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3623\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3624\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3625\u001b[0m                 \u001b[1;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'cat'"
     ]
    }
   ],
   "source": [
    "#//*** Write to excel file\n",
    "output_filename = f\"{tgt_year}_{quarter}_Collected_Stories.xlsx\"\n",
    "print(output_filename)\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(output_filename, engine='xlsxwriter')\n",
    "\n",
    "#//*** Build Sheet and Data from From each url_item element\n",
    "for url_item in url_items:\n",
    "    sheet = url_item['cat']\n",
    "    \n",
    "    tdf = cache_df[cache_df['cat'] == sheet].copy()\n",
    "    \n",
    "    tdf = tdf[['urls','time_date','time_text','headline','body_text']].sort_values('time_date',ascending=False)\n",
    "    \n",
    "    tdf.to_excel(writer,sheet_name=sheet)\n",
    "    \n",
    "try:\n",
    "    writer.save()    \n",
    "except:\n",
    "    print(\"Trouble Saving the Spreadsheet. It's Probably Open Somewhere. Close it and Retry\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9658c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76957a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_df.drop_duplicates(subset=\"url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25667394",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_items = [\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/climate-change/\",\n",
    "        \"cat\" : \"Climate\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/environment/\",\n",
    "        \"cat\" : \"Environment\"\n",
    "    },\n",
    " \n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/economy/\",\n",
    "        \"cat\" : \"Economy\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/jobs/\",\n",
    "        \"cat\" : \"Jobs\"\n",
    "    },    \n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/safety/\",\n",
    "        \"cat\" : \"Safety\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/health/\",\n",
    "        \"cat\" : \"Health\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/education/\",\n",
    "        \"cat\" : \"Education\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/race-and-culture/\",\n",
    "        \"cat\" : \"Race\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/discrimination/\",\n",
    "        \"cat\" : \"Discrimination\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/civil-rights/\",\n",
    "        \"cat\" : \"Civil Rights\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/building-a-better-bay-area/\",\n",
    "        \"cat\" : \"BABBA\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/7onyourside/\",\n",
    "        \"cat\" : \"7OYS\"\n",
    "    },\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/tag/covid-19/\",\n",
    "        \"cat\" : \"COVID\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"url\" : \"https://abc7news.com/iteam/\",\n",
    "        \"cat\" : \"I-TEAM\"\n",
    "    },\n",
    "    \n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "cache_df['time_date'] = cache_df['time_date'].dt.date\n",
    "\n",
    "#//*** Write to excel file\n",
    "output_filename = f\"{tgt_year}_{quarter}_Collected_Stories.xlsx\"\n",
    "print(output_filename)\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter(output_filename, engine='xlsxwriter')\n",
    "\n",
    "#//*** Build Sheet and Data from From each url_item element\n",
    "for url_item in url_items:\n",
    "    sheet = url_item['cat']\n",
    "    \n",
    "    tdf = cache_df[cache_df['cat'] == sheet].copy()\n",
    "    \n",
    "    tdf = tdf[['urls','time_date','time_text','headline','body_text']]\n",
    "    \n",
    "    tdf.to_excel(writer,sheet_name=sheet)\n",
    "    \n",
    "try:\n",
    "    writer.save()    \n",
    "except:\n",
    "    print(\"Trouble Saving the Spreadsheet. It's Probably Open Somewhere. Close it and Retry\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98baa66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f513df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8228ddfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1/1) - https://abc7news.com/california-drought-santa-cruz-county-seawater-intrusion-soquel-creek-water-district/11869614/\n",
      "Problem Processing Story. Skipping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = ['https://abc7news.com/california-drought-santa-cruz-county-seawater-intrusion-soquel-creek-water-district/11869614/']\n",
    "get_scripts(urls,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28b9507",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_driver = webdriver.Firefox()\n",
    "page_driver.get(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dab1c89a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15040/3617944649.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m loop_story = {\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m\"url\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;34m\"headline\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mpage_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"headline\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;34m\"time_text\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mpage_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"lastmodified\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m\"body_text\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mpage_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLASS_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"body-text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "url = urls[0]\n",
    "loop_story = {\n",
    "    \"url\" : url,\n",
    "    \"headline\" : page_driver.find_elements(By.CLASS_NAME,\"headline\")[0].text,\n",
    "    \"time_text\" : page_driver.find_elements(By.CLASS_NAME,\"lastmodified\")[0].text,\n",
    "    \"body_text\" : page_driver.find_elements(By.CLASS_NAME,\"body-text\")[0].text,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ec116d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'WebDriver' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15040/387324822.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpage_driver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'WebDriver' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "page_driver.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#//*** Split the Date\n",
    "loop_story['time_date'] = loop_story['time_text'].split()\n",
    "\n",
    "#//*** Rebuild Date string using only the first four fields. Drop the extra time\n",
    "loop_story['time_date'] = \" \".join(loop_story['time_date'][:4])\n",
    "\n",
    "loop_story['time_date'] = datetime.datetime.strptime(loop_story['time_date'], \"%A, %B %d, %Y\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
