{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 540 - Week 05/06\n",
    "- ## Chapter 5, Activity7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity you are given the Wikipedia page where we have the GDP of all countries listed and you are asked to create three data frames from the three sources mentioned in the page ( link - https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal) )\n",
    "\n",
    "You will have to -\n",
    "\n",
    "- Open the page in a separate chrome/firefox tab and use something like `inspect element` tool to see the source HTML and understand the structure\n",
    "- Read the page using bs4\n",
    "- Find the table structure you will need to deal with (how many tables are there)\n",
    "- Find the right table using bs4\n",
    "- Separate the Source Names and their corresponding data\n",
    "- Get the source names from the list of sources you have created\n",
    "- Seperate the header and data from the data that you separated before. For the first source only. And then create a DataFrame using that\n",
    "- Repeat the last task for the other two data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //****************************************************************************************\n",
    "# //*** Set Working Directory to thinkstats folder.\n",
    "# //*** This pseudo-relative path call should work on all Stoneburner localized projects. \n",
    "# //****************************************************************************************\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "#//*** Going to use the requests library, since it's the same library used for API calls\n",
    "import requests\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource:\n",
    "- https://generalistprogrammer.com/python/python-web-scraping-tutorial-with-beautifulsoup-and-requests/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Use Requests to get the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Verify Response is ok. This *should* be analogous to checking if the response code is 200\n",
    "if response.ok == True: \n",
    "    #//*** Make soup...Beautiful Soup\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "else:\n",
    "    print(\"Problem with the URL Request\")\n",
    "    \n",
    "#//*** The tables all have the class name wikitable\n",
    "#//*** Discard the first table, which is a container for the other three.\n",
    "tables = soup.find_all('table', class_='wikitable')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Use the tableCounter to keep track of which table we are working in.\n",
    "#//*** If we were super cool, we'd tie something in to using the first row of the maintable to keep track of \n",
    "#//*** Of which table/dataframe is which. But since we are looking for very specific things, it doesn't make\n",
    "#//*** sense to invest in a more robust structure, since any slight change of source code will break the\n",
    "#//*** whole scrape.\n",
    "\n",
    "#//*** Personally, I'd skip Beautiful Soup and just use Regex. Mostly, because regex is universal and be applies\n",
    "#//*** to other scenarios as well as other languages. It is is very useful across many tasks. I've also written \n",
    "#//*** an HTML parser in javascript using HTML. It was for a project where news talent reads scripts off of an iPad\n",
    "#//*** instead of paper scripts.\n",
    "\n",
    "#//*** The book uses a very pythonic single line method to generate a multi dimensional array. I'm not a fan of \n",
    "#//*** that in general. I prefer more readable verbose code.\n",
    "\n",
    "#//*** We'll deviate from the assignment a bit by handling all three tables in a loop. What works once\n",
    "#//*** should work thrice.\n",
    "\n",
    "#//*** tableCounter helps keep track of which of the three tables we are working in. This is required\n",
    "#//*** when determining which of the three dataframes to build\n",
    "tableCounter = 0\n",
    "\n",
    "#//*** Parse Each table\n",
    "for table in tables:\n",
    "    tableCounter+=1\n",
    "    \n",
    "    #//************************************\n",
    "    #//*** Build Table Headers\n",
    "    #//************************************\n",
    "    #//*** Get the Table Headers. These will be our data frame Columns.\n",
    "    ths = table.find_all(\"th\")\n",
    "    #//*** initialize a list to hold the column names\n",
    "    colnames = []\n",
    "    \n",
    "    #//*** Columnnames are the first value contained in contents\n",
    "    for th in ths:\n",
    "        colnames.append(th.contents[0])\n",
    "    \n",
    "    #//**********************************\n",
    "    #//*** Initialize tableDict.\n",
    "    #//**********************************\n",
    "    #//*** tableDict is a dictionary container to hold row data.\n",
    "    #//*** The tableDict will hold each of the row lists. The keys will be each colname\n",
    "    tableDict = {}\n",
    "    \n",
    "    #//*** Initialize tableDict\n",
    "    for name in colnames:\n",
    "        tableDict[name] = []\n",
    "    \n",
    "    #//***********************************************\n",
    "    #//*** Process each tablerow\n",
    "    #//*** The sausage is primarily made here\n",
    "    #//***********************************************\n",
    "    \n",
    "    #//*** Get a BS list of table rows \n",
    "    trs = table.find_all(\"tr\")\n",
    "    \n",
    "    #//*** For each table row in tablerows\n",
    "    for tr in trs:\n",
    "        #//*** Skip the table header\n",
    "        if len(tr.find_all(\"th\")) == 0:\n",
    "            #//*** Loop through the colnames Index\n",
    "            #//*** The gets the key value to store the TD data\n",
    "            #//*** Get a TD with a corresponding index value and extract the text\n",
    "            for x in range(0,len(colnames)):\n",
    "                #//*** Append the text to the appropriate colname list.\n",
    "                #//*** Using index values keeps everthing aligned.\n",
    "                tableDict[colnames[x]].append(tr.find_all('td')[x].text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "    #//**************************************************************************************\n",
    "    #//*** Table is fully parsed into the tableDict\n",
    "    #//*** Remove the first element of each list. It contains the World Summary numbers\n",
    "    #//**************************************************************************************\n",
    "    for key in tableDict.keys():\n",
    "        tableDict[key].pop(0)\n",
    "        \n",
    "    #//*********************************************************\n",
    "    #//*** Convert tableDict into a dataframe.\n",
    "    #//*** the individual df is determined by the tableCounter\n",
    "    #//*********************************************************\n",
    "    if tableCounter == 1:\n",
    "        #//*** Create the IMF Dataframe\n",
    "        imf_df = pd.DataFrame()\n",
    "        \n",
    "        #//*** Add each Column to dataframe\n",
    "        for x in colnames:\n",
    "            imf_df[x] = tableDict[x]\n",
    "    \n",
    "    elif tableCounter == 2:\n",
    "        #//*** Create the IMF Dataframe\n",
    "        worldbank_df = pd.DataFrame()\n",
    "        \n",
    "        #//*** Add each Column to dataframe\n",
    "        for x in colnames:\n",
    "            worldbank_df[x] = tableDict[x]\n",
    "        \n",
    "    elif tableCounter == 3:\n",
    "        #//*** Create the IMF Dataframe\n",
    "        un_df = pd.DataFrame()\n",
    "        \n",
    "        #//*** Add each Column to dataframe\n",
    "        for x in colnames:\n",
    "            un_df[x] = tableDict[x]\n",
    "    \n",
    "#//*********************************************************\n",
    "#//*** END table in tables\n",
    "#//*********************************************************\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#############\n",
      "IMF\n",
      "#############\n",
      "  Rank Country/Territory         GDP\n",
      "0    1     United States  20,807,269\n",
      "1    2   China[n 2][n 3]  14,860,775\n",
      "2    3             Japan   4,910,580\n",
      "3    4           Germany   3,780,553\n",
      "4    5    United Kingdom   2,638,296\n",
      "\n",
      "#############\n",
      "World Bank\n",
      "#############\n",
      "  Rank Country/Territory         GDP\n",
      "0    1     United States  21,427,700\n",
      "1    2        China[n 9]  14,342,903\n",
      "2    3             Japan   5,081,770\n",
      "3    4           Germany   3,845,630\n",
      "4    5             India   2,875,142\n",
      "\n",
      "#############\n",
      "UN\n",
      "#############\n",
      "  Rank Country/Territory         GDP\n",
      "0    1     United States  21,433,226\n",
      "1    2        China[n 9]  14,342,933\n",
      "2    3             Japan   5,082,465\n",
      "3    4           Germany   3,861,123\n",
      "4    5             India   2,891,582\n"
     ]
    }
   ],
   "source": [
    "        print(\"\\n#############\")\n",
    "        print(\"IMF\")\n",
    "        print(\"#############\")\n",
    "        print(imf_df.head())\n",
    "\n",
    "        print(\"\\n#############\")\n",
    "        print(\"World Bank\")\n",
    "        print(\"#############\")\n",
    "        print(worldbank_df.head())\n",
    "        \n",
    "        print(\"\\n#############\")\n",
    "        print(\"UN\")\n",
    "        print(\"#############\")\n",
    "        print(un_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6, Activity 08\n",
    "\n",
    "In this activity we do the following\n",
    "\n",
    "* Create a data frame from a given CSV\n",
    "* Check for duplicates in the columns that matter\n",
    "* Check for NaN in the columns that matter\n",
    "* Apply our domain knowledge to single out and remove outliers\n",
    "* Generate nice print statements as reports for differents steps\n",
    "\n",
    "The data set is a 1000 row data set which represnets the traffic on a certain page of a website. The Names, email, and IP are faked out in order to keep the privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data (the file name is - visit_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id first_name last_name                       email gender  \\\n",
      "0   1      Sonny      Dahl            sdahl0@mysql.com   Male   \n",
      "1   2        NaN       NaN           dhoovart1@hud.gov    NaN   \n",
      "2   3        Gar     Armal      garmal2@technorati.com    NaN   \n",
      "3   4    Chiarra     Nulty       cnulty3@newyorker.com    NaN   \n",
      "4   5        NaN       NaN  sleaver4@elegantthemes.com    NaN   \n",
      "\n",
      "        ip_address   visit  \n",
      "0    135.36.96.183  1225.0  \n",
      "1  237.165.194.143   919.0  \n",
      "2   166.43.137.224   271.0  \n",
      "3   139.98.137.108  1002.0  \n",
      "4    46.117.117.27  2434.0  \n"
     ]
    }
   ],
   "source": [
    "### Write your code bellow this comment\n",
    "base_df = pd.read_csv(\"z_sup_wk05_06_visit_data.csv\")\n",
    "print(base_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 1 (Are there duplicates?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for Duplicate Email addresses: False\n",
      "There don't appear to be duplicates in the data set\n"
     ]
    }
   ],
   "source": [
    "#//*** Use df.duplicated() to test for duplicate values in any row.\n",
    "print( f\"Test for Duplicate Email addresses: {base_df['email'].duplicated().any()}\")\n",
    "print(\"There don't appear to be duplicates in the data set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 2 (do any essential column contain NaN?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN in id: 0\n",
      "Number of NaN in email: 0\n",
      "Number of NaN in ip_address: 0\n",
      "Number of NaN in visit: 26\n",
      "The website traffic, visit column contains 26 NaN. These are likely outliers.\n"
     ]
    }
   ],
   "source": [
    "#//*** Build a list containing the essential column names\n",
    "essential_cols = ['id', 'email', 'ip_address','visit']\n",
    "\n",
    "#//*** Loop through the essential column names checking for NaN values.\n",
    "for col in essential_cols:\n",
    "    print(f\"Number of NaN in {col}: {sum(base_df[col].isna()==True)}\")\n",
    "\n",
    "print(\"The website traffic, visit column contains 26 NaN. These are likely outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 3 (Get rid of the outliers)\n",
    "\n",
    "Consider what are the essential columns if you are preparing this dataset for a model building exercise where the target is to predict number of visits given a user name, email, IP address, Gender etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Get the length of the dataframe before values are dropped.\n",
    "orig_len = len(base_df)\n",
    "\n",
    "#//*** Drop rows with NaN in the visit column.\n",
    "base_df = base_df.dropna(subset=['visit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 4 (Report the size difference)\n",
    "\n",
    "The `shape` method of a data frame gives you a tuple which represents (row, column) of the data frame, in this task you have to compare and report the number of rows before and after getting rid of the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Dataframe length: 1000 rows\n",
      "After removing NaN 26 visits, the length is: 974 rows and 7 columns\n"
     ]
    }
   ],
   "source": [
    "#//*** Use orig_len to display the original number of rows before dropping the Nans from visit\n",
    "print(f\"Orginal Dataframe length: {orig_len} rows\")\n",
    "\n",
    "#//*** Use df.shape() to report the dimensionality of the dataframe.\n",
    "print(f\"After removing NaN {orig_len - base_df.shape[0]} visits, the length is: {base_df.shape[0]} rows and {base_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 5 (Box plot visit to further check any Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x15afe4c8eb0>,\n",
       "  <matplotlib.lines.Line2D at 0x15afe4df250>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x15afe4df5b0>,\n",
       "  <matplotlib.lines.Line2D at 0x15afe4df910>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x15afe4c8b50>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x15afe4dfc70>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x15afe4dff70>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(base_df['visit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Insert data into a SQL Lite database – create a table with the following data (Hint: Python for Data Analysis page 191):\n",
    "\n",
    "a. Name, Address, City, State, Zip, Phone Number\n",
    "\n",
    "b. Add at least 10 rows of data and submit your code with a query generating your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Added the Faker Library to generate fake people.\n",
    "#//*** https://pypi.org/project/Faker/\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Anthony Marshall', 'address': '4296 Murphy Rapids', 'city': 'Cynthiafurt', 'state': 'IL', 'zip': '19939', 'phone': '(909)050-4619x69026'}\n",
      "{'name': 'Gregg Baker', 'address': '2549 Ronald Walk', 'city': 'Port Jennifer', 'state': 'VA', 'zip': '95533', 'phone': '996.317.6960'}\n",
      "{'name': 'Elizabeth Rich', 'address': '677 Michelle Pike', 'city': 'East Carolinefort', 'state': 'UT', 'zip': '60783', 'phone': '7460088038'}\n",
      "{'name': 'Gregory Cordova', 'address': '279 Powell Haven', 'city': 'East Paul', 'state': 'SD', 'zip': '05111', 'phone': '+1-624-801-4556x01453'}\n",
      "{'name': 'John Singleton', 'address': '70197 Carly Cliffs Suite 707', 'city': 'Andersonport', 'state': 'MT', 'zip': '37616', 'phone': '958-451-4571x48717'}\n"
     ]
    }
   ],
   "source": [
    "#//*** Build 100 fake people\n",
    "#//*** It's a loop, why stop at 10 people? Let's make it 100 hundred for grins and giggles.\n",
    "fake = Faker()\n",
    "\n",
    "#//**** People is a list containing a dictionary of people\n",
    "people = []\n",
    "for _ in range(100):\n",
    "    #//*** Store each entry in a person dictionary. Add each person to the people list\n",
    "    person = {}\n",
    "    person[\"name\"] = fake.name()\n",
    "    person['address'] = fake.street_address()\n",
    "    person['city'] = fake.city() \n",
    "    person['state'] = fake.state_abbr()\n",
    "    person['zip'] = fake.zipcode_in_state()\n",
    "    person['phone'] = fake.phone_number()\n",
    "    people.append(person)\n",
    "\n",
    "#//*** Display first 5 results, I mean people.\n",
    "#//*** And you get different people each time this runs.\n",
    "for x in range(5):\n",
    "    print(people[x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE People (name varchar(20), address varchar(20), city varchar(20), state varchar(20), zip varchar(20), phone varchar(20));\n",
      "(name, address, city, state, zip, phone)\n",
      "[('Anthony Marshall', '4296 Murphy Rapids', 'Cynthiafurt', 'IL', '19939', '(909)050-4619x69026'), ('Gregg Baker', '2549 Ronald Walk', 'Port Jennifer', 'VA', '95533', '996.317.6960'), ('Elizabeth Rich', '677 Michelle Pike', 'East Carolinefort', 'UT', '60783', '7460088038'), ('Gregory Cordova', '279 Powell Haven', 'East Paul', 'SD', '05111', '+1-624-801-4556x01453'), ('John Singleton', '70197 Carly Cliffs Suite 707', 'Andersonport', 'MT', '37616', '958-451-4571x48717'), ('Daniel Davis', '001 Mary Camp', 'Keithfurt', 'OH', '61165', '587-323-1592x6356'), ('Nicole Henry', '997 Mallory Hills Suite 208', 'Joneshaven', 'DC', '21923', '+1-328-684-0760'), ('Belinda Perkins', '724 Jeremy Parkways', 'Jessicamouth', 'NV', '84290', '(959)857-7657x41655'), ('Samuel Smith', '59699 Isabel Port', 'Porterview', 'AK', '40817', '(337)138-4996x7486'), ('Heather Wyatt', '1424 Amanda Valleys', 'Allenchester', 'WY', '68090', '402.717.8804'), ('Kathryn Richards', '381 Butler Crossing', 'Scottville', 'GA', '98066', '7379672487'), ('Mariah Kelley', '914 Brian Pine Apt. 996', 'Jamesview', 'NY', '22238', '(356)031-7546x1581'), ('Vicki Campos', '4834 Green Camp', 'Snyderstad', 'TX', '89492', '001-889-083-3956'), ('Charles Butler', '215 Audrey Burgs', 'North Kathrynburgh', 'NM', '56558', '917.148.7475'), ('Juan Rodriguez', '41506 Lee Landing Suite 948', 'East Sean', 'NE', '78322', '659.967.1464x9146'), ('Matthew Hill', '2780 Chang Views', 'Michealmouth', 'TN', '97125', '603-906-9592'), ('Kelsey Gonzalez', '5506 Ashley Freeway', 'Port Marissa', 'RI', '29858', '(060)943-2191'), ('Tammy Knight', '90701 Stevens Burgs Suite 958', 'Barbershire', 'VT', '73098', '104.439.6526'), ('Brett Hess', '7199 Turner Center', 'Douglashaven', 'WA', '06229', '001-731-161-1102x542'), ('Jason Anderson', '544 Lopez Spur', 'Coxchester', 'NY', '67009', '385-729-5801'), ('Sandra Chang', '261 Mark Cove', 'Port Cynthia', 'WA', '06183', '956-776-2500'), ('Scott Donovan', '7323 Mary Turnpike Suite 444', 'Bautistaport', 'IA', '96772', '682-729-2028'), ('Pamela Adams', '7547 Marshall Station Apt. 889', 'East William', 'MN', '92476', '(959)953-5165x58126'), ('Christopher Jackson', '81096 Santana Branch', 'Richardchester', 'DC', '06276', '8955897917'), ('Michael Garner', '9688 Traci Point', 'Katherinechester', 'NC', '25497', '001-827-789-8445x171'), ('Jennifer Petersen', '30693 Zachary Burg Apt. 264', 'East Saraland', 'AZ', '57279', '001-395-597-2651x3079'), ('Rachel Allen', '618 Delgado Club', 'Port Brianhaven', 'WY', '77301', '(163)694-4979'), ('Karen Rivera', '5751 Moore Mission Apt. 376', 'Maldonadoview', 'CO', '63107', '(492)872-1937x988'), ('Luke Moore', '6344 Amy Views Apt. 796', 'West Ericborough', 'GA', '89281', '883-162-0224'), ('Michael Cobb', '574 Estrada Dam', 'Jamieberg', 'TX', '25492', '918.187.6665x670'), ('Linda Durham', '544 Heather Trail Apt. 600', 'Port Brittneymouth', 'IA', '57221', '(928)018-7824x504'), ('Carolyn Smith', '02441 Sophia Stravenue Apt. 237', 'Lake Timothytown', 'HI', '96147', '695-850-4679x14999'), ('Adam Yates', '220 Tran Knoll Suite 003', 'Curryland', 'PA', '80732', '+1-408-411-2916x14306'), ('David Hale', '2042 Cynthia Route', 'North Kyleshire', 'MN', '04966', '2007254630'), ('Charles Hogan', '4175 Andrew Center', 'Christianton', 'AR', '39254', '5685178064'), ('Lindsay Schmidt', '89351 Brenda Ville Apt. 082', 'Mcdonaldland', 'ID', '68039', '001-988-747-3349'), ('Debbie Rogers', '9457 Brady Branch Suite 145', 'East Jordan', 'UT', '60605', '(104)790-4277x07399'), ('Shawn Ross', '438 Samuel Shores Suite 765', 'East Kimberly', 'VA', '12950', '001-342-785-7923'), ('Jillian Barnes', '80501 Justin Ports Suite 400', 'New Elaine', 'TX', '97727', '138-430-3555x76109'), ('Ashley Richard', '0463 Norris Spurs Suite 968', 'Yatesbury', 'OR', '87427', '+1-543-280-3922x802'), ('Eric Schmidt', '407 Peggy Throughway', 'Garyfurt', 'AZ', '38458', '081-373-2677'), ('Mercedes Dean', '5727 Salinas Forks Apt. 922', 'Noahtown', 'MI', '96813', '153.256.5593'), ('Jeffery Maldonado', '116 Roberts Station', 'North Mary', 'NC', '68083', '289.303.2448'), ('Andrew Drake', '0552 Stephanie Manor', 'Elizabethhaven', 'AK', '44128', '(623)421-7187x9065'), ('Andrew Ellis', '654 Matthews Cape', 'Castroburgh', 'MA', '06282', '9604571532'), ('Michael Hill', '215 Singleton Union', 'East Jeffery', 'CT', '19745', '001-407-908-3663'), ('Ashley Norton', '30070 Patricia Lights Apt. 171', 'East Christopherchester', 'NC', '54185', '362.170.8858'), ('Faith Padilla MD', '0803 Luis Street Apt. 799', 'New Tylerfort', 'IN', '01602', '+1-752-132-9692x047'), ('Brett Soto', '775 Nicole Roads Apt. 643', 'Kaylaport', 'NE', '10534', '473.303.4120x63537'), ('Michael Berry', '201 Bonnie Fall', 'Nelsonview', 'RI', '71941', '466.897.5459'), ('Melissa Mercado', '05669 Laura Mews', 'East Jorge', 'AZ', '05088', '(399)253-0190x74268'), ('Dawn Hickman', '95241 Julie Keys Apt. 431', 'Joshuaville', 'IL', '85467', '+1-171-178-2320x98119'), ('Kelly Soto', '0303 Elizabeth Port Apt. 733', 'Port Eric', 'VA', '19884', '345-728-7752x99915'), ('Danny Beck', '063 Brian Ridges Apt. 464', 'Bryanthaven', 'IN', '57537', '(521)603-8406'), ('Robert Mahoney', '8229 Bonnie Turnpike', 'East Joshuamouth', 'DE', '45877', '+1-247-693-0890x105'), ('Gregory Brown', '89975 Sabrina Glen Apt. 544', 'Johnsonshire', 'CO', '29604', '942-203-3183x93987'), ('Mr. Charles Wells', '04018 Johnson Forest', 'West Ashley', 'WY', '50692', '001-435-656-6540x496'), ('Kenneth Martinez', '19183 Ronald Drive', 'Lake Robertchester', 'AR', '41886', '224.034.5619x60557'), ('Brandon Vasquez', '331 Christopher Mill Apt. 776', 'Stoutmouth', 'ID', '72937', '(866)296-1387x2846'), ('Anthony Benitez', '23629 Richard Run Suite 035', 'North Jamesport', 'OK', '37384', '610-162-3094x57524'), ('Francisco Anderson', '7964 Nicholas Square Suite 509', 'Lake Julie', 'MA', '34566', '001-037-707-0679x80533'), ('William Taylor', '37120 Kline Junctions', 'Benjaminfort', 'MT', '68088', '944-716-9718'), ('Timothy Maddox', '3762 Nathan Crossroad Suite 181', 'Jamestown', 'NV', '27046', '001-102-296-0995x87242'), ('Eric Edwards', '2840 Henderson Brook', 'West Lisaberg', 'MN', '64376', '+1-518-174-0983x6487'), ('Mark Baker', '9896 Robert Center Suite 395', 'South Mariah', 'WI', '24383', '+1-669-306-6251x3341'), ('Daniel Hamilton', '49053 Martin Dale', 'Michaelchester', 'MO', '68028', '001-465-679-3875x613'), ('Benjamin Flores', '580 Pacheco Via', 'Port Benjamin', 'NJ', '36738', '001-759-895-2790x1539'), ('Melissa Lopez', '15788 Davis Harbors Suite 075', 'Lake Oscar', 'DE', '28331', '911.562.1166x5522'), ('Marie Baker', '52033 Clark Radial Apt. 938', 'South Barbarachester', 'VA', '97728', '+1-734-876-2556x47101'), ('Jennifer Huff', '7933 Tracy Fords', 'East Terranceton', 'MD', '67436', '001-497-546-3358x64636'), ('Tammy Lloyd', '343 Scott Island Suite 020', 'Mariabury', 'MI', '68033', '+1-084-291-2986x3359'), ('Sarah Rodriguez', '8669 Fletcher Rue Suite 609', 'Jenniferchester', 'AK', '34659', '364.332.0560'), ('Danielle Conner', '6479 Madden Mission Apt. 670', 'New Travis', 'LA', '98577', '(804)501-6480x8854'), ('Sarah Hernandez DDS', '6041 Robin Village Apt. 927', 'West Ashley', 'KS', '70960', '089.326.5363'), ('Selena Jordan', '908 Monica Rapid Suite 635', 'Samuelberg', 'IN', '83267', '+1-853-993-9093x43521'), ('Timothy Bell', '0846 Brown Estates Suite 900', 'Lake Marilyn', 'MN', '70076', '064.134.9335x6057'), ('Nathan Juarez', '325 Hall Field', 'Matthewside', 'VA', '02444', '(160)326-0979'), ('Carla Payne', '7458 Stevens Hollow', 'West Stacie', 'KS', '97280', '081-713-1648x5224'), ('Alison Hill', '24073 Willie Rapid', 'Joshuahaven', 'LA', '87872', '6215669628'), ('Lori Barker', '0255 Carl Meadows Apt. 965', 'Bankstown', 'OH', '70150', '086.838.9845'), ('Sergio Green', '69105 Ricardo Parks', 'West Julia', 'AR', '16889', '+1-762-168-5169'), ('John Williams', '20318 Hughes Haven', 'East Aprilbury', 'VA', '98543', '751.392.9684'), ('Ann Lopez', '0367 Holland Squares Suite 393', 'Lake Lisa', 'MA', '91117', '928.966.9669'), ('Michael Thomas', '3061 Robert Way Suite 622', 'West Randallfurt', 'NM', '35983', '217-705-9757'), ('Belinda Bartlett', '00553 Timothy Roads Suite 921', 'Maldonadomouth', 'SC', '26558', '443.209.1417'), ('Tricia Schwartz', '637 Mark Oval', 'Salazarberg', 'IA', '61986', '044.058.8667'), ('Jeremy Rojas', '1106 Ramirez Unions', 'New Steven', 'PA', '06074', '+1-515-926-0953x3164'), ('Amanda Caldwell', '6176 Andrew Orchard', 'Port Caleb', 'ME', '11503', '607.054.4893'), ('Nichole Hobbs', '93824 Joshua Fort Suite 322', 'Russellberg', 'AL', '98110', '001-126-705-7147'), ('Laurie Peterson', '773 Bentley Extensions Apt. 130', 'Anthonybury', 'AL', '51075', '322.380.1425'), ('Arthur Walker', '57534 Stewart Corner Suite 088', 'Russellberg', 'WA', '39703', '935.271.0059'), ('Jorge Brown', '50079 Brian Loop', 'North Christopherland', 'MT', '99786', '843.450.9355'), ('Joseph Powers', '24382 Tanner Overpass', 'Marialand', 'MD', '98917', '177-784-1457'), ('Robert Brooks', '815 Douglas Green', 'Nobleport', 'TX', '58346', '167-259-4837x11409'), ('James Shah', '4951 Paul Trail Suite 461', 'Port Nancyburgh', 'DE', '29408', '211.630.0332x2207'), ('Jill Coffey', '70076 Roberts Parkways', 'Kristinton', 'WY', '82040', '001-222-347-3269'), ('Megan Levy', '0676 Porter Plaza Apt. 720', 'Austinmouth', 'NC', '49839', '865.302.2010x7269'), ('Nicole Juarez', '0675 Alvarado Ferry', 'Thompsonville', 'NM', '98766', '381.638.2325'), ('David Jimenez', '1762 Adkins Lights', 'South Kathryn', 'KY', '36516', '279-656-3580x8524'), ('Lisa Marshall', '441 Owens Ranch Apt. 532', 'Beardton', 'CA', '84071', '974-458-4883')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function Connection.__exit__>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Build a new database\n",
    "#//*** Start from scratch each run. Therefore delete any previous version\n",
    "db_filename = 'people.sqldb'\n",
    "\n",
    "#//*** Delete the previous db instance if it exists.\n",
    "if os.path.exists(db_filename):\n",
    "    os.remove(db_filename)\n",
    "    \n",
    "#//*** Start a database instance\n",
    "con = sqlite3.connect(db_filename)\n",
    "\n",
    "#//*** Build Table\n",
    "#//*** Use Person keys() to build the column names. We'll keep all fields as VARCHAR(20) for simplicity\n",
    "query = \"CREATE TABLE People (\"\n",
    "\n",
    "#//*** person is the last person in the list. It's the last instance from the loop used to build the people list.\n",
    "#//*** Normally this is considered a 'throw-away' variable. But since it's in memory, let's reuse it.\n",
    "#//*** And each person() has the same values, so why not. \n",
    "\n",
    "#//*** This creates the columns (attributes) that we'll be filling.\n",
    "for key in person.keys():\n",
    "    query += f\"{key} varchar(20), \"\n",
    "\n",
    "#//*** Trim the trailing ,\n",
    "query = query[:-2]\n",
    "\n",
    "query += \");\"\n",
    "\n",
    "print(query)\n",
    "\n",
    "#//*** Execute Build TABLE query\n",
    "con.execute(query)\n",
    "\n",
    "\n",
    "#//*** Build Column name for INSERT\n",
    "cols = \"(\"\n",
    "for key in person.keys():\n",
    "    cols += f\"{key}, \"\n",
    "cols = cols[:-2]\n",
    "cols += \")\"\n",
    "\n",
    "print(cols)\n",
    "\n",
    "#//*** Build the INSERT Query for each Person\n",
    "#//*** Loop through each person\n",
    "for person in people:\n",
    "    data = \"(\"\n",
    "    #//*** Build the attributes/columns for each person\n",
    "    for attrib in person:\n",
    "        data += f\"'{person[attrib]}', \"\n",
    "    #//*** Trim the trailing comma space.\n",
    "    data = data[:-2]\n",
    "    data += \")\"\n",
    "    #//*** Add each person individually to the db.\n",
    "    con.execute(f\"INSERT INTO People {cols} VALUES {data}\")\n",
    "    #//*** Commit the INSERT. I suppose we should verify that the INSERT was good. Perhaps in a production db.\n",
    "    con.commit()\n",
    "#//*** END - person in people\n",
    "#//*** All people entered into the db.\n",
    "\n",
    "#//*** Display the people in the database\n",
    "cursor = con.execute(\"select * FROM People\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "#//*** Close and Exit the Database. For \n",
    "con.close()\n",
    "con.__exit__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Connection.__exit__>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#con.commit()\n",
    "con.close()\n",
    "con.__exit__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DirEntry', 'F_OK', 'MutableMapping', 'O_APPEND', 'O_BINARY', 'O_CREAT', 'O_EXCL', 'O_NOINHERIT', 'O_RANDOM', 'O_RDONLY', 'O_RDWR', 'O_SEQUENTIAL', 'O_SHORT_LIVED', 'O_TEMPORARY', 'O_TEXT', 'O_TRUNC', 'O_WRONLY', 'P_DETACH', 'P_NOWAIT', 'P_NOWAITO', 'P_OVERLAY', 'P_WAIT', 'PathLike', 'R_OK', 'SEEK_CUR', 'SEEK_END', 'SEEK_SET', 'TMP_MAX', 'W_OK', 'X_OK', '_AddedDllDirectory', '_Environ', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_check_methods', '_execvpe', '_exists', '_exit', '_fspath', '_get_exports_list', '_putenv', '_unsetenv', '_wrap_close', 'abc', 'abort', 'access', 'add_dll_directory', 'altsep', 'chdir', 'chmod', 'close', 'closerange', 'cpu_count', 'curdir', 'defpath', 'device_encoding', 'devnull', 'dup', 'dup2', 'environ', 'error', 'execl', 'execle', 'execlp', 'execlpe', 'execv', 'execve', 'execvp', 'execvpe', 'extsep', 'fdopen', 'fsdecode', 'fsencode', 'fspath', 'fstat', 'fsync', 'ftruncate', 'get_exec_path', 'get_handle_inheritable', 'get_inheritable', 'get_terminal_size', 'getcwd', 'getcwdb', 'getenv', 'getlogin', 'getpid', 'getppid', 'isatty', 'kill', 'linesep', 'link', 'listdir', 'lseek', 'lstat', 'makedirs', 'mkdir', 'name', 'open', 'pardir', 'path', 'pathsep', 'pipe', 'popen', 'putenv', 'read', 'readlink', 'remove', 'removedirs', 'rename', 'renames', 'replace', 'rmdir', 'scandir', 'sep', 'set_handle_inheritable', 'set_inheritable', 'spawnl', 'spawnle', 'spawnv', 'spawnve', 'st', 'startfile', 'stat', 'stat_result', 'statvfs_result', 'strerror', 'supports_bytes_environ', 'supports_dir_fd', 'supports_effective_ids', 'supports_fd', 'supports_follow_symlinks', 'symlink', 'sys', 'system', 'terminal_size', 'times', 'times_result', 'truncate', 'umask', 'uname_result', 'unlink', 'urandom', 'utime', 'waitpid', 'walk', 'write']\n",
      "['DataError', 'DatabaseError', 'Error', 'IntegrityError', 'InterfaceError', 'InternalError', 'NotSupportedError', 'OperationalError', 'ProgrammingError', 'Warning', '__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'backup', 'close', 'commit', 'create_aggregate', 'create_collation', 'create_function', 'cursor', 'enable_load_extension', 'execute', 'executemany', 'executescript', 'in_transaction', 'interrupt', 'isolation_level', 'iterdump', 'load_extension', 'rollback', 'row_factory', 'set_authorizer', 'set_progress_handler', 'set_trace_callback', 'text_factory', 'total_changes']\n"
     ]
    }
   ],
   "source": [
    "con.close()\n",
    "con.__exit__\n",
    "\n",
    "print(dir(os))\n",
    "print(dir(con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
