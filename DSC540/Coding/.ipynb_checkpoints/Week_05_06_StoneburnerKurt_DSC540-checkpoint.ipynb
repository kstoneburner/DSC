{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 540 - Week 05/06\n",
    "- ## Chapter 5, Activity7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this activity you are given the Wikipedia page where we have the GDP of all countries listed and you are asked to create three data frames from the three sources mentioned in the page ( link - https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal) )\n",
    "\n",
    "You will have to -\n",
    "\n",
    "- Open the page in a separate chrome/firefox tab and use something like `inspect element` tool to see the source HTML and understand the structure\n",
    "- Read the page using bs4\n",
    "- Find the table structure you will need to deal with (how many tables are there)\n",
    "- Find the right table using bs4\n",
    "- Separate the Source Names and their corresponding data\n",
    "- Get the source names from the list of sources you have created\n",
    "- Seperate the header and data from the data that you separated before. For the first source only. And then create a DataFrame using that\n",
    "- Repeat the last task for the other two data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //****************************************************************************************\n",
    "# //*** Set Working Directory to thinkstats folder.\n",
    "# //*** This pseudo-relative path call should work on all Stoneburner localized projects. \n",
    "# //****************************************************************************************\n",
    "\n",
    "import os\n",
    "import sys\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "#//*** Going to use the requests library, since it's the same library used for API calls\n",
    "import requests\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource:\n",
    "- https://generalistprogrammer.com/python/python-web-scraping-tutorial-with-beautifulsoup-and-requests/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Use Requests to get the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Verify Response is ok. This *should* be analogous to checking if the response code is 200\n",
    "if response.ok == True: \n",
    "    #//*** Make soup...Beautiful Soup\n",
    "    soup = BeautifulSoup(response.content,'html.parser')\n",
    "else:\n",
    "    print(\"Problem with the URL Request\")\n",
    "    \n",
    "#//*** The tables all have the class name wikitable\n",
    "#//*** Discard the first table, which is a container for the other three.\n",
    "tables = soup.find_all('table', class_='wikitable')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Use the tableCounter to keep track of which table we are working in.\n",
    "#//*** If we were super cool, we'd tie something in to using the first row of the maintable to keep track of \n",
    "#//*** Of which table/dataframe is which. But since we are looking for very specific things, it doesn't make\n",
    "#//*** sense to invest in a more robust structure, since any slight change of source will break the whole scrape.\n",
    "\n",
    "#//*** Personally, I'd skip Beautiful Soup and just use Regex. Mostly, because regex is universal and be applied\n",
    "#//*** to other scenarios as well as other languages. It is is very useful across many tasks. I've also written \n",
    "#//*** an HTML parser in javascript using HTML. It was for a project where news talent reads scripts off of an iPad\n",
    "#//*** instead of paper scripts.\n",
    "\n",
    "#//*** The book uses a very pythonic single line method to generate a multi dimensional array. I'm not a fan of \n",
    "#//*** that in general. I prefer more readable verbose code.\n",
    "\n",
    "#//*** We'll deviate from the assignment a bit by handling all three tables in a loop.\n",
    "\n",
    "#//*** tableCounter helps keep track of which of the three tables we are working in. This is required\n",
    "#//*** when determining which dataframe to build\n",
    "tableCounter = 0\n",
    "\n",
    "#//*** Parse Each table\n",
    "for table in tables:\n",
    "    tableCounter+=1\n",
    "    \n",
    "    #//************************************\n",
    "    #//*** Build Table Headers\n",
    "    #//************************************\n",
    "    #//*** Get the Table Headers. These will be our data frame Columns.\n",
    "    ths = table.find_all(\"th\")\n",
    "    #//*** initialize a list to hold the column names\n",
    "    colnames = []\n",
    "    \n",
    "    #//*** Columnnames are the first value contained in contents\n",
    "    for th in ths:\n",
    "        colnames.append(th.contents[0])\n",
    "    \n",
    "    #//**********************************\n",
    "    #//*** Initialize tableDict.\n",
    "    #//**********************************\n",
    "    #//*** tableDict is a dictionary container to hold row data.\n",
    "    #//*** The tableDict will hold each of the row lists. The keys will be each colname\n",
    "    tableDict = {}\n",
    "    \n",
    "    #//*** Initialize tableDict\n",
    "    for name in colnames:\n",
    "        tableDict[name] = []\n",
    "    \n",
    "    #//***********************************************\n",
    "    #//*** Process each tablerow\n",
    "    #//*** The sausage is primarily made here\n",
    "    #//***********************************************\n",
    "    \n",
    "    #//*** Get a BS list of table rows\n",
    "    trs = table.find_all(\"tr\")\n",
    "    \n",
    "    #//*** For each table row in tablerows\n",
    "    for tr in trs:\n",
    "        #//*** Skip the table header\n",
    "        if len(tr.find_all(\"th\")) == 0:\n",
    "            #//*** Loop through the colnames Index\n",
    "            #//*** The gets the key value to store the TD data\n",
    "            #//*** Get a TD with a corresponding index value and extract the text\n",
    "            for x in range(0,len(colnames)):\n",
    "                #//*** Append the text to the appropriate colname list.\n",
    "                #//*** Using index values keeps everthing aligned.\n",
    "                tableDict[colnames[x]].append(tr.find_all('td')[x].text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "    #//**************************************************************************************\n",
    "    #//*** Table is fully parsed into the tableDict\n",
    "    #//*** Remove the first element of each list. It contains the World Summary numbers\n",
    "    #//**************************************************************************************\n",
    "    for key in tableDict.keys():\n",
    "        tableDict[key].pop(0)\n",
    "        \n",
    "    #//*********************************************************\n",
    "    #//*** Convert tableDict into a df.\n",
    "    #//*** the individual df is determined by the tableCounter\n",
    "    #//*********************************************************\n",
    "    if tableCounter == 1:\n",
    "        #//*** Create the IMF Dataframe\n",
    "        imf_df = pd.DataFrame()\n",
    "        \n",
    "        #//*** Add each Column to dataframe\n",
    "        for x in colnames:\n",
    "            imf_df[x] = tableDict[x]\n",
    "    \n",
    "    elif tableCounter == 2:\n",
    "        #//*** Create the IMF Dataframe\n",
    "        worldbank_df = pd.DataFrame()\n",
    "        \n",
    "        #//*** Add each Column to dataframe\n",
    "        for x in colnames:\n",
    "            worldbank_df[x] = tableDict[x]\n",
    "        \n",
    "    elif tableCounter == 3:\n",
    "        #//*** Create the IMF Dataframe\n",
    "        un_df = pd.DataFrame()\n",
    "        \n",
    "        #//*** Add each Column to dataframe\n",
    "        for x in colnames:\n",
    "            un_df[x] = tableDict[x]\n",
    "    \n",
    "#//*********************************************************\n",
    "#//*** END table in tables\n",
    "#//*********************************************************\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#############\n",
      "IMF\n",
      "#############\n",
      "  Rank Country/Territory         GDP\n",
      "0    1     United States  20,807,269\n",
      "1    2   China[n 2][n 3]  14,860,775\n",
      "2    3             Japan   4,910,580\n",
      "3    4           Germany   3,780,553\n",
      "4    5    United Kingdom   2,638,296\n",
      "\n",
      "#############\n",
      "World Bank\n",
      "#############\n",
      "  Rank Country/Territory         GDP\n",
      "0    1     United States  21,427,700\n",
      "1    2        China[n 9]  14,342,903\n",
      "2    3             Japan   5,081,770\n",
      "3    4           Germany   3,845,630\n",
      "4    5             India   2,875,142\n",
      "\n",
      "#############\n",
      "UN\n",
      "#############\n",
      "  Rank Country/Territory         GDP\n",
      "0    1     United States  21,433,226\n",
      "1    2        China[n 9]  14,342,933\n",
      "2    3             Japan   5,082,465\n",
      "3    4           Germany   3,861,123\n",
      "4    5             India   2,891,582\n"
     ]
    }
   ],
   "source": [
    "        print(\"\\n#############\")\n",
    "        print(\"IMF\")\n",
    "        print(\"#############\")\n",
    "        print(imf_df.head())\n",
    "\n",
    "        print(\"\\n#############\")\n",
    "        print(\"World Bank\")\n",
    "        print(\"#############\")\n",
    "        print(worldbank_df.head())\n",
    "        \n",
    "        print(\"\\n#############\")\n",
    "        print(\"UN\")\n",
    "        print(\"#############\")\n",
    "        print(un_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6, Activity 08\n",
    "\n",
    "In this activity we do the following\n",
    "\n",
    "* Create a data frame from a given CSV\n",
    "* Check for duplicates in the columns that matter\n",
    "* Check for NaN in the columns that matter\n",
    "* Apply our domain knowledge to single out and remove outliers\n",
    "* Generate nice print statements as reports for differents steps\n",
    "\n",
    "The data set is a 1000 row data set which represnets the traffic on a certain page of a website. The Names, email, and IP are faked out in order to keep the privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data (the file name is - visit_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id first_name last_name                       email gender  \\\n",
      "0   1      Sonny      Dahl            sdahl0@mysql.com   Male   \n",
      "1   2        NaN       NaN           dhoovart1@hud.gov    NaN   \n",
      "2   3        Gar     Armal      garmal2@technorati.com    NaN   \n",
      "3   4    Chiarra     Nulty       cnulty3@newyorker.com    NaN   \n",
      "4   5        NaN       NaN  sleaver4@elegantthemes.com    NaN   \n",
      "\n",
      "        ip_address   visit  \n",
      "0    135.36.96.183  1225.0  \n",
      "1  237.165.194.143   919.0  \n",
      "2   166.43.137.224   271.0  \n",
      "3   139.98.137.108  1002.0  \n",
      "4    46.117.117.27  2434.0  \n"
     ]
    }
   ],
   "source": [
    "### Write your code bellow this comment\n",
    "base_df = pd.read_csv(\"z_sup_wk05_06_visit_data.csv\")\n",
    "print(base_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 1 (Are there duplicates?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test for Duplicate Email addresses: False\n",
      "There don't appear to be duplicates in the data set\n"
     ]
    }
   ],
   "source": [
    "print( f\"Test for Duplicate Email addresses: {base_df['email'].duplicated().any()}\")\n",
    "print(\"There don't appear to be duplicates in the data set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 2 (do any essential column contain NaN?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN in id: 0\n",
      "Number of NaN in email: 0\n",
      "Number of NaN in ip_address: 0\n",
      "Number of NaN in visit: 26\n",
      "The website traffic, visit column contains 26 NaN. These are likely outliers.\n"
     ]
    }
   ],
   "source": [
    "essential_cols = ['id', 'email', 'ip_address','visit']\n",
    "for col in essential_cols:\n",
    "    print(f\"Number of NaN in {col}: {sum(base_df[col].isna()==True)}\")\n",
    "\n",
    "print(\"The website traffic, visit column contains 26 NaN. These are likely outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 3 (Get rid of the outliers)\n",
    "\n",
    "Consider what are the essential columns if you are preparing this dataset for a model building exercise where the target is to predict number of visits given a user name, email, IP address, Gender etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_len = len(base_df)\n",
    "base_df = base_df.dropna(subset=['visit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 4 (Report the size difference)\n",
    "\n",
    "The `shape` method of a data frame gives you a tuple which represents (row, column) of the data frame, in this task you have to compare and report the number of rows before and after getting rid of the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Dataframe length: 1000 rows\n",
      "After removing NaN 26 visits, the length is: 974 rows and 7 columns\n"
     ]
    }
   ],
   "source": [
    "### Write your code bellow this comment\n",
    "print(f\"Orginal Dataframe length: {orig_len} rows\")\n",
    "print(f\"After removing NaN {orig_len - base_df.shape[0]} visits, the length is: {base_df.shape[0]} rows and {base_df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 5 (Box plot visit to further check any Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1a4366c8dc0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a437ed0160>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1a437ed04c0>,\n",
       "  <matplotlib.lines.Line2D at 0x1a437ed0820>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1a4366c8a60>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1a437ed0b80>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1a437ed0e80>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(base_df['visit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Insert data into a SQL Lite database – create a table with the following data (Hint: Python for Data Analysis page 191):\n",
    "\n",
    "a. Name, Address, City, State, Zip, Phone Number\n",
    "\n",
    "b. Add at least 10 rows of data and submit your code with a query generating your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Added the Faker Library to generate fake people.\n",
    "#//*** https://pypi.org/project/Faker/\n",
    "from faker import Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Heather Thompson', 'address': '111 Perry Island', 'city': 'Greenhaven', 'state': 'NY', 'zip': '97523', 'phone': '210.225.6549x609'}\n",
      "{'name': 'Jason Clark', 'address': '861 Patterson Meadow Suite 960', 'city': 'South Marissa', 'state': 'SC', 'zip': '98559', 'phone': '709-129-5009x582'}\n",
      "{'name': 'Luis Gibson', 'address': '056 Sherri Forest', 'city': 'Priceland', 'state': 'CA', 'zip': '38011', 'phone': '193.674.9889x27728'}\n",
      "{'name': 'Grace Turner', 'address': '1027 Lori Land Apt. 851', 'city': 'South Richard', 'state': 'AZ', 'zip': '61179', 'phone': '(968)160-4999x805'}\n",
      "{'name': 'Morgan Rodriguez', 'address': '65628 Shaun Manor Apt. 025', 'city': 'Cynthiabury', 'state': 'NV', 'zip': '08329', 'phone': '853-393-0127x73759'}\n"
     ]
    }
   ],
   "source": [
    "#//*** Build 100 fake people\n",
    "fake = Faker()\n",
    "\n",
    "people = []\n",
    "for _ in range(100):\n",
    "    #//*** Store each entry in a person dictionary. Add each person to the people list\n",
    "    person = {}\n",
    "    person[\"name\"] = fake.name()\n",
    "    person['address'] = fake.street_address()\n",
    "    person['city'] = fake.city() \n",
    "    person['state'] = fake.state_abbr()\n",
    "    person['zip'] = fake.zipcode_in_state()\n",
    "    person['phone'] = fake.phone_number()\n",
    "    people.append(person)\n",
    "\n",
    "#//*** Display first 5 results \n",
    "for x in range(5):\n",
    "    print(people[x])\n",
    "    \n",
    "#print(dir(fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE People (name varchar(20), address varchar(20), city varchar(20), state varchar(20), zip varchar(20), phone varchar(20));\n",
      "(name, address, city, state, zip, phone)\n",
      "[('Brent Bowman', '79847 Smith Burg', 'West Steven', 'OK', '70406', '675-931-4209'), ('Jordan Benjamin', '68724 Norma Islands Apt. 014', 'Steventown', 'NM', '63913', '714-175-7132x7741'), ('Nina Carter', '446 Aaron Mountain Apt. 253', 'Ingramport', 'MO', '97057', '524-261-6776'), ('Victoria Sanders', '14188 Warren Throughway Suite 670', 'Gabriellaland', 'TX', '64895', '+1-418-499-2601x102'), ('Edward Smith', '746 Ryan Garden', 'South Kelli', 'MA', '05191', '001-492-267-8247x4986'), ('Emily Martin', '71091 Hayes Manors', 'West Michaelland', 'FL', '85522', '+1-136-944-7950x7413'), ('Kevin Choi', '210 Jessica Stravenue', 'Colinmouth', 'NJ', '48692', '637-465-6497'), ('Barbara Hernandez', '142 Tracy Ports', 'Lake Gabrielle', 'DC', '57456', '(193)508-6808'), ('Joe Delgado', '8035 Robert Villages Apt. 775', 'New Rachelport', 'IL', '83589', '957-276-8544x4650'), ('Jared Saunders', '07235 Perez Haven', 'Snowton', 'DC', '60915', '001-895-571-8622x319'), ('Denise Gallegos', '725 Hodge Center Apt. 398', 'West Alexander', 'AR', '38993', '611-384-3233x8072'), ('Paul Adams', '095 Anderson Crescent Apt. 975', 'North Roberttown', 'MS', '02833', '938-953-1122x321'), ('Courtney Bullock', '000 Angela Dale', 'Lake Donna', 'KS', '70227', '+1-636-401-9200'), ('Kenneth Moore', '901 Berg Trafficway', 'Coreyburgh', 'IA', '48028', '+1-175-112-2577'), ('Keith Wilson', '43973 Brian Corners', 'Hutchinsonmouth', 'IN', '30737', '577.522.0694x22605'), ('Sarah Johnson', '4838 Robinson Roads', 'Port Cynthia', 'GA', '38517', '070.656.8870x4352'), ('Daniel Hull', '2796 Fry Crossroad', 'New Jermaineshire', 'PA', '52084', '(351)079-6507x27931'), ('Tamara Henderson', '77476 Elaine Parkways Apt. 927', 'Johnborough', 'SD', '33472', '434.393.6691'), ('Lauren Edwards', '43938 Jones Cove', 'Aaronton', 'SD', '64386', '001-413-255-8684'), ('James Figueroa', '54433 Susan Crescent Apt. 009', 'South Conniemouth', 'NM', '01577', '595-452-2129'), ('Patricia Gentry', '246 Brian Glen', 'Vaughnhaven', 'KY', '49306', '122-649-9743x35767'), ('Richard Smith', '5879 Rodriguez Plains Suite 880', 'Amandamouth', 'OH', '03527', '(540)589-1217'), ('Rebecca Park', '74821 Everett Greens', 'North Davidview', 'AR', '22175', '197-638-2286x4365'), ('Duane Acosta', '03973 Odonnell Drive Apt. 108', 'North Adam', 'WV', '66659', '358.841.2698'), ('Brianna Long', '4245 Jimmy Crescent Suite 194', 'New Sharon', 'MI', '02918', '(487)125-6770'), ('Brandon Barron', '665 Baker Roads Suite 680', 'Hamiltonhaven', 'TN', '49840', '527.531.3896x4231'), ('Melanie Terry', '42731 Martinez Island Apt. 898', 'Gregorytown', 'HI', '58342', '815-612-7482'), ('Sandra Herman', '5430 Becker Crescent', 'Boydchester', 'DE', '84175', '493.282.3092'), ('Christina Anderson', '525 Michelle Grove', 'Perrymouth', 'WY', '62568', '371.584.2637x7912'), ('Michael Armstrong', '5449 Sarah Curve Apt. 837', 'Colemanmouth', 'MD', '08300', '+1-317-399-7864x71767'), ('Christina Fisher', '222 Sarah Lodge', 'Kellieshire', 'CT', '32813', '(474)899-5632x9985'), ('Stephen Lopez', '3746 Carpenter Canyon', 'Scottmouth', 'NV', '19792', '(434)706-1862x3209'), ('Christy Wood', '46240 Patricia Ramp Apt. 963', 'Curryburgh', 'IN', '41141', '(774)655-3533x04893'), ('Jennifer Obrien', '57095 Miller Motorway Suite 787', 'Sharonshire', 'TX', '57570', '519-875-9414x12607'), ('Diane Rodriguez', '8279 Matthew Course', 'Bakerland', 'MD', '82765', '(292)084-3986'), ('Carly Hoffman', '8629 Laura Shoals Suite 317', 'Baileychester', 'PA', '60809', '9198463872'), ('Jeffery Russell', '34531 Murray Freeway Apt. 174', 'Waltermouth', 'CO', '84358', '8668743584'), ('Mark Austin', '953 Stacey Spurs', 'North Christophermouth', 'TX', '91602', '994-058-9094'), ('Brian Erickson', '768 Prince Locks Apt. 856', 'Kellyshire', 'CO', '21272', '001-533-810-1907x231'), ('Shirley Cooper', '4467 Butler Knoll', 'North Nathantown', 'NH', '05065', '783.874.8528'), ('Thomas King', '66105 Elliott Club Suite 133', 'Stacyview', 'IN', '59341', '(733)966-3434x57904'), ('Phyllis Leonard', '615 Jonathan Freeway Apt. 998', 'South Johnport', 'MD', '83588', '997-074-6278'), ('Elizabeth Bird', '21538 Rush Via', 'East William', 'NM', '47702', '(415)807-3089x3027'), ('Michael Ryan', '56657 Garcia Islands Apt. 532', 'West Lisa', 'NH', '83271', '(544)409-2699x987'), ('Eric Strickland', '199 Richards View', 'North Dana', 'DC', '20923', '030.768.0003'), ('Brittany Williams MD', '6731 Santana Springs', 'Kevinport', 'DE', '46629', '071.993.7040x94424'), ('Amanda Baker', '73864 Richard Flat', 'South Kristen', 'CA', '75935', '3009699312'), ('Daniel Carroll', '27875 Kevin Well Apt. 964', 'Lake Joshuatown', 'WY', '38927', '(744)487-9183x122'), ('Dustin Elliott', '73493 Antonio Manor Apt. 030', 'Lake Jared', 'AL', '54633', '+1-811-759-4420x17570'), ('Travis Hunter', '23492 Nathan Dam', 'Gomezland', 'OR', '29502', '494-552-9320x05701'), ('Amanda Kramer', '7863 Waller Walks Apt. 839', 'Danielland', 'SD', '41250', '+1-143-251-6349x24649'), ('Joshua Wilkins', '9736 Shaw Cape Suite 870', 'West Mandyview', 'MD', '97309', '3173990645'), ('Tammy Boyle', '73778 Christopher Plains Apt. 526', 'East Jordan', 'MA', '21617', '825-031-3079'), ('David Perez', '53085 Janet Mountains Apt. 861', 'Port Danielle', 'AK', '97076', '8679436285'), ('Micheal Vaughn', '7431 Julie Plains Apt. 127', 'Houstonburgh', 'SD', '05394', '345.607.4328x55569'), ('Tanya Hansen', '830 Heather Ford', 'Sethview', 'SD', '59342', '+1-841-022-7577x1830'), ('Kenneth Fowler', '670 Roman Locks', 'Lisaville', 'NY', '98603', '569.182.3757x4645'), ('Joshua Smith', '2925 Casey Expressway', 'Lake Sarahbury', 'PA', '52003', '+1-959-798-1012'), ('Margaret Chavez', '7784 Bowers Rue Suite 693', 'Jenniferland', 'OR', '68090', '4213682847'), ('Paul Campbell', '568 Whitney Turnpike Suite 270', 'South Allen', 'MT', '08326', '+1-352-041-1051x08759'), ('Mandy Frost', '429 Charles Freeway Apt. 102', 'New Jasminborough', 'ND', '58788', '(214)700-5794x92152'), ('John Howard', '3060 Ho Landing', 'Ericton', 'VT', '96827', '011-334-3550x80979'), ('Melissa Carr', '95231 Anne Course', 'West Davidtown', 'CA', '25992', '001-463-249-7865x179'), ('Bryan Williams', '1231 Singleton Forks Apt. 195', 'Floresshire', 'WY', '82007', '001-844-526-8004x206'), ('Patricia Williams', '932 Thomas Curve', 'Shannonstad', 'MT', '57231', '+1-381-661-3876x089'), ('Lisa Franco', '6950 Vanessa Heights Apt. 605', 'Huntfurt', 'ND', '23518', '(542)130-8252x237'), ('Shawn Jennings', '43266 David Mountains Apt. 801', 'Jayfort', 'TN', '55949', '+1-550-481-5206'), ('Stephanie Barker DDS', '689 Horn Radial Suite 346', 'Cruzburgh', 'HI', '20018', '(307)035-1102x1452'), ('Joseph Rhodes', '134 Coffey Circles Apt. 023', 'East James', 'MA', '65216', '321.277.2890x8898'), ('Danny Cannon', '438 Campbell Via Suite 617', 'Port Richardville', 'CT', '97902', '262-342-5005'), ('Charles Chan', '49338 Frey Expressway Suite 978', 'Katrinaton', 'OK', '08805', '(516)325-1863x929'), ('Andrew Huynh', '1712 Alyssa Causeway Suite 879', 'Thomasview', 'IL', '70960', '001-990-264-9682x125'), ('Robert Cochran', '2631 Evelyn Rest Apt. 065', 'South Janice', 'ID', '23249', '(634)938-4389'), ('Suzanne Lee', '31347 Walker Meadow', 'Port Amystad', 'IN', '38573', '+1-862-781-5501x790'), ('Natalie Cruz', '92538 Garcia Well', 'Port Walter', 'DE', '20006', '525.877.8977'), ('Kyle Shah', '377 Gregory Station Suite 657', 'Hayesville', 'ND', '05127', '001-326-436-6347'), ('Michelle Hamilton', '277 Brian Summit', 'Krystalstad', 'MT', '66372', '598.379.9069'), ('Kenneth Clark', '1136 Bailey Mountains', 'Gravesstad', 'ME', '96753', '001-868-825-2408x50468'), ('Eric Freeman', '35778 Cynthia Plain', 'Christopherchester', 'MA', '56449', '543.495.9105'), ('Shelby Schultz', '236 Dana Lakes', 'New Brian', 'MN', '42426', '0049828364'), ('Jonathan Porter', '41937 Lane Union Suite 947', 'Port Davidfurt', 'CT', '40841', '001-065-705-6467x17178'), ('Amber Holmes', '00869 Cassandra Dam Suite 852', 'Lake Tiffanytown', 'RI', '91106', '+1-512-857-8625x571'), ('Taylor Hernandez', '918 Justin Canyon', 'Mercadobury', 'SD', '58598', '(645)927-2852x930'), ('Jose Jones', '4349 Todd Shoals', 'Port Roberthaven', 'LA', '55582', '434-791-2306'), ('Amy Yates', '69862 Chapman River Apt. 781', 'North Samantha', 'SD', '72415', '512.023.1986x7276'), ('Melissa Medina', '8648 Raymond Brook Apt. 515', 'Donnaville', 'RI', '29273', '203-039-6313'), ('Lori Gardner', '4491 David Trail', 'Irwinton', 'ME', '20019', '(997)310-6810x688'), ('Timothy Valdez', '325 Phillip Shoal', 'Port Robertside', 'NY', '71027', '(199)628-5176x9585'), ('John Gomez', '71448 Allison Rue Suite 838', 'Lake Danielleton', 'IL', '53591', '552-588-6545x5164'), ('Scott Ray', '35947 Williams Shoal', 'Ericborough', 'NY', '39256', '048.471.5525x9890'), ('Adriana Bush', '240 Salazar Locks Suite 577', 'North Jack', 'MI', '68101', '(477)464-7825x48286'), ('Peter Gibson', '98498 Johnson Ports', 'Port Steven', 'ID', '72369', '248.656.5554'), ('Albert Lester', '09586 Adams Expressway Apt. 954', 'Gonzalezton', 'MI', '03181', '920.534.2807x8872'), ('Christina Martinez', '43151 Turner Plaza', 'Mooreview', 'SD', '20026', '991.199.7777x187'), ('Nancy Williams', '0684 Lamb Mountain', 'Breannaton', 'PA', '39722', '572-069-6812x350'), ('Jessica Brown', '2447 Wilson Summit', 'South Kathy', 'GA', '26637', '+1-078-711-4181x180'), ('Debra Villanueva', '01076 White Island', 'Karenview', 'MI', '59213', '(445)487-5753'), ('Jonathan Taylor', '107 Jones Locks', 'West Anthonyshire', 'ME', '49394', '(792)340-5413x1247'), ('Bryan Collins', '3035 Munoz Track', 'Port James', 'DE', '03047', '706.836.0827x4368'), ('Maria Hays', '4870 Yoder Spurs', 'North Shellyborough', 'SC', '82577', '001-108-675-2113x47191')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function Connection.__exit__>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Build a new database\n",
    "#//*** Start from scratch each run. Therefore delete any previous version\n",
    "db_filename = 'people.sqldb'\n",
    "\n",
    "#//*** Delete old instance\n",
    "if os.path.exists(db_filename):\n",
    "    os.remove(db_filename)\n",
    "    \n",
    "#//*** Start a database instance\n",
    "con = sqlite3.connect(db_filename)\n",
    "\n",
    "#//*** Build Table\n",
    "#//*** Use Person keys() to build the column names. We'll keep all fields as VARCHAR(20) for simplicity\n",
    "query = \"CREATE TABLE People (\"\n",
    "for key in person.keys():\n",
    "    query += f\"{key} varchar(20), \"\n",
    "\n",
    "#//*** Trim the trailing ,\n",
    "query = query[:-2]\n",
    "\n",
    "query += \");\"\n",
    "\n",
    "print(query)\n",
    "\n",
    "#//*** Execute Build TABLE query\n",
    "con.execute(query)\n",
    "\n",
    "\n",
    "#//*** Build Column name for INSERT\n",
    "cols = \"(\"\n",
    "for key in person.keys():\n",
    "    cols += f\"{key}, \"\n",
    "cols = cols[:-2]\n",
    "cols += \")\"\n",
    "\n",
    "print(cols)\n",
    "\n",
    "#//*** Build the INSERT Query for each Person\n",
    "for person in people:\n",
    "    data = \"(\"\n",
    "    for attrib in person:\n",
    "        data += f\"'{person[attrib]}', \"\n",
    "    data = data[:-2]\n",
    "    data += \")\"\n",
    "    con.execute(f\"INSERT INTO People {cols} VALUES {data}\")\n",
    "    con.commit()\n",
    "\n",
    "#//*** Display the people in the database\n",
    "cursor = con.execute(\"select * FROM People\")\n",
    "print(cursor.fetchall())\n",
    "\n",
    "#//*** Close and Exit the Database. For \n",
    "con.close()\n",
    "con.__exit__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Connection.__exit__>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#con.commit()\n",
    "con.close()\n",
    "con.__exit__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DirEntry', 'F_OK', 'MutableMapping', 'O_APPEND', 'O_BINARY', 'O_CREAT', 'O_EXCL', 'O_NOINHERIT', 'O_RANDOM', 'O_RDONLY', 'O_RDWR', 'O_SEQUENTIAL', 'O_SHORT_LIVED', 'O_TEMPORARY', 'O_TEXT', 'O_TRUNC', 'O_WRONLY', 'P_DETACH', 'P_NOWAIT', 'P_NOWAITO', 'P_OVERLAY', 'P_WAIT', 'PathLike', 'R_OK', 'SEEK_CUR', 'SEEK_END', 'SEEK_SET', 'TMP_MAX', 'W_OK', 'X_OK', '_AddedDllDirectory', '_Environ', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_check_methods', '_execvpe', '_exists', '_exit', '_fspath', '_get_exports_list', '_putenv', '_unsetenv', '_wrap_close', 'abc', 'abort', 'access', 'add_dll_directory', 'altsep', 'chdir', 'chmod', 'close', 'closerange', 'cpu_count', 'curdir', 'defpath', 'device_encoding', 'devnull', 'dup', 'dup2', 'environ', 'error', 'execl', 'execle', 'execlp', 'execlpe', 'execv', 'execve', 'execvp', 'execvpe', 'extsep', 'fdopen', 'fsdecode', 'fsencode', 'fspath', 'fstat', 'fsync', 'ftruncate', 'get_exec_path', 'get_handle_inheritable', 'get_inheritable', 'get_terminal_size', 'getcwd', 'getcwdb', 'getenv', 'getlogin', 'getpid', 'getppid', 'isatty', 'kill', 'linesep', 'link', 'listdir', 'lseek', 'lstat', 'makedirs', 'mkdir', 'name', 'open', 'pardir', 'path', 'pathsep', 'pipe', 'popen', 'putenv', 'read', 'readlink', 'remove', 'removedirs', 'rename', 'renames', 'replace', 'rmdir', 'scandir', 'sep', 'set_handle_inheritable', 'set_inheritable', 'spawnl', 'spawnle', 'spawnv', 'spawnve', 'st', 'startfile', 'stat', 'stat_result', 'statvfs_result', 'strerror', 'supports_bytes_environ', 'supports_dir_fd', 'supports_effective_ids', 'supports_fd', 'supports_follow_symlinks', 'symlink', 'sys', 'system', 'terminal_size', 'times', 'times_result', 'truncate', 'umask', 'uname_result', 'unlink', 'urandom', 'utime', 'waitpid', 'walk', 'write']\n",
      "['DataError', 'DatabaseError', 'Error', 'IntegrityError', 'InterfaceError', 'InternalError', 'NotSupportedError', 'OperationalError', 'ProgrammingError', 'Warning', '__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'backup', 'close', 'commit', 'create_aggregate', 'create_collation', 'create_function', 'cursor', 'enable_load_extension', 'execute', 'executemany', 'executescript', 'in_transaction', 'interrupt', 'isolation_level', 'iterdump', 'load_extension', 'rollback', 'row_factory', 'set_authorizer', 'set_progress_handler', 'set_trace_callback', 'text_factory', 'total_changes']\n"
     ]
    }
   ],
   "source": [
    "con.close()\n",
    "con.__exit__\n",
    "\n",
    "print(dir(os))\n",
    "print(dir(con))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
