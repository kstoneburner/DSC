{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 540 - Week XX/XX\n",
    "- ## Chapter X, Exercise X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling the BoingBoing Candy Survey\n",
    "This is fun. Boing Boing has been in my daily reading rotation for a longtime. So of course I have to work with the data. It doesn't hit the same notes as the symphony, but the data is sweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are three years of the Candy surveys, import each one\n",
    "df_2015 = pd.read_excel(\"z_sup_wk07_08_candy2015.xlsx\")\n",
    "df_2016 = pd.read_excel(\"z_sup_wk07_08_candy2016.xlsx\")\n",
    "df_2017 = pd.read_excel(\"z_sup_wk07_08_candy2017.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' [Butterfinger]', ' [100 Grand Bar]', ' [Anonymous brown globs that come in black and orange wrappers]', ' [Any full-sized candy bar]', ' [Black Jacks]', ' [Bonkers]', ' [Bottle Caps]', \" [Box'o'Raisins]\", ' [Brach products (not including candy corn)]', ' [Bubble Gum]', ' [Cadbury Creme Eggs]', ' [Candy Corn]', ' [Vials of pure high fructose corn syrup, for main-lining into your vein]', ' [Candy that is clearly just the stuff given out for free at restaurants]', ' [Cash, or other forms of legal tender]', ' [Chiclets]', ' [Caramellos]', ' [Snickers]', ' [Dark Chocolate Hershey]', ' [Dental paraphenalia]', ' [Dots]', ' [Fuzzy Peaches]', ' [Generic Brand Acetaminophen]', ' [Glow sticks]', ' [Broken glow stick]', ' [Goo Goo Clusters]', \" [Good N' Plenty]\", ' [Gum from baseball cards]', ' [Gummy Bears straight up]', ' [Creepy Religious comics/Chick Tracts]', ' [Healthy Fruit]', ' [Heath Bar]', ' [Hershey’s Kissables]', ' [Hershey’s Milk Chocolate]', ' [Hugs (actual physical hugs)]', ' [Jolly Rancher (bad flavor)]', ' [Jolly Ranchers (good flavor)]', ' [Kale smoothie]', ' [Kinder Happy Hippo]', ' [Kit Kat]', ' [Hard Candy]', ' [Lapel Pins]', ' [LemonHeads]', ' [Licorice]', ' [Licorice (not black)]', ' [Lindt Truffle]', ' [Lollipops]', ' [Mars]', ' [Mary Janes]', ' [Maynards]', ' [Milk Duds]', ' [LaffyTaffy]', ' [Minibags of chips]', ' [JoyJoy (Mit Iodine)]', ' [Reggie Jackson Bar]', ' [Pixy Stix]', ' [Nerds]', ' [Nestle Crunch]', \" [Now'n'Laters]\", ' [Pencils]', ' [Milky Way]', ' [Reese’s Peanut Butter Cups]', ' [Tolberone something or other]', ' [Runts]', ' [Junior Mints]', ' [Senior Mints]', ' [Mint Kisses]', ' [Mint Juleps]', ' [Mint Leaves]', ' [Peanut M&M’s]', ' [Regular M&Ms]', ' [Mint M&Ms]', ' [Ribbon candy]', ' [Rolos]', ' [Skittles]', ' [Smarties (American)]', ' [Smarties (Commonwealth)]', ' [Chick-o-Sticks (we don’t know what that is)]', ' [Spotted Dick]', ' [Starburst]', ' [Swedish Fish]', ' [Sweetums]', ' [Those odd marshmallow circus peanut things]', ' [Three Musketeers]', ' [Peterson Brand Sidewalk Chalk]', ' [Peanut Butter Bars]', ' [Peanut Butter Jars]', ' [Trail Mix]', ' [Twix]', ' [Vicodin]', ' [White Bread]', ' [Whole Wheat anything]', ' [York Peppermint Patties]', ' [Sea-salt flavored stuff, probably chocolate, since this is the \"it\" flavor of the year]', ' [Necco Wafers]']\n",
      "['Butterfinger', '100 Grand Bar', 'Anonymous brown globs that come in black and orange wrappers', 'Any full-sized candy bar', 'Black Jacks', 'Bonkers', 'Bottle Caps', \"Box'o'Raisins\", 'Brach products (not including candy corn)', 'Bubble Gum', 'Cadbury Creme Eggs', 'Candy Corn', 'Vials of pure high fructose corn syrup, for main-lining into your vein', 'Candy that is clearly just the stuff given out for free at restaurants', 'Cash, or other forms of legal tender', 'Chiclets', 'Caramellos', 'Snickers', 'Dark Chocolate Hershey', 'Dental paraphenalia', 'Dots', 'Fuzzy Peaches', 'Generic Brand Acetaminophen', 'Glow sticks', 'Broken glow stick', 'Goo Goo Clusters', \"Good N' Plenty\", 'Gum from baseball cards', 'Gummy Bears straight up', 'Creepy Religious comics/Chick Tracts', 'Healthy Fruit', 'Heath Bar', 'Hershey’s Kissables', 'Hershey’s Milk Chocolate', 'Hugs (actual physical hugs)', 'Jolly Rancher (bad flavor)', 'Jolly Ranchers (good flavor)', 'Kale smoothie', 'Kinder Happy Hippo', 'Kit Kat', 'Hard Candy', 'Lapel Pins', 'LemonHeads', 'Licorice', 'Licorice (not black)', 'Lindt Truffle', 'Lollipops', 'Mars', 'Mary Janes', 'Maynards', 'Milk Duds', 'LaffyTaffy', 'Minibags of chips', 'JoyJoy (Mit Iodine)', 'Reggie Jackson Bar', 'Pixy Stix', 'Nerds', 'Nestle Crunch', \"Now'n'Laters\", 'Pencils', 'Milky Way', 'Reese’s Peanut Butter Cups', 'Tolberone something or other', 'Runts', 'Junior Mints', 'Senior Mints', 'Mint Kisses', 'Mint Juleps', 'Mint Leaves', 'Peanut M&M’s', 'Regular M&Ms', 'Mint M&Ms', 'Ribbon candy', 'Rolos', 'Skittles', 'Smarties (American)', 'Smarties (Commonwealth)', 'Chick-o-Sticks (we don’t know what that is)', 'Spotted Dick', 'Starburst', 'Swedish Fish', 'Sweetums', 'Those odd marshmallow circus peanut things', 'Three Musketeers', 'Peterson Brand Sidewalk Chalk', 'Peanut Butter Bars', 'Peanut Butter Jars', 'Trail Mix', 'Twix', 'Vicodin', 'White Bread', 'Whole Wheat anything', 'York Peppermint Patties', 'Sea-salt flavored stuff, probably chocolate, since this is the \"it\" flavor of the year', 'Necco Wafers']\n"
     ]
    }
   ],
   "source": [
    "#//*** Rename some columns to help with Fuzzy Matching\n",
    "df_2015.rename(columns = {\" [Box’o’ Raisins]\" : \" [Box'o'Raisins]\"}, inplace=True)\n",
    "\n",
    "\" [Dark Chocolate Hershey]\" : \" [Hershey's Dark Chocolate]\"\n",
    "\" [Hershey’s Kissables]\" : \" [Hershey's Kisses]\"\n",
    "\" [Licorice]\"  - Licorice (not black) - Licorice (not black)\n",
    "JoyJoy (Mit Iodine) - JoyJoy (Mit Iodine!) - JoyJoy (Mit Iodine!)\n",
    "\n",
    "print(list( df_2015.columns [ df_2015.columns.str.match('^.\\[')]))\n",
    "\n",
    "#//*** It's a little early for Merging, But let's look at the columns to determine which ones have candy types.\n",
    "#//*** No sense in cleaning columns we are not going to use.\n",
    "#//*** 2015 - Candy names start at the beginning of the column name and are wrapped in brackets\n",
    "\n",
    "#//*** Get Candy Columns for 2015. Use Regex to to match the start of the string, any character then Bracket.\n",
    "#//*** This eliminates the degrees of separation quetions.\n",
    "#/**** Trim the leading space and brackets while we are at it. \n",
    "cols_2015 = list( df_2015.columns [ df_2015.columns.str.match('^.\\[')])\n",
    "\n",
    "#//*** Generate a cleaner list of column names. The clean name will be used to concatenate the dataframes\n",
    "cols_2015_clean = list(df_2015.columns [ df_2015.columns.str.match('^.\\[')].str.replace('^.',\"\").str.replace('[',\"\").str.replace(']',\"\"))\n",
    "#//*** This is a good starting point for 2015 columns\n",
    "#print(cols_2015)\n",
    "print(f\"{cols_2015_clean}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100 Grand Bar', 'Anonymous brown globs that come in black and orange wrappers', 'Any full-sized candy bar', 'Black Jacks', 'Bonkers (the candy)', 'Bonkers (the board game)', 'Bottle Caps', \"Box'o'Raisins\", 'Broken glow stick', 'Butterfinger', 'Cadbury Creme Eggs', 'Candy Corn', 'Candy that is clearly just the stuff given out for free at restaurants', 'Caramellos', 'Cash, or other forms of legal tender', 'Chardonnay', 'Chick-o-Sticks (we don’t know what that is)', 'Chiclets', 'Coffee Crisp', 'Creepy Religious comics/Chick Tracts', 'Dental paraphenalia', 'Dots', 'Dove Bars', 'Fuzzy Peaches', 'Generic Brand Acetaminophen', 'Glow sticks', 'Goo Goo Clusters', \"Good N' Plenty\", 'Gum from baseball cards', 'Gummy Bears straight up', 'Hard Candy', 'Healthy Fruit', 'Heath Bar', \"Hershey's Dark Chocolate\", 'Hershey’s Milk Chocolate', \"Hershey's Kisses\", 'Hugs (actual physical hugs)', 'Jolly Rancher (bad flavor)', 'Jolly Ranchers (good flavor)', 'JoyJoy (Mit Iodine!)', 'Junior Mints', 'Senior Mints', 'Kale smoothie', 'Kinder Happy Hippo', 'Kit Kat', 'LaffyTaffy', 'LemonHeads', 'Licorice (not black)', 'Licorice (yes black)', 'Lindt Truffle', 'Lollipops', 'Mars', 'Mary Janes', 'Maynards', 'Mike and Ike', 'Milk Duds', 'Milky Way', 'Regular M&Ms', 'Peanut M&M’s', \"Blue M&M's\", \"Red M&M's\", \"Third Party M&M's\", 'Minibags of chips', 'Mint Kisses', 'Mint Juleps', 'Mr. Goodbar', 'Necco Wafers', 'Nerds', 'Nestle Crunch', \"Now'n'Laters\", 'Peeps', 'Pencils', 'Person of Interest Season 3 DVD Box Set (not including Disc 4 with hilarious outtakes)', 'Pixy Stix', 'Reese’s Peanut Butter Cups', \"Reese's Pieces\", 'Reggie Jackson Bar', 'Rolos', 'Skittles', 'Smarties (American)', 'Smarties (Commonwealth)', 'Snickers', 'Sourpatch Kids (i.e. abominations of nature)', 'Spotted Dick', 'Starburst', 'Sweet Tarts', 'Swedish Fish', 'Sweetums (a friend to diabetes)', 'Tic Tacs', 'Those odd marshmallow circus peanut things', 'Three Musketeers', 'Tolberone something or other', 'Trail Mix', 'Twix', 'Vials of pure high fructose corn syrup, for main-lining into your vein', 'Vicodin', 'Whatchamacallit Bars', 'White Bread', 'Whole Wheat anything', 'York Peppermint Patties', 'York Peppermint Patties Ignore']\n"
     ]
    }
   ],
   "source": [
    "#//*** Get Candy Columns for 2016. These questions are structured using the same methods as 2015.\n",
    "cols_2016 = list( df_2016.columns [ df_2016.columns.str.match('^.\\[')])\n",
    "#.str.replace('^.',\"\").str.replace('[',\"\").str.replace(']',\"\")\n",
    "\n",
    "\n",
    "#//*** Generate a cleaner list of column names. The clean name will be used to concatenate the dataframes\n",
    "cols_2016_clean = list(df_2016.columns [ df_2016.columns.str.match('^.\\[')].str.replace('^.',\"\").str.replace('[',\"\").str.replace(']',\"\"))\n",
    "\n",
    "print(cols_2016_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100 Grand Bar', 'Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)', 'Any full-sized candy bar', 'Black Jacks', 'Bonkers (the candy)', 'Bonkers (the board game)', 'Bottle Caps', \"Box'o'Raisins\", 'Broken glow stick', 'Butterfinger', 'Cadbury Creme Eggs', 'Candy Corn', 'Candy that is clearly just the stuff given out for free at restaurants', 'Caramellos', 'Cash, or other forms of legal tender', 'Chardonnay', 'Chick-o-Sticks (we don’t know what that is)', 'Chiclets', 'Coffee Crisp', 'Creepy Religious comics/Chick Tracts', 'Dental paraphenalia', 'Dots', 'Dove Bars', 'Fuzzy Peaches', 'Generic Brand Acetaminophen', 'Glow sticks', 'Goo Goo Clusters', \"Good N' Plenty\", 'Gum from baseball cards', 'Gummy Bears straight up', 'Hard Candy', 'Healthy Fruit', 'Heath Bar', \"Hershey's Dark Chocolate\", 'Hershey’s Milk Chocolate', \"Hershey's Kisses\", 'Hugs (actual physical hugs)', 'Jolly Rancher (bad flavor)', 'Jolly Ranchers (good flavor)', 'JoyJoy (Mit Iodine!)', 'Junior Mints', 'Senior Mints', 'Kale smoothie', 'Kinder Happy Hippo', 'Kit Kat', 'LaffyTaffy', 'LemonHeads', 'Licorice (not black)', 'Licorice (yes black)', 'Lindt Truffle', 'Lollipops', 'Mars', 'Maynards', 'Mike and Ike', 'Milk Duds', 'Milky Way', 'Regular M&Ms', 'Peanut M&M’s', \"Blue M&M's\", \"Red M&M's\", \"Green Party M&M's\", \"Independent M&M's\", \"Abstained from M&M'ing.\", 'Minibags of chips', 'Mint Kisses', 'Mint Juleps', 'Mr. Goodbar', 'Necco Wafers', 'Nerds', 'Nestle Crunch', \"Now'n'Laters\", 'Peeps', 'Pencils', 'Pixy Stix', 'Real Housewives of Orange County Season 9 Blue-Ray', 'Reese’s Peanut Butter Cups', \"Reese's Pieces\", 'Reggie Jackson Bar', 'Rolos', 'Sandwich-sized bags filled with BooBerry Crunch', 'Skittles', 'Smarties (American)', 'Smarties (Commonwealth)', 'Snickers', 'Sourpatch Kids (i.e. abominations of nature)', 'Spotted Dick', 'Starburst', 'Sweet Tarts', 'Swedish Fish', 'Sweetums (a friend to diabetes)', 'Take 5', 'Tic Tacs', 'Those odd marshmallow circus peanut things', 'Three Musketeers', 'Tolberone something or other', 'Trail Mix', 'Twix', 'Vials of pure high fructose corn syrup, for main-lining into your vein', 'Vicodin', 'Whatchamacallit Bars', 'White Bread', 'Whole Wheat anything', 'York Peppermint Patties']\n"
     ]
    }
   ],
   "source": [
    "#//*** Get Candy Columns for 2017. All Candy questions Begin with Q6 in the Column Name.\n",
    "cols_2017 = list(df_2017.columns [ df_2017.columns.str.match('^Q6')])\n",
    "#.str.replace('^Q6 \\| ','')\n",
    "cols_2017_clean = list(df_2017.columns [ df_2017.columns.str.match('^Q6')].str.replace('^Q6 \\| ',''))\n",
    "\n",
    "print(cols_2017_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candy Column Lengths\n",
      "2015: 95 - 2016: 101 - 2017: 103\n",
      "Bonkers - Snickers - Snickers\n",
      "Box’o’ Raisins - Box'o'Raisins - Box'o'Raisins\n",
      "Brach products (not including candy corn) - Bonkers (the candy) - Bonkers (the candy)\n",
      "Bubble Gum - Blue M&M's - Blue M&M's\n",
      "Dark Chocolate Hershey - Hershey's Dark Chocolate - Hershey's Dark Chocolate\n",
      "Hershey’s Kissables - Hershey's Kisses - Hershey's Kisses\n",
      "Lapel Pins - Senior Mints - Senior Mints\n",
      "Licorice - Licorice (not black) - Licorice (not black)\n",
      "JoyJoy (Mit Iodine) - JoyJoy (Mit Iodine!) - JoyJoy (Mit Iodine!)\n",
      "Runts - Junior Mints - Junior Mints\n",
      "Mint Leaves - Mint Kisses - Mint Kisses\n",
      "Mint M&Ms - Peanut M&M’s - Peanut M&M’s\n",
      "Ribbon candy - Bonkers (the candy) - Bonkers (the candy)\n",
      "Sweetums - Sweet Tarts - Sweet Tarts\n",
      "Peterson Brand Sidewalk Chalk - Generic Brand Acetaminophen - Generic Brand Acetaminophen\n",
      "Peanut Butter Bars - Reese’s Peanut Butter Cups - Reese’s Peanut Butter Cups\n",
      "Peanut Butter Jars - Reese’s Peanut Butter Cups - Reese’s Peanut Butter Cups\n",
      "Sea-salt flavored stuff, probably chocolate, since this is the \"it\" flavor of the year - Candy that is clearly just the stuff given out for free at restaurants - Candy that is clearly just the stuff given out for free at restaurants\n"
     ]
    }
   ],
   "source": [
    "#//**** Get the differences between two lists. Code which I liberally borrowed from the geeksforgeeks.org\n",
    "#//*** Determine the differences in candy values\n",
    "\n",
    "print(\"Candy Column Lengths\")\n",
    "print(f\"2015: {len(cols_2015_clean)} - 2016: {len(cols_2016_clean)} - 2017: {len(cols_2017_clean)}\")\n",
    "\n",
    "               \n",
    "                 \n",
    "#//*** These are not equal, we need to remove the items not found in all three dataframes. Likely due to\n",
    "#//*** Fun statistical questions like: Vicodin. Which are likely used to reduce testing bias (or the researchers)\n",
    "#//*** have an awesome sense of humour or both).\n",
    "for index_2015 in range(0, len(cols_2015_clean)):\n",
    "    \n",
    "    value_2015 = cols_2015_clean[index_2015]\n",
    "    \n",
    "    #//*** Fuzzy Match with 2016 List\n",
    "    best_2016_score = -1\n",
    "    best_2016_index = -1\n",
    "    best_2016_value = \"\"\n",
    "\n",
    "    for index_2016 in range(0,len(cols_2016_clean)):\n",
    "        value_2016 = cols_2016_clean[index_2016]\n",
    "        score = fuzz.ratio(value_2015,value_2016)\n",
    "\n",
    "        if score > best_2016_score:\n",
    "            best_2016_score = score\n",
    "            best_2016_index = index_2016\n",
    "            best_2016_value = value_2016\n",
    "        \n",
    "    #print(f\"{index_2015}:{value_2015} - [{best_2016_score}] {best_2016_index}: {best_2016_value}\")\n",
    "\n",
    "    #//*** Fuzzy Match with 2017 List\n",
    "    best_2017_score = -1\n",
    "    best_2017_index = -1\n",
    "    best_2017_value = \"\"\n",
    "\n",
    "    for index_2017 in range(0,len(cols_2017_clean)):\n",
    "        value_2017 = cols_2017_clean[index_2017]\n",
    "        score = fuzz.ratio(value_2015,value_2017)\n",
    "\n",
    "        if score > best_2017_score:\n",
    "            best_2017_score = score\n",
    "            best_2017_index = index_2017\n",
    "            best_2017_value = value_2017\n",
    "    \n",
    "    if best_2016_score < 100:\n",
    "        print(f\"{value_2015} - {best_2016_value} - {best_2017_value}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build New Dataframes with just the columns we are going to combine.\n",
    "concat_df_2015 = pd.DataFrame()\n",
    "concat_df_2016 = pd.DataFrame()\n",
    "concat_df_2017 = pd.DataFrame()\n",
    "\n",
    "#//*** Add the Age Columns Manually\n",
    "concat_df_2015['age'] = df_2015['How old are you?']\n",
    "concat_df_2016['age'] = df_2016['How old are you?']\n",
    "concat_df_2017['age'] = df_2017['Q3: AGE']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7 - Task1 ###\n",
    "**Filter Out Missing Values**\n",
    "\n",
    "In the Drop rows where no Candy values were filled out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Drop rows where None of the Candy columns filled out\n",
    "print(f\"2015 length  before cleaning: {len(df_2015)}\")\n",
    "print(f\"2016 length before cleaning: {len(df_2016)}\")\n",
    "print(f\"2017 length before cleaning: {len(df_2017)}\")\n",
    "\n",
    "\n",
    "df_2015.dropna(axis=0,how='all',subset=cols_2015,inplace=True)\n",
    "df_2016.dropna(axis=0,how='all',subset=cols_2016,inplace=True)\n",
    "df_2017.dropna(axis=0,how='all',subset=cols_2017,inplace=True)\n",
    "\n",
    "print(f\"2015 length after cleaning: {len(df_2015)}\")\n",
    "print(f\"2016 length after cleaning: {len(df_2016)}\")\n",
    "print(f\"2017 length after cleaning: {len(df_2017)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7 - Task 2###\n",
    "**Replace Values**\n",
    "\n",
    "In many cases usere did not fill out all the form data. If we dropped these values, there wouldn't be much of a survey. Replace NaN with 0. Which will be used as a categorical for not answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Replace NaN with 0 in 2015 Data\n",
    "df_2015.fillna(value=0,axis=0,inplace=True)\n",
    "print(df_2015.head(10))\n",
    "\n",
    "#//*** Replace NaN with 0 in 2016 Data\n",
    "df_2016.fillna(value=0,axis=0,inplace=True)\n",
    "\n",
    "#//*** Replace NaN with 0 in 2017 Data\n",
    "df_2017.fillna(value=0,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7 - Task 3###\n",
    "**Transform Data**\n",
    "\n",
    "Convert the categorical descriptions from Despair and Joy to 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Check for unique values in the candy columsn\n",
    "#//*** Looking for miscodes or irregularities\n",
    "print(pd.unique(df_2015[cols_2015].values.ravel()))\n",
    "print(pd.unique(df_2016[list(cols_2016)].values.ravel()))\n",
    "print(pd.unique(df_2017[list(cols_2017)].values.ravel()))\n",
    "\n",
    "\n",
    "#for x in cols_2016:\n",
    "#    print(df_2016[x].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Apply a map to e\n",
    "def remap_df(input_df, input_cols, input_map):\n",
    "    \n",
    "    for col in input_cols:\n",
    "        \n",
    "        input_df[col] = input_df[col].map(input_map, na_action='ignore')\n",
    "    \n",
    "\n",
    "#//**************************************************************************\n",
    "#//*** Create Map based on Unique Values\n",
    "#//*** Replace Joy with 1, because joy should always go first\n",
    "#//*** Replace Despair with 2, because despair is greater than joy\n",
    "#//*** Replace Meh with 3, because apathy conquers all\n",
    "#//**************************************************************************\n",
    "\n",
    "remap_ratings = {'JOY' : 1, 'DESPAIR' : 2, 'MEH' : 3, 0 : 0}\n",
    "\n",
    "#//*** Mapping only applies to a series.\n",
    "#//*** Loop through the dataframes and apply the mapping to each column.\n",
    "#//*** This feels like a good use for a generator or Lambda expression.\n",
    "#//*** But I'm not that cool today.\n",
    "#//*** Do it with Loops because ... Loops\n",
    "\n",
    "#//*** Remaps can only be applied once. Adding a conditional to run if JOY exist as a unique value\n",
    "#//*** This speeds up coding / debugging due to the reusable nature of iPython\n",
    "#// Remap 2015\n",
    "if 'JOY' in list(pd.unique(df_2015[cols_2015].values.ravel())):\n",
    "    remap_df(df_2015, cols_2015, remap_ratings)\n",
    "\n",
    "#// Remap 2016\n",
    "if 'JOY' in list(pd.unique(df_2016[cols_2016].values.ravel())):\n",
    "    remap_df(df_2016, cols_2016, remap_ratings)\n",
    "\n",
    "#// Remap 2017    \n",
    "if 'JOY' in list(pd.unique(df_2017[cols_2017].values.ravel())):\n",
    "    remap_df(df_2017, cols_2017, remap_ratings)\n",
    "\n",
    "\n",
    "    \n",
    "#//*** Visually Check our Work   \n",
    "print(df_2015.head(5))\n",
    "print(df_2016.head(5))\n",
    "print(df_2017.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
