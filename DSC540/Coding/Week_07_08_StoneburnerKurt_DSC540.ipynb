{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 540 - Week XX/XX\n",
    "- ## Chapter X, Exercise X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling the BoingBoing Candy Survey\n",
    "This is fun. Boing Boing has been in my daily reading rotation for a longtime. So of course I have to work with the data. It doesn't hit the same notes as the symphony, but the data is sweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are three years of the Candy surveys, import each one\n",
    "df_2015 = pd.read_excel(\"z_sup_wk07_08_candy2015.xlsx\")\n",
    "df_2016 = pd.read_excel(\"z_sup_wk07_08_candy2016.xlsx\")\n",
    "df_2017 = pd.read_excel(\"z_sup_wk07_08_candy2017.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' [Butterfinger]', ' [100 Grand Bar]', ' [Anonymous brown globs that come in black and orange wrappers]', ' [Any full-sized candy bar]', ' [Black Jacks]', ' [Bonkers]', ' [Bottle Caps]', \" [Box'o'Raisins]\", ' [Brach products (not including candy corn)]', ' [Bubble Gum]', ' [Cadbury Creme Eggs]', ' [Candy Corn]', ' [Vials of pure high fructose corn syrup, for main-lining into your vein]', ' [Candy that is clearly just the stuff given out for free at restaurants]', ' [Cash, or other forms of legal tender]', ' [Chiclets]', ' [Caramellos]', ' [Snickers]', \" [Hershey's Dark Chocolate]\", ' [Dental paraphenalia]', ' [Dots]', ' [Fuzzy Peaches]', ' [Generic Brand Acetaminophen]', ' [Glow sticks]', ' [Broken glow stick]', ' [Goo Goo Clusters]', \" [Good N' Plenty]\", ' [Gum from baseball cards]', ' [Gummy Bears straight up]', ' [Creepy Religious comics/Chick Tracts]', ' [Healthy Fruit]', ' [Heath Bar]', \" [Hershey's Kisses]\", ' [Hershey’s Milk Chocolate]', ' [Hugs (actual physical hugs)]', ' [Jolly Rancher (bad flavor)]', ' [Jolly Ranchers (good flavor)]', ' [Kale smoothie]', ' [Kinder Happy Hippo]', ' [Kit Kat]', ' [Hard Candy]', ' [Lapel Pins]', ' [LemonHeads]', ' [Licorice (not black)]', ' [Licorice (not black)]', ' [Lindt Truffle]', ' [Lollipops]', ' [Mars]', ' [Mary Janes]', ' [Maynards]', ' [Milk Duds]', ' [LaffyTaffy]', ' [Minibags of chips]', ' [JoyJoy (Mit Iodine)]', ' [Reggie Jackson Bar]', ' [Pixy Stix]', ' [Nerds]', ' [Nestle Crunch]', \" [Now'n'Laters]\", ' [Pencils]', ' [Milky Way]', ' [Reese’s Peanut Butter Cups]', ' [Tolberone something or other]', ' [Runts]', ' [Junior Mints]', ' [Senior Mints]', ' [Mint Kisses]', ' [Mint Juleps]', ' [Mint Leaves]', ' [Peanut M&M’s]', ' [Regular M&Ms]', ' [Mint M&Ms]', ' [Ribbon candy]', ' [Rolos]', ' [Skittles]', ' [Smarties (American)]', ' [Smarties (Commonwealth)]', ' [Chick-o-Sticks (we don’t know what that is)]', ' [Spotted Dick]', ' [Starburst]', ' [Swedish Fish]', ' [Sweetums]', ' [Those odd marshmallow circus peanut things]', ' [Three Musketeers]', ' [Peterson Brand Sidewalk Chalk]', ' [Peanut Butter Bars]', ' [Peanut Butter Jars]', ' [Trail Mix]', ' [Twix]', ' [Vicodin]', ' [White Bread]', ' [Whole Wheat anything]', ' [York Peppermint Patties]', ' [Sea-salt flavored stuff, probably chocolate, since this is the \"it\" flavor of the year]', ' [Necco Wafers]']\n",
      " [Butterfinger]\n",
      "['Butterfinger', '100 Grand Bar', 'Anonymous brown globs that come in black and orange wrappers', 'Any full-sized candy bar', 'Black Jacks', 'Bonkers', 'Bottle Caps', \"Box'o'Raisins\", 'Brach products (not including candy corn)', 'Bubble Gum', 'Cadbury Creme Eggs', 'Candy Corn', 'Vials of pure high fructose corn syrup, for main-lining into your vein', 'Candy that is clearly just the stuff given out for free at restaurants', 'Cash, or other forms of legal tender', 'Chiclets', 'Caramellos', 'Snickers', \"Hershey's Dark Chocolate\", 'Dental paraphenalia', 'Dots', 'Fuzzy Peaches', 'Generic Brand Acetaminophen', 'Glow sticks', 'Broken glow stick', 'Goo Goo Clusters', \"Good N' Plenty\", 'Gum from baseball cards', 'Gummy Bears straight up', 'Creepy Religious comics/Chick Tracts', 'Healthy Fruit', 'Heath Bar', \"Hershey's Kisses\", 'Hershey’s Milk Chocolate', 'Hugs (actual physical hugs)', 'Jolly Rancher (bad flavor)', 'Jolly Ranchers (good flavor)', 'Kale smoothie', 'Kinder Happy Hippo', 'Kit Kat', 'Hard Candy', 'Lapel Pins', 'LemonHeads', 'Licorice (not black)', 'Licorice (not black)', 'Lindt Truffle', 'Lollipops', 'Mars', 'Mary Janes', 'Maynards', 'Milk Duds', 'LaffyTaffy', 'Minibags of chips', 'JoyJoy (Mit Iodine)', 'Reggie Jackson Bar', 'Pixy Stix', 'Nerds', 'Nestle Crunch', \"Now'n'Laters\", 'Pencils', 'Milky Way', 'Reese’s Peanut Butter Cups', 'Tolberone something or other', 'Runts', 'Junior Mints', 'Senior Mints', 'Mint Kisses', 'Mint Juleps', 'Mint Leaves', 'Peanut M&M’s', 'Regular M&Ms', 'Mint M&Ms', 'Ribbon candy', 'Rolos', 'Skittles', 'Smarties (American)', 'Smarties (Commonwealth)', 'Chick-o-Sticks (we don’t know what that is)', 'Spotted Dick', 'Starburst', 'Swedish Fish', 'Sweetums', 'Those odd marshmallow circus peanut things', 'Three Musketeers', 'Peterson Brand Sidewalk Chalk', 'Peanut Butter Bars', 'Peanut Butter Jars', 'Trail Mix', 'Twix', 'Vicodin', 'White Bread', 'Whole Wheat anything', 'York Peppermint Patties', 'Sea-salt flavored stuff, probably chocolate, since this is the \"it\" flavor of the year', 'Necco Wafers']\n"
     ]
    }
   ],
   "source": [
    "#//*** Rename some columns to help with Fuzzy Matching\n",
    "df_2015.rename(columns = {\" [Box’o’ Raisins]\" : \" [Box'o'Raisins]\", \" [Dark Chocolate Hershey]\" : \" [Hershey's Dark Chocolate]\",\" [Hershey’s Kissables]\" : \" [Hershey's Kisses]\",\" [Licorice]\" :\" [Licorice (not black)]\"}, inplace=True)\n",
    "\n",
    "\n",
    "print(list( df_2015.columns [ df_2015.columns.str.match('^.\\[')]))\n",
    "\n",
    "#//*** It's a little early for Merging, But let's look at the columns to determine which ones have candy types.\n",
    "#//*** No sense in cleaning columns we are not going to use.\n",
    "#//*** 2015 - Candy names start at the beginning of the column name and are wrapped in brackets\n",
    "\n",
    "#//*** Get Candy Columns for 2015. Use Regex to to match the start of the string, any character then Bracket.\n",
    "#//*** This eliminates the degrees of separation quetions.\n",
    "#/**** Trim the leading space and brackets while we are at it. \n",
    "cols_2015 = list( df_2015.columns [ df_2015.columns.str.match('^.\\[')])\n",
    "\n",
    "#//*** Generate a cleaner list of column names. The clean name will be used to concatenate the dataframes\n",
    "cols_2015_clean = list(df_2015.columns [ df_2015.columns.str.match('^.\\[')].str.replace('^.',\"\").str.replace('[',\"\").str.replace(']',\"\"))\n",
    "#//*** This is a good starting point for 2015 columns\n",
    "\n",
    "print(f\"{cols_2015_clean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' [100 Grand Bar]', ' [Anonymous brown globs that come in black and orange wrappers]', ' [Any full-sized candy bar]', ' [Black Jacks]', ' [Bonkers (the candy)]', ' [Bonkers (the board game)]', ' [Bottle Caps]', \" [Box'o'Raisins]\", ' [Broken glow stick]', ' [Butterfinger]', ' [Cadbury Creme Eggs]', ' [Candy Corn]', ' [Candy that is clearly just the stuff given out for free at restaurants]', ' [Caramellos]', ' [Cash, or other forms of legal tender]', ' [Chardonnay]', ' [Chick-o-Sticks (we don’t know what that is)]', ' [Chiclets]', ' [Coffee Crisp]', ' [Creepy Religious comics/Chick Tracts]', ' [Dental paraphenalia]', ' [Dots]', ' [Dove Bars]', ' [Fuzzy Peaches]', ' [Generic Brand Acetaminophen]', ' [Glow sticks]', ' [Goo Goo Clusters]', \" [Good N' Plenty]\", ' [Gum from baseball cards]', ' [Gummy Bears straight up]', ' [Hard Candy]', ' [Healthy Fruit]', ' [Heath Bar]', \" [Hershey's Dark Chocolate]\", ' [Hershey’s Milk Chocolate]', \" [Hershey's Kisses]\", ' [Hugs (actual physical hugs)]', ' [Jolly Rancher (bad flavor)]', ' [Jolly Ranchers (good flavor)]', ' [JoyJoy (Mit Iodine!)]', ' [Junior Mints]', ' [Senior Mints]', ' [Kale smoothie]', ' [Kinder Happy Hippo]', ' [Kit Kat]', ' [LaffyTaffy]', ' [LemonHeads]', ' [Licorice (not black)]', ' [Licorice (yes black)]', ' [Lindt Truffle]', ' [Lollipops]', ' [Mars]', ' [Mary Janes]', ' [Maynards]', ' [Mike and Ike]', ' [Milk Duds]', ' [Milky Way]', ' [Regular M&Ms]', ' [Peanut M&M’s]', \" [Blue M&M's]\", \" [Red M&M's]\", \" [Third Party M&M's]\", ' [Minibags of chips]', ' [Mint Kisses]', ' [Mint Juleps]', ' [Mr. Goodbar]', ' [Necco Wafers]', ' [Nerds]', ' [Nestle Crunch]', \" [Now'n'Laters]\", ' [Peeps]', ' [Pencils]', ' [Person of Interest Season 3 DVD Box Set (not including Disc 4 with hilarious outtakes)]', ' [Pixy Stix]', ' [Reese’s Peanut Butter Cups]', \" [Reese's Pieces]\", ' [Reggie Jackson Bar]', ' [Rolos]', ' [Skittles]', ' [Smarties (American)]', ' [Smarties (Commonwealth)]', ' [Snickers]', ' [Sourpatch Kids (i.e. abominations of nature)]', ' [Spotted Dick]', ' [Starburst]', ' [Sweet Tarts]', ' [Swedish Fish]', ' [Sweetums (a friend to diabetes)]', ' [Tic Tacs]', ' [Those odd marshmallow circus peanut things]', ' [Three Musketeers]', ' [Tolberone something or other]', ' [Trail Mix]', ' [Twix]', ' [Vials of pure high fructose corn syrup, for main-lining into your vein]', ' [Vicodin]', ' [Whatchamacallit Bars]', ' [White Bread]', ' [Whole Wheat anything]', ' [York Peppermint Patties]', ' [York Peppermint Patties] Ignore']\n",
      "['100 Grand Bar', 'Anonymous brown globs that come in black and orange wrappers', 'Any full-sized candy bar', 'Black Jacks', 'Bonkers (the candy)', 'Bonkers (the board game)', 'Bottle Caps', \"Box'o'Raisins\", 'Broken glow stick', 'Butterfinger', 'Cadbury Creme Eggs', 'Candy Corn', 'Candy that is clearly just the stuff given out for free at restaurants', 'Caramellos', 'Cash, or other forms of legal tender', 'Chardonnay', 'Chick-o-Sticks (we don’t know what that is)', 'Chiclets', 'Coffee Crisp', 'Creepy Religious comics/Chick Tracts', 'Dental paraphenalia', 'Dots', 'Dove Bars', 'Fuzzy Peaches', 'Generic Brand Acetaminophen', 'Glow sticks', 'Goo Goo Clusters', \"Good N' Plenty\", 'Gum from baseball cards', 'Gummy Bears straight up', 'Hard Candy', 'Healthy Fruit', 'Heath Bar', \"Hershey's Dark Chocolate\", 'Hershey’s Milk Chocolate', \"Hershey's Kisses\", 'Hugs (actual physical hugs)', 'Jolly Rancher (bad flavor)', 'Jolly Ranchers (good flavor)', 'JoyJoy (Mit Iodine!)', 'Junior Mints', 'Senior Mints', 'Kale smoothie', 'Kinder Happy Hippo', 'Kit Kat', 'LaffyTaffy', 'LemonHeads', 'Licorice (not black)', 'Licorice (yes black)', 'Lindt Truffle', 'Lollipops', 'Mars', 'Mary Janes', 'Maynards', 'Mike and Ike', 'Milk Duds', 'Milky Way', 'Regular M&Ms', 'Peanut M&M’s', \"Blue M&M's\", \"Red M&M's\", \"Third Party M&M's\", 'Minibags of chips', 'Mint Kisses', 'Mint Juleps', 'Mr. Goodbar', 'Necco Wafers', 'Nerds', 'Nestle Crunch', \"Now'n'Laters\", 'Peeps', 'Pencils', 'Person of Interest Season 3 DVD Box Set (not including Disc 4 with hilarious outtakes)', 'Pixy Stix', 'Reese’s Peanut Butter Cups', \"Reese's Pieces\", 'Reggie Jackson Bar', 'Rolos', 'Skittles', 'Smarties (American)', 'Smarties (Commonwealth)', 'Snickers', 'Sourpatch Kids (i.e. abominations of nature)', 'Spotted Dick', 'Starburst', 'Sweet Tarts', 'Swedish Fish', 'Sweetums (a friend to diabetes)', 'Tic Tacs', 'Those odd marshmallow circus peanut things', 'Three Musketeers', 'Tolberone something or other', 'Trail Mix', 'Twix', 'Vials of pure high fructose corn syrup, for main-lining into your vein', 'Vicodin', 'Whatchamacallit Bars', 'White Bread', 'Whole Wheat anything', 'York Peppermint Patties', 'York Peppermint Patties Ignore']\n"
     ]
    }
   ],
   "source": [
    "#//*** Get Candy Columns for 2016. These questions are structured using the same methods as 2015.\n",
    "cols_2016 = list( df_2016.columns [ df_2016.columns.str.match('^.\\[')])\n",
    "#.str.replace('^.',\"\").str.replace('[',\"\").str.replace(']',\"\")\n",
    "\n",
    "print(cols_2016)\n",
    "#//*** Generate a cleaner list of column names. The clean name will be used to concatenate the dataframes\n",
    "cols_2016_clean = list(df_2016.columns [ df_2016.columns.str.match('^.\\[')].str.replace('^.',\"\").str.replace('[',\"\").str.replace(']',\"\"))\n",
    "\n",
    "print(cols_2016_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Q6 | 100 Grand Bar', 'Q6 | Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)', 'Q6 | Any full-sized candy bar', 'Q6 | Black Jacks', 'Q6 | Bonkers (the candy)', 'Q6 | Bonkers (the board game)', 'Q6 | Bottle Caps', \"Q6 | Box'o'Raisins\", 'Q6 | Broken glow stick', 'Q6 | Butterfinger', 'Q6 | Cadbury Creme Eggs', 'Q6 | Candy Corn', 'Q6 | Candy that is clearly just the stuff given out for free at restaurants', 'Q6 | Caramellos', 'Q6 | Cash, or other forms of legal tender', 'Q6 | Chardonnay', 'Q6 | Chick-o-Sticks (we don’t know what that is)', 'Q6 | Chiclets', 'Q6 | Coffee Crisp', 'Q6 | Creepy Religious comics/Chick Tracts', 'Q6 | Dental paraphenalia', 'Q6 | Dots', 'Q6 | Dove Bars', 'Q6 | Fuzzy Peaches', 'Q6 | Generic Brand Acetaminophen', 'Q6 | Glow sticks', 'Q6 | Goo Goo Clusters', \"Q6 | Good N' Plenty\", 'Q6 | Gum from baseball cards', 'Q6 | Gummy Bears straight up', 'Q6 | Hard Candy', 'Q6 | Healthy Fruit', 'Q6 | Heath Bar', \"Q6 | Hershey's Dark Chocolate\", 'Q6 | Hershey’s Milk Chocolate', \"Q6 | Hershey's Kisses\", 'Q6 | Hugs (actual physical hugs)', 'Q6 | Jolly Rancher (bad flavor)', 'Q6 | Jolly Ranchers (good flavor)', 'Q6 | JoyJoy (Mit Iodine!)', 'Q6 | Junior Mints', 'Q6 | Senior Mints', 'Q6 | Kale smoothie', 'Q6 | Kinder Happy Hippo', 'Q6 | Kit Kat', 'Q6 | LaffyTaffy', 'Q6 | LemonHeads', 'Q6 | Licorice (not black)', 'Q6 | Licorice (yes black)', 'Q6 | Lindt Truffle', 'Q6 | Lollipops', 'Q6 | Mars', 'Q6 | Maynards', 'Q6 | Mike and Ike', 'Q6 | Milk Duds', 'Q6 | Milky Way', 'Q6 | Regular M&Ms', 'Q6 | Peanut M&M’s', \"Q6 | Blue M&M's\", \"Q6 | Red M&M's\", \"Q6 | Green Party M&M's\", \"Q6 | Independent M&M's\", \"Q6 | Abstained from M&M'ing.\", 'Q6 | Minibags of chips', 'Q6 | Mint Kisses', 'Q6 | Mint Juleps', 'Q6 | Mr. Goodbar', 'Q6 | Necco Wafers', 'Q6 | Nerds', 'Q6 | Nestle Crunch', \"Q6 | Now'n'Laters\", 'Q6 | Peeps', 'Q6 | Pencils', 'Q6 | Pixy Stix', 'Q6 | Real Housewives of Orange County Season 9 Blue-Ray', 'Q6 | Reese’s Peanut Butter Cups', \"Q6 | Reese's Pieces\", 'Q6 | Reggie Jackson Bar', 'Q6 | Rolos', 'Q6 | Sandwich-sized bags filled with BooBerry Crunch', 'Q6 | Skittles', 'Q6 | Smarties (American)', 'Q6 | Smarties (Commonwealth)', 'Q6 | Snickers', 'Q6 | Sourpatch Kids (i.e. abominations of nature)', 'Q6 | Spotted Dick', 'Q6 | Starburst', 'Q6 | Sweet Tarts', 'Q6 | Swedish Fish', 'Q6 | Sweetums (a friend to diabetes)', 'Q6 | Take 5', 'Q6 | Tic Tacs', 'Q6 | Those odd marshmallow circus peanut things', 'Q6 | Three Musketeers', 'Q6 | Tolberone something or other', 'Q6 | Trail Mix', 'Q6 | Twix', 'Q6 | Vials of pure high fructose corn syrup, for main-lining into your vein', 'Q6 | Vicodin', 'Q6 | Whatchamacallit Bars', 'Q6 | White Bread', 'Q6 | Whole Wheat anything', 'Q6 | York Peppermint Patties']\n",
      "['100 Grand Bar', 'Anonymous brown globs that come in black and orange wrappers\\t(a.k.a. Mary Janes)', 'Any full-sized candy bar', 'Black Jacks', 'Bonkers (the candy)', 'Bonkers (the board game)', 'Bottle Caps', \"Box'o'Raisins\", 'Broken glow stick', 'Butterfinger', 'Cadbury Creme Eggs', 'Candy Corn', 'Candy that is clearly just the stuff given out for free at restaurants', 'Caramellos', 'Cash, or other forms of legal tender', 'Chardonnay', 'Chick-o-Sticks (we don’t know what that is)', 'Chiclets', 'Coffee Crisp', 'Creepy Religious comics/Chick Tracts', 'Dental paraphenalia', 'Dots', 'Dove Bars', 'Fuzzy Peaches', 'Generic Brand Acetaminophen', 'Glow sticks', 'Goo Goo Clusters', \"Good N' Plenty\", 'Gum from baseball cards', 'Gummy Bears straight up', 'Hard Candy', 'Healthy Fruit', 'Heath Bar', \"Hershey's Dark Chocolate\", 'Hershey’s Milk Chocolate', \"Hershey's Kisses\", 'Hugs (actual physical hugs)', 'Jolly Rancher (bad flavor)', 'Jolly Ranchers (good flavor)', 'JoyJoy (Mit Iodine!)', 'Junior Mints', 'Senior Mints', 'Kale smoothie', 'Kinder Happy Hippo', 'Kit Kat', 'LaffyTaffy', 'LemonHeads', 'Licorice (not black)', 'Licorice (yes black)', 'Lindt Truffle', 'Lollipops', 'Mars', 'Maynards', 'Mike and Ike', 'Milk Duds', 'Milky Way', 'Regular M&Ms', 'Peanut M&M’s', \"Blue M&M's\", \"Red M&M's\", \"Green Party M&M's\", \"Independent M&M's\", \"Abstained from M&M'ing.\", 'Minibags of chips', 'Mint Kisses', 'Mint Juleps', 'Mr. Goodbar', 'Necco Wafers', 'Nerds', 'Nestle Crunch', \"Now'n'Laters\", 'Peeps', 'Pencils', 'Pixy Stix', 'Real Housewives of Orange County Season 9 Blue-Ray', 'Reese’s Peanut Butter Cups', \"Reese's Pieces\", 'Reggie Jackson Bar', 'Rolos', 'Sandwich-sized bags filled with BooBerry Crunch', 'Skittles', 'Smarties (American)', 'Smarties (Commonwealth)', 'Snickers', 'Sourpatch Kids (i.e. abominations of nature)', 'Spotted Dick', 'Starburst', 'Sweet Tarts', 'Swedish Fish', 'Sweetums (a friend to diabetes)', 'Take 5', 'Tic Tacs', 'Those odd marshmallow circus peanut things', 'Three Musketeers', 'Tolberone something or other', 'Trail Mix', 'Twix', 'Vials of pure high fructose corn syrup, for main-lining into your vein', 'Vicodin', 'Whatchamacallit Bars', 'White Bread', 'Whole Wheat anything', 'York Peppermint Patties']\n"
     ]
    }
   ],
   "source": [
    "#//*** Get Candy Columns for 2017. All Candy questions Begin with Q6 in the Column Name.\n",
    "cols_2017 = list(df_2017.columns [ df_2017.columns.str.match('^Q6')])\n",
    "#.str.replace('^Q6 \\| ','')\n",
    "cols_2017_clean = list(df_2017.columns [ df_2017.columns.str.match('^Q6')].str.replace('^Q6 \\| ',''))\n",
    "print(cols_2017)\n",
    "print(cols_2017_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 8 - Task1 ###\n",
    "**Merge the Dataframes**\n",
    "\n",
    "Merging the dataframes first means all the cleaning can be applied once.\n",
    "\n",
    "1. Combine the dates\n",
    "2. Add a year column\n",
    "3. Use FuzzyMatching on the the clean column names to find the common columns in all three datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2015-10-23 08:46:20.451\n",
      "1      2015-10-23 08:46:51.583\n",
      "2      2015-10-23 08:47:34.285\n",
      "3      2015-10-23 08:47:58.964\n",
      "4      2015-10-23 08:48:11.719\n",
      "                 ...          \n",
      "5625   2015-10-31 05:23:40.526\n",
      "5626   2015-10-31 05:29:26.937\n",
      "5627   2015-10-31 06:13:29.083\n",
      "5628   2015-10-31 06:26:52.566\n",
      "5629   2015-10-31 06:41:31.904\n",
      "Name: Timestamp, Length: 5630, dtype: datetime64[ns]\n",
      "0      2016-10-24 05:09:23.033\n",
      "1      2016-10-24 05:09:54.798\n",
      "2      2016-10-24 05:13:06.734\n",
      "3      2016-10-24 05:14:17.192\n",
      "4      2016-10-24 05:14:24.625\n",
      "                 ...          \n",
      "1254   2016-10-29 16:53:52.516\n",
      "1255   2016-10-30 06:53:54.735\n",
      "1256   2016-10-30 11:06:10.827\n",
      "1257   2016-10-30 16:07:26.539\n",
      "1258   2016-10-30 17:06:45.660\n",
      "Name: Timestamp, Length: 1259, dtype: datetime64[ns]\n",
      "0       90258773\n",
      "1       90272821\n",
      "2       90272829\n",
      "3       90272840\n",
      "4       90272841\n",
      "          ...   \n",
      "2455    90314359\n",
      "2456    90314580\n",
      "2457    90314634\n",
      "2458    90314658\n",
      "2459    90314802\n",
      "Name: Internal ID, Length: 2460, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#//*******************************************************************************************************\n",
    "#//*** Combine 2015, 2016, & 2017 datasets\n",
    "#//*** Build a year column indicating which year generated the results\n",
    "#//*** Use Fuzzy Matching on the column name to find the common columns between all three dataframes\n",
    "#//*******************************************************************************************************\n",
    "\n",
    "#//*** Initialize the dataframe\n",
    "candy_df = pd.DataFrame()\n",
    "\n",
    "print(df_2015[df_2015.columns[0]])\n",
    "print(df_2016[df_2016.columns[0]])\n",
    "print(df_2017[df_2017.columns[0]])\n",
    "\n",
    "#//***********************************************************************************************\n",
    "#//*** Generate a year value for each value\n",
    "#//*** Using 3 generators feels stupid And pythonic. But why not? it works.\n",
    "#//*** Each generator builds a list the length of each data frame with a year value.\n",
    "#//*** These lists are added together (concatenated), shoved into a Series, and added to candy_df\n",
    "#//***********************************************************************************************\n",
    "candy_df['year'] = pd.Series( \n",
    "    [2015 for x in range(0,len(df_2015))] + \n",
    "    [2016 for x in range(0,len(df_2016))] + \n",
    "    [2017 for x in range(0,len(df_2017))])                 \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cols_to_drop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-27b84d9eaf0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m#//*** If it didn't match 2016, then it isn't a match\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mbest_2016_score\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mcols_to_drop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{value_2015} - {best_2016_value} - {best_2017_value}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m#//*********************************************************************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cols_to_drop' is not defined"
     ]
    }
   ],
   "source": [
    "#//*****************************************************************\n",
    "#//*** Fuzzy match for columns that exist in all three dataframes\n",
    "#//*****************************************************************\n",
    "#//*** 2015 has the fewest columns, Use fuzzy matching to compare 2015 with 2016 then 2017 column names\n",
    "#//*** This keeps values that only match a score of 100, the rest get tossed aside.A record of skipped columns\n",
    "#//*** is kept in cols_to_drop for reference. \n",
    "#//*** Fuzzy Matching caught all but 4 (technically 5) columns. I manually renamed these columns earlier in the code.\n",
    "#//*** I did drop JoyJoy Mit Iodine, becuase it a Simpson's treehouse of Horrors Gag. Maybe it should be left in.\n",
    "#//*** But I contend \"The Simpsons Did It\"\n",
    "\n",
    "#//*** Loop through the index values of 2015\n",
    "#//*** The index is used to link the cleaned name to the original column name.\n",
    "for index_2015 in range(0, len(cols_2015_clean)):\n",
    "    \n",
    "    #//*** Get the 2015 column name\n",
    "    value_2015 = cols_2015_clean[index_2015]\n",
    "    \n",
    "    #//*** Initialize the 2016 best values\n",
    "    best_2016_score = -1\n",
    "    best_2016_index = -1\n",
    "    best_2016_value = \"\"\n",
    "\n",
    "    #//*** Loop through 2016 Column Names and Fuzzy Match with the current 2015 column name\n",
    "    #//*** Get the highest scoring value\n",
    "    for index_2016 in range(0,len(cols_2016_clean)):\n",
    "        \n",
    "        #//*** Get a 2016 column name\n",
    "        value_2016 = cols_2016_clean[index_2016]\n",
    "        \n",
    "        #//*** Get a Fuzzy Score comparing 2015 with 2016\n",
    "        score = fuzz.ratio(value_2015,value_2016)\n",
    "\n",
    "        #//*** Update the best score if applicable\n",
    "        if score > best_2016_score:\n",
    "            best_2016_score = score\n",
    "            best_2016_index = index_2016\n",
    "            best_2016_value = value_2016\n",
    "\n",
    "\n",
    "    #//*** Initialize the 2017 best values\n",
    "    best_2017_score = -1\n",
    "    best_2017_index = -1\n",
    "    best_2017_value = \"\"\n",
    "\n",
    "    #//*** Loop through 2017 Column Names and Fuzzy Match with the current 2015 column name\n",
    "    #//*** Get the highest scoring value\n",
    "    for index_2017 in range(0,len(cols_2017_clean)):\n",
    "\n",
    "        #//*** Get a 2017 column name\n",
    "        value_2017 = cols_2017_clean[index_2017]\n",
    "        \n",
    "        #//*** Get a Fuzzy Score comparing 2015 with 2017\n",
    "        score = fuzz.ratio(value_2015,value_2017)\n",
    "\n",
    "        #//*** Update the best score if applicable\n",
    "        if score > best_2017_score:\n",
    "            best_2017_score = score\n",
    "            best_2017_index = index_2017\n",
    "            best_2017_value = value_2017\n",
    "    \n",
    "    #//*** Keep a list of unable to match columns, These should all be fake/non-sensical/non-matching\n",
    "    #//*** If it didn't match 2016, then it isn't a match\n",
    "    if best_2016_score < 100:\n",
    "        cols_to_drop.append(f\"{value_2015} - {best_2016_value} - {best_2017_value}\")\n",
    "    else:\n",
    "        #//*********************************************************************************************************\n",
    "        #//*** It's a match!!! \n",
    "        #//*** Assemble the common columns and concatenate the series, then add to the final assembled dataframe\n",
    "        #//*** This is a totally awkward janky method to merge. But it works\n",
    "        #//*** This is similar to the year generator earlier, except this time we're grabbing\n",
    "        #//*** Columns based on index value to generate a Series, which is converted into lists for 2015,2016,2017\n",
    "        #//*** The lists are added (concatenated), converted back into a Series and shoved into the dataframe\n",
    "        #//*** Like I said, Janky...but effective.\n",
    "        #//*********************************************************************************************************\n",
    "        candy_df[value_2015] = pd.Series(list(df_2015[cols_2015[index_2015]]) \n",
    "                                         + list(df_2016[cols_2016[index_2016]])\n",
    "                                         + list(df_2017[cols_2017[index_2017]])\n",
    "                                        )\n",
    "\n",
    "print(candy_df.head(5))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7 - Task1 ###\n",
    "**Filter Out Missing Values**\n",
    "\n",
    "In the Drop rows where no Candy values were filled out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Drop rows where None of the Candy columns filled out\n",
    "#//*** Every Year has a value. Use a subset of columns without the year\n",
    "#//*** Technically we could leave these in, and replace the values with zeros\n",
    "#//*** Since they have no value \"GIT 'em Out of here!!!'\"\n",
    "print(f\"2015 length  before cleaning: {len(candy_df)}\")\n",
    "candy_df.dropna(axis=0,how='all',subset=candy_df.columns[1:],inplace=True)\n",
    "\n",
    "print(f\"2015 length after cleaning: {len(candy_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7 - Task 2###\n",
    "**Replace Values**\n",
    "\n",
    "In many cases usere did not fill out all the form data. If we dropped these values, there wouldn't be much of a survey. Replace NaN with 0. Which will be used as a categorical for not answered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Replace NaN with 0 in 2015 Data\n",
    "df_2015.fillna(value=0,axis=0,inplace=True)\n",
    "print(df_2015.head(10))\n",
    "\n",
    "#//*** Replace NaN with 0 in 2016 Data\n",
    "df_2016.fillna(value=0,axis=0,inplace=True)\n",
    "\n",
    "#//*** Replace NaN with 0 in 2017 Data\n",
    "df_2017.fillna(value=0,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 7 - Task 3###\n",
    "**Transform Data**\n",
    "\n",
    "Convert the categorical descriptions from Despair and Joy to 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Check for unique values in the candy columsn\n",
    "#//*** Looking for miscodes or irregularities\n",
    "print(pd.unique(df_2015[cols_2015].values.ravel()))\n",
    "print(pd.unique(df_2016[list(cols_2016)].values.ravel()))\n",
    "print(pd.unique(df_2017[list(cols_2017)].values.ravel()))\n",
    "\n",
    "\n",
    "#for x in cols_2016:\n",
    "#    print(df_2016[x].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Apply a map to e\n",
    "def remap_df(input_df, input_cols, input_map):\n",
    "    \n",
    "    for col in input_cols:\n",
    "        \n",
    "        input_df[col] = input_df[col].map(input_map, na_action='ignore')\n",
    "    \n",
    "\n",
    "#//**************************************************************************\n",
    "#//*** Create Map based on Unique Values\n",
    "#//*** Replace Joy with 1, because joy should always go first\n",
    "#//*** Replace Despair with 2, because despair is greater than joy\n",
    "#//*** Replace Meh with 3, because apathy conquers all\n",
    "#//**************************************************************************\n",
    "\n",
    "remap_ratings = {'JOY' : 1, 'DESPAIR' : 2, 'MEH' : 3, 0 : 0}\n",
    "\n",
    "#//*** Mapping only applies to a series.\n",
    "#//*** Loop through the dataframes and apply the mapping to each column.\n",
    "#//*** This feels like a good use for a generator or Lambda expression.\n",
    "#//*** But I'm not that cool today.\n",
    "#//*** Do it with Loops because ... Loops\n",
    "\n",
    "#//*** Remaps can only be applied once. Adding a conditional to run if JOY exist as a unique value\n",
    "#//*** This speeds up coding / debugging due to the reusable nature of iPython\n",
    "#// Remap 2015\n",
    "if 'JOY' in list(pd.unique(df_2015[cols_2015].values.ravel())):\n",
    "    remap_df(df_2015, cols_2015, remap_ratings)\n",
    "\n",
    "#// Remap 2016\n",
    "if 'JOY' in list(pd.unique(df_2016[cols_2016].values.ravel())):\n",
    "    remap_df(df_2016, cols_2016, remap_ratings)\n",
    "\n",
    "#// Remap 2017    \n",
    "if 'JOY' in list(pd.unique(df_2017[cols_2017].values.ravel())):\n",
    "    remap_df(df_2017, cols_2017, remap_ratings)\n",
    "\n",
    "\n",
    "    \n",
    "#//*** Visually Check our Work   \n",
    "print(df_2015.head(5))\n",
    "print(df_2016.head(5))\n",
    "print(df_2017.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
