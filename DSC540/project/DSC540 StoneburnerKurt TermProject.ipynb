{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSC540 Term Project\n",
    "Kurt Stoneburner\n",
    "\n",
    "California COVID019 Ethnicity Data\n",
    "https://data.ca.gov/dataset/covid-19-cases/resource/7e477adb-d7ab-4d4b-a198-dc4c6dc634c9\n",
    "\n",
    "API Example: https://data.ca.gov/api/3/action/datastore_search?resource_id=7e477adb-d7ab-4d4b-a198-dc4c6dc634c9&limit=5\n",
    "\n",
    "Requests Documentation: https://www.w3schools.com/python/ref_requests_response.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build Dictionary to hold Global values.\n",
    "#//*** Placing Globals in a dictionary, keeps things tidy and helps with scope.\n",
    "g = {\n",
    "    #//*** Values for the API call\n",
    "    \"api\" : {\n",
    "        \"url\" : \"https://data.ca.gov\",\n",
    "        \"ethnic\" : {\n",
    "            \"url\" : \"/api/3/action/datastore_search?resource_id=7e477adb-d7ab-4d4b-a198-dc4c6dc634c9\",\n",
    "            \"colnames\" : [], #//*** Column names\n",
    "            #//*** Additional Column name attributes. Probably not needed. But ingesting anyway.\n",
    "            #//*** Key - colname, value is attributes\n",
    "            \"attrib\" : {}, \n",
    "        } #//*** CLOSE api.ethnic\n",
    "        \n",
    "    } #//*** CLOSE api\n",
    "\n",
    "} #//***CLOSE g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Get the whole database 100 records at a time.\n",
    "#//*** This request gets the first 100 records. Future calls are handled in a loop\n",
    "#response = requests.get(g['api']['url']+g[\"api\"][\"ethnic\"][\"url\"])\n",
    "\n",
    "#print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 32\n",
      "Quitting Loop\n"
     ]
    }
   ],
   "source": [
    "#//*** Build a data frame returning all values from a California Data Source API\n",
    "def build_df_from_CA_API(url):\n",
    "    \n",
    "    #//*** Build the attributes for the API. This includes column names and column attributes which includes column\n",
    "    #//*** Type and other details\n",
    "\n",
    "    #//*** Request the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    #//*** Check for valid response\n",
    "    if response.ok == False:\n",
    "        #//*** Trouble with API, so some error handling here.\n",
    "        print(\"Trouble fetching API data\")\n",
    "        print(response)\n",
    "    else:\n",
    "        #//*** Valid Response\n",
    "        #//*** Convert response.content to a dictionary using JSON\n",
    "        rawOBJ=json.loads(response.content)\n",
    "        \n",
    "        #//*** Peek at the results\n",
    "        #print(rawOBJ[\"result\"].keys())\n",
    "        #for key, value in rawOBJ.ites():\n",
    "        #    print(f\"{key} : {value}\")\n",
    "        \n",
    "        #//*** Initialize list of column names\n",
    "        colnames = []\n",
    "        \n",
    "        #//*** Attrib_dict contains the attributes of each column\n",
    "        #//*** key = Column name\n",
    "        #//*** value = dictionary of attributes\n",
    "        attrib_dict = {}\n",
    "        \n",
    "        #//*** Parse the [results][fields] key for data\n",
    "        rawFields = rawOBJ[\"result\"]['fields']\n",
    "        \n",
    "        #//*** Loop through the rawfields dictionary.\n",
    "        #//*** each LoopOBJ contains a column name and column attributes\n",
    "        for loopOBJ in rawFields:\n",
    "            \n",
    "            #//*** Build temporary attributes for each loop instance\n",
    "            loopAttrib = {}\n",
    "\n",
    "            #//*** All Columns have an info field except _id.\n",
    "            if 'info' in loopOBJ.keys():\n",
    "                loopAttrib = loopOBJ[\"info\"]\n",
    "\n",
    "            #//*** Add Type to loopAttrib\n",
    "            loopAttrib['type'] = loopOBJ['type']\n",
    "\n",
    "            #//*** The column name is the ID field. Append the id field to the colnames list\n",
    "            colnames.append(loopOBJ['id'])\n",
    "\n",
    "            #//*** Assign the attributes dictionary based on column name\n",
    "            attrib_dict[ loopOBJ['id'] ] = loopAttrib\n",
    "        \n",
    "        \"\"\"\n",
    "        #//*** Display column names and attributes\n",
    "        print(f\"Column Names: {colnames}\")\n",
    "        \n",
    "        print(\"Attrib_dict\")\n",
    "        for x in colnames:\n",
    "            print(attrib_dict[x])\n",
    "        \"\"\"\n",
    "        \n",
    "        #//*************************************\n",
    "        #//*** Process the row an column data \n",
    "        #//*************************************\n",
    "\n",
    "        #//*** Build dictionary to hold raw data (rd)\n",
    "        rd = {}\n",
    "\n",
    "        #//*** Use each column as a key, create and empty list for each column\n",
    "        for x in colnames:\n",
    "            rd[x] = []\n",
    "\n",
    "        #//################################################################################################\n",
    "        #//*** While rawOBJ['success'] is true. Which implies we've successfully retrieved and API request\n",
    "        #//*** And is our loop mechanism to keep requesting records in 100 record incremenets.\n",
    "        #//################################################################################################\n",
    "        while rawOBJ[\"success\"]:\n",
    "\n",
    "            #//*** Get Records as a List for each entry\n",
    "            rawRecords = rawOBJ['result'][\"records\"]\n",
    "\n",
    "            #//*** Print a visual note for each loop iteraction / API call\n",
    "            print(f\"Processing {len(rawRecords)}\")\n",
    "\n",
    "            #//*** Parse Each Record.\n",
    "            for record in rawRecords:\n",
    "                #//*** Each Record is an object.\n",
    "                #//*** Each key is a column name.\n",
    "                #//*** Loop through the Column names and append the value to the column stored in rd\n",
    "\n",
    "                #//*** This is the sauce to that converts the object values into lists based on columns\n",
    "                #//*** It's kind of cool that the sausage is essentially made with two lines of code\n",
    "                #//*** The rest is just setup and control code.\n",
    "                for col in colnames:\n",
    "                    #//*** Assign each element to the appropriate column\n",
    "                    rd[col].append(record[col])\n",
    "\n",
    "            #//################################\n",
    "            #//*** Check if loop needs to end.\n",
    "            #//################################\n",
    "            #//*** If the number of records returned is less than the limit, we are done\n",
    "            if len(rawOBJ['result']['records']) < rawOBJ['result']['limit']:\n",
    "                print(\"Quitting Loop\")\n",
    "                break\n",
    "\n",
    "            #//*** Check if there are more records to grab\n",
    "            #//*** next contains the URL of the next request\n",
    "            #//*** The API is limited to 100 records per API request.\n",
    "            if 'next' in rawOBJ['result']['_links'].keys():\n",
    "                ##//***API CODE HERE\n",
    "                nextCall = rawOBJ['result']['_links']['next']\n",
    "\n",
    "                #//*** Add the Next value to the base API call\n",
    "                response = requests.get(g['api']['url']+nextCall)\n",
    "                rawOBJ=json.loads(response.content)\n",
    "                if rawOBJ[\"success\"] == False:\n",
    "                    #//*** Break if Success returns False\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                #//*** Quit Here\n",
    "                break\n",
    "        ########################################################\n",
    "        #//*** END while rawOBJ['success'] == True\n",
    "        #//*** Data successfully gathered to the rd dictionary\n",
    "        ########################################################\n",
    "\n",
    "        #//*** Build the dataframe\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        #//*** Create a column based on the values gathered in rd[column name]\n",
    "        for col in colnames:\n",
    "            df[col] = rd[col]\n",
    "\n",
    "        #//*** return the dataframe, column names, attribute dictionary\n",
    "        return df,colnames,attrib_dict\n",
    "\n",
    "#//*** END build_df_from_CA_API\n",
    "        \n",
    "####################################################################################################\n",
    "#//*** Build ethnic_df from the API\n",
    "#//*** This is broken out as a function to keep the code cleaner\n",
    "####################################################################################################\n",
    "\n",
    "ethnic_df = pd.DataFrame\n",
    "\n",
    "ethnic_url = g['api']['url']+g[\"api\"][\"ethnic\"][\"url\"]\n",
    "ethnic_df = build_df_from_CA_API(ethnic_url)[0]\n",
    "#ethnic_df, g['api']['ethnic']['colnames'], g['api']['ethnic']['attrib'] = buil_df_from_CA_API(ethnic_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _id race_ethnicity  cases  case_percentage  deaths  death_percentage  \\\n",
      "0    1         Latino   5276            35.99     170             28.38   \n",
      "1    2         Latino   5910            37.18     203             29.72   \n",
      "2    3         Latino   6433            37.80     226             29.70   \n",
      "3    4         Latino   7013            38.51     254             29.85   \n",
      "4    5         Latino   7627            39.41     281             30.58   \n",
      "5    6         Latino   8195            40.28     314             31.24   \n",
      "6    7         Latino   8397            40.37     326             31.38   \n",
      "7    8         Latino   9090            40.52     337             31.09   \n",
      "8    9         Latino   9701            41.03     364             31.11   \n",
      "9   10         Latino  10385            42.05     406             32.04   \n",
      "\n",
      "   percent_ca_population                 date  \n",
      "0                   38.9  2020-04-13T00:00:00  \n",
      "1                   38.9  2020-04-14T00:00:00  \n",
      "2                   38.9  2020-04-15T00:00:00  \n",
      "3                   38.9  2020-04-16T00:00:00  \n",
      "4                   38.9  2020-04-17T00:00:00  \n",
      "5                   38.9  2020-04-18T00:00:00  \n",
      "6                   38.9  2020-04-19T00:00:00  \n",
      "7                   38.9  2020-04-20T00:00:00  \n",
      "8                   38.9  2020-04-21T00:00:00  \n",
      "9                   38.9  2020-04-22T00:00:00  \n"
     ]
    }
   ],
   "source": [
    "#//*** Process Flat File: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
