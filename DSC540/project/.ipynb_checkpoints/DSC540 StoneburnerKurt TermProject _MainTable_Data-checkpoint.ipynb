{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "output_width = 1000\n",
    "#output_width = 80 #//*** Normal Output width\n",
    "\n",
    "#//*** Normal Output width\n",
    "pd.set_option(\"display.width\", output_width)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "#pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work with the Data for Term Project\n",
    "\n",
    "Data is downloaded using DSC540 StoneburnerKurt TermProject _ Load_PreProcess_Data\n",
    "which I supposed should be added as an external library if this was a production project.\n",
    "\n",
    "Coded is separated to keep the project more manageable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*************************************\n",
    "#//*** Import stored/preprocessed data\n",
    "#//*************************************\n",
    "\n",
    "#//*** Columns to remove from imported CSVs. We should be able to kill these on import if we were cool.\n",
    "#//*** But we're not, so we'll use an expedient column delete list.\n",
    "\n",
    "del_cols = ['Unnamed: 0', '_id']\n",
    "#//*** Load datframes from file, because we mess them up\n",
    "covid_ethnic_df = pd.read_csv(\"z_covid_ethnic_df.csv\")\n",
    "covid_cases_df = pd.read_csv(\"z_covid_cases_df.csv\")\n",
    "pop_attrib_df = pd.read_csv(\"z_pop_attrib_df.csv\")\n",
    "covid_project_df = pd.read_csv(\"z_covid_project_df.csv\")\n",
    "\n",
    "#//***********************************************************************************\n",
    "#//*** Remove excess columns from read_csv\n",
    "#//*** Use the loop in case we need to delete columns that are not exclusive to all\n",
    "#//***********************************************************************************\n",
    "for x in del_cols:\n",
    "    if x in covid_cases_df.columns:\n",
    "        covid_cases_df.drop([x], axis=1, inplace=True)\n",
    "\n",
    "    if x in covid_ethnic_df.columns:\n",
    "        covid_ethnic_df.drop([x], axis=1, inplace=True)\n",
    "    \n",
    "    if x in pop_attrib_df.columns:\n",
    "        pop_attrib_df.drop([x], axis=1, inplace=True)\n",
    "    \n",
    "    if x in covid_project_df.columns:\n",
    "        covid_project_df.drop([x], axis=1, inplace=True)\n",
    "        \n",
    "#print(covid_cases_df.head())\n",
    "#print(covid_ethnic_df.head())\n",
    "#print(pop_attrib_df.head())\n",
    "#print(covid_project_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Combine Pacific Islander and Hawaiian values into one.\n",
    "#//*** Hawaiian isn't a good choice of variable name. It's kind of racist and definitely non-inclusive.\n",
    "#//*** But I need this to work, before I can reconsider a different variable name\n",
    "\n",
    "covid_ethnic_df['race_ethnicity']=covid_ethnic_df['race_ethnicity'].str.replace('Native Hawaiian or Pacific Islander','Hawaiian')\n",
    "covid_ethnic_df['race_ethnicity']=covid_ethnic_df['race_ethnicity'].str.replace('Native Hawaiian and other Pacific Islander','Hawaiian')\n",
    "covid_ethnic_df['race_ethnicity']=covid_ethnic_df['race_ethnicity'].str.replace('Multi-Race','Multiracial' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(pop_attrib_df)\n",
    "\n",
    "HTML(pop_attrib_df.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//*** Sort Time Series by date and reset index\n",
    "covid_cases_df = covid_cases_df.sort_values(by='date')\n",
    "covid_ethnic_df = covid_ethnic_df.sort_values(by='date')\n",
    "\n",
    "#//*** Reset the index\n",
    "#covid_ethnic_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#//*** Get first Ethnic_df date\n",
    "ethnic_start_date = covid_ethnic_df['date'].iloc[0]\n",
    "print(f\"Ethinic State: {ethnic_start_date}\")\n",
    "\n",
    "#//*************************************************************************************************\n",
    "#//*** Get the iloc (index #) of the first covid_case_df entry to match the date in covid_ethic_df\n",
    "#//*** Compound code\n",
    "#//*** 1. Get the entries where the date matches ethnic start date\n",
    "#//*** 2. Get the first value from the list\n",
    "#//*** 3. Get the Index (name) of that entry\n",
    "#//*** 4. Get the iloc value of the name entry. This is the value to slice from covid_cases_df\n",
    "#//*************************************************************************************************\n",
    "#//*** I hate these, but I see the appeal\n",
    "#//*************************************************************************************************\n",
    "covid_start_iloc = covid_cases_df.index.get_loc(covid_cases_df[ covid_cases_df['date'] == ethnic_start_date].iloc[0].name)\n",
    "\n",
    "#print(covid_cases_df.iloc[covid_start_iloc])\n",
    "#//*** Merge Time Series covid_ethnic_df - covid_cases_df\n",
    "covid_cases_df = covid_cases_df.iloc[covid_start_iloc:]\n",
    "\n",
    "#//*** Start the Bg Table DF with a subset of\n",
    "#bt_df = covid_ethnic_df\n",
    "#print\n",
    "#print(covid_ethnic_df.head())\n",
    "#print(bt_df.head())\n",
    "    \n",
    "    \n",
    "bt_df = pd.merge(covid_ethnic_df,covid_cases_df,how='left', on='date')\n",
    "\n",
    "bt_df = pd.merge(bt_df,pop_attrib_df,how='left', on='county')\n",
    "\n",
    "print(len(bt_df))\n",
    "\n",
    "for group in bt_df.groupby('date'):\n",
    "    print(group[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_df = bt_df.set_index([bt_df['date'],bt_df['county']])\n",
    "\n",
    "#print(hier_df)\n",
    "\n",
    "#HTML(hier_df.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Let's run some correllations for funsies\n",
    "pop_cols = ['population', 'Latino','White','Asian','Black','American Indian or Alaska Native', 'Hawaiian', 'Other' ]\n",
    "rf_cols = ['0rf_num', '1-2rf_num',  '3plrf_num']\n",
    "rf_cols = ['0rf_rate', '1-2rf_rate',  '3plrf_rate']\n",
    "\n",
    "for x in pop_cols:\n",
    "    for y in rf_cols:\n",
    "        print(f\"{x} {y} - {pop_attrib_df[ [x,y] ].corr().iloc[0].iloc[1] }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
