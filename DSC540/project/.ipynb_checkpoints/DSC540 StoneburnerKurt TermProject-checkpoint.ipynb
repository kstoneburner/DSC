{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSC540 Term Project\n",
    "Kurt Stoneburner\n",
    "\n",
    "California COVID019 Ethnicity Data\n",
    "https://data.ca.gov/dataset/covid-19-cases/resource/7e477adb-d7ab-4d4b-a198-dc4c6dc634c9\n",
    "\n",
    "API Example: https://data.ca.gov/api/3/action/datastore_search?resource_id=7e477adb-d7ab-4d4b-a198-dc4c6dc634c9&limit=5\n",
    "\n",
    "Requests Documentation: https://www.w3schools.com/python/ref_requests_response.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build Dictionary to hold Global values.\n",
    "#//*** Placing Globals in a dictionary, keeps things tidy and helps with scope.\n",
    "g = {\n",
    "    #//*** Values for the API call\n",
    "    \"api\" : {\n",
    "        \"url\" : \"https://data.ca.gov\",\n",
    "        \"ethnic\" : {\n",
    "            \"url\" : \"/api/3/action/datastore_search?resource_id=7e477adb-d7ab-4d4b-a198-dc4c6dc634c9\",\n",
    "            \"colnames\" : [], #//*** Column names\n",
    "            #//*** Additional Column name attributes. Probably not needed. But ingesting anyway.\n",
    "            #//*** Key - colname, value is attributes\n",
    "            \"attrib\" : {}, \n",
    "        } #//*** CLOSE api.ethnic\n",
    "        \n",
    "    } #//*** CLOSE api\n",
    "\n",
    "} #//***CLOSE g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Get the whole database 100 records at a time.\n",
    "#//*** This request gets the first 100 records. Future calls are handled in a loop\n",
    "#response = requests.get(g['api']['url']+g[\"api\"][\"ethnic\"][\"url\"])\n",
    "\n",
    "#print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 32\n",
      "Quitting Loop\n"
     ]
    }
   ],
   "source": [
    "#//*** Build a data frame returning all values from a California Data Source API\n",
    "def build_df_from_CA_API(url):\n",
    "    \n",
    "    #//*** Build the attributes for the API. This includes column names and column attributes which includes column\n",
    "    #//*** Type and other details\n",
    "\n",
    "    #//*** Request the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    #//*** Check for valid response\n",
    "    if response.ok == False:\n",
    "        #//*** Trouble with API, so some error handling here.\n",
    "        print(\"Trouble fetching API data\")\n",
    "        print(response)\n",
    "    else:\n",
    "        #//*** Valid Response\n",
    "        #//*** Convert response.content to a dictionary using JSON\n",
    "        rawOBJ=json.loads(response.content)\n",
    "        \n",
    "        #//*** Peek at the results\n",
    "        #print(rawOBJ[\"result\"].keys())\n",
    "        #for key, value in rawOBJ.ites():\n",
    "        #    print(f\"{key} : {value}\")\n",
    "        \n",
    "        #//*** Initialize list of column names\n",
    "        colnames = []\n",
    "        \n",
    "        #//*** Attrib_dict contains the attributes of each column\n",
    "        #//*** key = Column name\n",
    "        #//*** value = dictionary of attributes\n",
    "        attrib_dict = {}\n",
    "        \n",
    "        #//*** Parse the [results][fields] key for data\n",
    "        rawFields = rawOBJ[\"result\"]['fields']\n",
    "        \n",
    "        #//*** Loop through the rawfields dictionary.\n",
    "        #//*** each LoopOBJ contains a column name and column attributes\n",
    "        for loopOBJ in rawFields:\n",
    "            \n",
    "            #//*** Build temporary attributes for each loop instance\n",
    "            loopAttrib = {}\n",
    "\n",
    "            #//*** All Columns have an info field except _id.\n",
    "            if 'info' in loopOBJ.keys():\n",
    "                loopAttrib = loopOBJ[\"info\"]\n",
    "\n",
    "            #//*** Add Type to loopAttrib\n",
    "            loopAttrib['type'] = loopOBJ['type']\n",
    "\n",
    "            #//*** The column name is the ID field. Append the id field to the colnames list\n",
    "            colnames.append(loopOBJ['id'])\n",
    "\n",
    "            #//*** Assign the attributes dictionary based on column name\n",
    "            attrib_dict[ loopOBJ['id'] ] = loopAttrib\n",
    "        \n",
    "        \"\"\"\n",
    "        #//*** Display column names and attributes\n",
    "        print(f\"Column Names: {colnames}\")\n",
    "        \n",
    "        print(\"Attrib_dict\")\n",
    "        for x in colnames:\n",
    "            print(attrib_dict[x])\n",
    "        \"\"\"\n",
    "        \n",
    "        #//*************************************\n",
    "        #//*** Process the row an column data \n",
    "        #//*************************************\n",
    "\n",
    "        #//*** Build dictionary to hold raw data (rd)\n",
    "        rd = {}\n",
    "\n",
    "        #//*** Use each column as a key, create and empty list for each column\n",
    "        for x in colnames:\n",
    "            rd[x] = []\n",
    "\n",
    "        #//################################################################################################\n",
    "        #//*** While rawOBJ['success'] is true. Which implies we've successfully retrieved and API request\n",
    "        #//*** And is our loop mechanism to keep requesting records in 100 record incremenets.\n",
    "        #//################################################################################################\n",
    "        while rawOBJ[\"success\"]:\n",
    "\n",
    "            #//*** Get Records as a List for each entry\n",
    "            rawRecords = rawOBJ['result'][\"records\"]\n",
    "\n",
    "            #//*** Print a visual note for each loop iteraction / API call\n",
    "            print(f\"Processing {len(rawRecords)}\")\n",
    "\n",
    "            #//*** Parse Each Record.\n",
    "            for record in rawRecords:\n",
    "                #//*** Each Record is an object.\n",
    "                #//*** Each key is a column name.\n",
    "                #//*** Loop through the Column names and append the value to the column stored in rd\n",
    "\n",
    "                #//*** This is the sauce to that converts the object values into lists based on columns\n",
    "                #//*** It's kind of cool that the sausage is essentially made with two lines of code\n",
    "                #//*** The rest is just setup and control code.\n",
    "                for col in colnames:\n",
    "                    #//*** Assign each element to the appropriate column\n",
    "                    rd[col].append(record[col])\n",
    "\n",
    "            #//################################\n",
    "            #//*** Check if loop needs to end.\n",
    "            #//################################\n",
    "            #//*** If the number of records returned is less than the limit, we are done\n",
    "            if len(rawOBJ['result']['records']) < rawOBJ['result']['limit']:\n",
    "                print(\"Quitting Loop\")\n",
    "                break\n",
    "\n",
    "            #//*** Check if there are more records to grab\n",
    "            #//*** next contains the URL of the next request\n",
    "            #//*** The API is limited to 100 records per API request.\n",
    "            if 'next' in rawOBJ['result']['_links'].keys():\n",
    "                ##//***API CODE HERE\n",
    "                nextCall = rawOBJ['result']['_links']['next']\n",
    "\n",
    "                #//*** Add the Next value to the base API call\n",
    "                response = requests.get(g['api']['url']+nextCall)\n",
    "                rawOBJ=json.loads(response.content)\n",
    "                if rawOBJ[\"success\"] == False:\n",
    "                    #//*** Break if Success returns False\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                #//*** Quit Here\n",
    "                break\n",
    "        ########################################################\n",
    "        #//*** END while rawOBJ['success'] == True\n",
    "        #//*** Data successfully gathered to the rd dictionary\n",
    "        ########################################################\n",
    "\n",
    "        #//*** Build the dataframe\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        #//*** Create a column based on the values gathered in rd[column name]\n",
    "        for col in colnames:\n",
    "            df[col] = rd[col]\n",
    "\n",
    "        #//*** return the dataframe, column names, attribute dictionary\n",
    "        return df,colnames,attrib_dict\n",
    "\n",
    "#//*** END build_df_from_CA_API\n",
    "        \n",
    "####################################################################################################\n",
    "#//*** Build ethnic_df from the API\n",
    "#//*** This is broken out as a function to keep the code cleaner\n",
    "####################################################################################################\n",
    "\n",
    "covid_ethnic_df = pd.DataFrame\n",
    "\n",
    "ethnic_url = g['api']['url']+g[\"api\"][\"ethnic\"][\"url\"]\n",
    "covid_ethnic_df = build_df_from_CA_API(ethnic_url)[0]\n",
    "#covid_ethnic_df, g['api']['ethnic']['colnames'], g['api']['ethnic']['attrib'] = buil_df_from_CA_API(ethnic_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'race_ethnicity', 'cases', 'case_percentage', 'deaths',\n",
      "       'death_percentage', 'percent_ca_population', 'date'],\n",
      "      dtype='object')\n",
      "['Latino' 'White' 'Asian' 'Black' 'Multiracial'\n",
      " 'American Indian or Alaska Native' 'Native Hawaiian or Pacific Islander'\n",
      " 'Other' 'Multi-Race' 'Native Hawaiian and other Pacific Islander']\n"
     ]
    }
   ],
   "source": [
    "print(ethnic_df.columns)\n",
    "print(ethnic_df['race_ethnicity'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Male: 823247\n",
      "['WA_MALE', 'BA_MALE', 'IA_MALE', 'AA_MALE', 'NA_MALE', 'TOM_MALE', 'NH_MALE', 'NHWA_MALE', 'NHBA_MALE', 'NHIA_MALE', 'NHAA_MALE', 'NHNA_MALE', 'NHTOM_MALE', 'H_MALE', 'HWA_MALE', 'HBA_MALE', 'HIA_MALE', 'HAA_MALE', 'HNA_MALE', 'HTOM_MALE']\n",
      "SUMLEV                     50\n",
      "STATE                       6\n",
      "COUNTY                      1\n",
      "STNAME             California\n",
      "CTYNAME        Alameda County\n",
      "                    ...      \n",
      "HIAC_FEMALE             12008\n",
      "HAAC_MALE                9100\n",
      "HAAC_FEMALE              9346\n",
      "HNAC_MALE                2296\n",
      "HNAC_FEMALE              2392\n",
      "Name: 209, Length: 80, dtype: object\n",
      " WA_MALE : 414416\n",
      " BA_MALE : 88167\n",
      " IA_MALE : 9048\n",
      " AA_MALE : 259991\n",
      " NA_MALE : 7534\n",
      " TOM_MALE : 44091\n",
      " NH_MALE : 634636\n",
      " NHWA_MALE : 256400\n",
      " NHBA_MALE : 81150\n",
      " NHIA_MALE : 1957\n",
      " NHAA_MALE : 254719\n",
      " NHNA_MALE : 6423\n",
      " NHTOM_MALE : 33987\n",
      " H_MALE : 188611\n",
      " HWA_MALE : 158016\n",
      " HBA_MALE : 7017\n",
      " HIA_MALE : 7091\n",
      " HAA_MALE : 5272\n",
      " HNA_MALE : 1111\n",
      " HTOM_MALE : 10104\n"
     ]
    }
   ],
   "source": [
    "#//*** Process Flat File: California Ethnicity demographics - cc-est2019-alldata-06.csv\n",
    "raw_ethnic_pop_df = pd.read_csv(\"cc-est2019-alldata-06.csv\")\n",
    "\n",
    "#//*** Data includes values for last twelve years. We only want data for the last year.\n",
    "\n",
    "#//*** Rebuild raw_ethnic_pop_df using only the last year (most recent) data\n",
    "raw_ethnic_pop_df = raw_ethnic_pop_df[raw_ethnic_pop_df['YEAR']==raw_ethnic_pop_df['YEAR'].max()]\n",
    "\n",
    "#//*** Ethnic data is broken down by age. At this stage we will only use the totals\n",
    "#//*** Buid\n",
    "\n",
    "thisRow = raw_ethnic_pop_df.iloc[0]\n",
    "\n",
    "totmale = thisRow['TOT_MALE']\n",
    "\n",
    "male_cols = []\n",
    "\n",
    "for col in thisRow.index:\n",
    "    if \"_MALE\" in col and not \"TOT_MALE\" in col and not \"AC_MALE\" in col:\n",
    "        male_cols.append(col)\n",
    "\n",
    "print(f\"Total Male: {totmale}\")\n",
    "print(f\"{male_cols}\")\n",
    "\n",
    "print(thisRow)\n",
    "\n",
    "#Total Hispanic - H_MALE, H_FEMALE \n",
    "\n",
    "for index in male_cols:\n",
    "    print(f\" {index} : {thisRow.loc[index]}\")\n",
    "#print(raw_ethnic_pop_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
