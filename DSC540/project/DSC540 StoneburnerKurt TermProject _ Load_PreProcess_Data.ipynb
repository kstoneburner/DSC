{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSC540 Term Project\n",
    "Kurt Stoneburner\n",
    "\n",
    "California COVID019 Ethnicity Data\n",
    "https://data.ca.gov/dataset/covid-19-cases/resource/7e477adb-d7ab-4d4b-a198-dc4c6dc634c9\n",
    "\n",
    "API Example: https://data.ca.gov/api/3/action/datastore_search?resource_id=7e477adb-d7ab-4d4b-a198-dc4c6dc634c9&limit=5\n",
    "\n",
    "Requests Documentation: https://www.w3schools.com/python/ref_requests_response.asp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import sqlite3\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build Dictionary to hold Global values.\n",
    "#//*** Placing Globals in a dictionary, keeps things tidy and helps with scope.\n",
    "g = {\n",
    "    #//*** Values for the API call\n",
    "    \"api\" : {\n",
    "        \"url\" : \"https://data.ca.gov\",\n",
    "        \"ethnic\" : {\n",
    "            \"url\" : \"/api/3/action/datastore_search?resource_id=7e477adb-d7ab-4d4b-a198-dc4c6dc634c9\",\n",
    "            \"colnames\" : [], #//*** Column names\n",
    "            #//*** Additional Column name attributes. Probably not needed. But ingesting anyway.\n",
    "            #//*** Key - colname, value is attributes\n",
    "            \"attrib\" : {}\n",
    "        },#//*** end Ethnic\n",
    "        \"cases\" : {\n",
    "            \"url\" : \"/api/3/action/datastore_search?resource_id=926fd08f-cc91-4828-af38-bd45de97f8c3\",\n",
    "            \"colnames\" : [], #//*** Column names\n",
    "            #//*** Additional Column name attributes. Probably not needed. But ingesting anyway.\n",
    "            #//*** Key - colname, value is attributes\n",
    "            \"attrib\" : {}, \n",
    "        }#//*** end Cases\n",
    "            \n",
    "        \n",
    "        \n",
    "    }, #//*** CLOSE api\n",
    "    \"weburl\" : \"https://covidtracking.com/data/state/california/cases\",\n",
    "\n",
    "} #//***CLOSE g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Get the whole database 100 records at a time.\n",
    "#//*** This request gets the first 100 records. Future calls are handled in a loop\n",
    "#response = requests.get(g['api']['url']+g[\"api\"][\"ethnic\"][\"url\"])\n",
    "\n",
    "#print(response)\n",
    "#print(cases_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build a data frame returning all values from a California Data Source API\n",
    "def build_df_from_CA_API(url):\n",
    "    \n",
    "    #//*** Build the attributes for the API. This includes column names and column attributes which includes column\n",
    "    #//*** Type and other details\n",
    "\n",
    "    #//*** Request the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    #//*** Check for valid response\n",
    "    if response.ok == False:\n",
    "        #//*** Trouble with API, so some error handling here.\n",
    "        print(\"Trouble fetching API data\")\n",
    "        print(response)\n",
    "    else:\n",
    "        #//*** Valid Response\n",
    "        #//*** Convert response.content to a dictionary using JSON\n",
    "        rawOBJ=json.loads(response.content)\n",
    "        \n",
    "        #//*** Peek at the results\n",
    "        #print(rawOBJ[\"result\"].keys())\n",
    "        #for key, value in rawOBJ.ites():\n",
    "        #    print(f\"{key} : {value}\")\n",
    "        \n",
    "        #//*** Initialize list of column names\n",
    "        colnames = []\n",
    "        \n",
    "        #//*** Attrib_dict contains the attributes of each column\n",
    "        #//*** key = Column name\n",
    "        #//*** value = dictionary of attributes\n",
    "        attrib_dict = {}\n",
    "        \n",
    "        #//*** Parse the [results][fields] key for data\n",
    "        rawFields = rawOBJ[\"result\"]['fields']\n",
    "        \n",
    "        #//*** Loop through the rawfields dictionary.\n",
    "        #//*** each LoopOBJ contains a column name and column attributes\n",
    "        for loopOBJ in rawFields:\n",
    "            \n",
    "            #//*** Build temporary attributes for each loop instance\n",
    "            loopAttrib = {}\n",
    "\n",
    "            #//*** All Columns have an info field except _id.\n",
    "            if 'info' in loopOBJ.keys():\n",
    "                loopAttrib = loopOBJ[\"info\"]\n",
    "\n",
    "            #//*** Add Type to loopAttrib\n",
    "            loopAttrib['type'] = loopOBJ['type']\n",
    "\n",
    "            #//*** The column name is the ID field. Append the id field to the colnames list\n",
    "            colnames.append(loopOBJ['id'])\n",
    "\n",
    "            #//*** Assign the attributes dictionary based on column name\n",
    "            attrib_dict[ loopOBJ['id'] ] = loopAttrib\n",
    "        \n",
    "        \"\"\"\n",
    "        #//*** Display column names and attributes\n",
    "        print(f\"Column Names: {colnames}\")\n",
    "        \n",
    "        print(\"Attrib_dict\")\n",
    "        for x in colnames:\n",
    "            print(attrib_dict[x])\n",
    "        \"\"\"\n",
    "        \n",
    "        #//*************************************\n",
    "        #//*** Process the row an column data \n",
    "        #//*************************************\n",
    "\n",
    "        #//*** Build dictionary to hold raw data (rd)\n",
    "        rd = {}\n",
    "\n",
    "        #//*** Use each column as a key, create and empty list for each column\n",
    "        for x in colnames:\n",
    "            rd[x] = []\n",
    "\n",
    "        #//################################################################################################\n",
    "        #//*** While rawOBJ['success'] is true. Which implies we've successfully retrieved and API request\n",
    "        #//*** And is our loop mechanism to keep requesting records in 100 record incremenets.\n",
    "        #//################################################################################################\n",
    "        while rawOBJ[\"success\"]:\n",
    "\n",
    "            #//*** Get Records as a List for each entry\n",
    "            rawRecords = rawOBJ['result'][\"records\"]\n",
    "\n",
    "            #//*** Print a visual note for each loop iteraction / API call\n",
    "            print(f\"Processing {len(rawRecords)}\")\n",
    "\n",
    "            #//*** Parse Each Record.\n",
    "            for record in rawRecords:\n",
    "                #//*** Each Record is an object.\n",
    "                #//*** Each key is a column name.\n",
    "                #//*** Loop through the Column names and append the value to the column stored in rd\n",
    "\n",
    "                #//*** This is the sauce to that converts the object values into lists based on columns\n",
    "                #//*** It's kind of cool that the sausage is essentially made with two lines of code\n",
    "                #//*** The rest is just setup and control code.\n",
    "                for col in colnames:\n",
    "                    #//*** Assign each element to the appropriate column\n",
    "                    rd[col].append(record[col])\n",
    "\n",
    "            #//################################\n",
    "            #//*** Check if loop needs to end.\n",
    "            #//################################\n",
    "            #//*** If the number of records returned is less than the limit, we are done\n",
    "            if len(rawOBJ['result']['records']) < rawOBJ['result']['limit']:\n",
    "                print(\"Quitting Loop\")\n",
    "                break\n",
    "\n",
    "            #//*** Check if there are more records to grab\n",
    "            #//*** next contains the URL of the next request\n",
    "            #//*** The API is limited to 100 records per API request.\n",
    "            if 'next' in rawOBJ['result']['_links'].keys():\n",
    "                ##//***API CODE HERE\n",
    "                nextCall = rawOBJ['result']['_links']['next']\n",
    "\n",
    "                #//*** Add the Next value to the base API call\n",
    "                response = requests.get(g['api']['url']+nextCall)\n",
    "                rawOBJ=json.loads(response.content)\n",
    "                if rawOBJ[\"success\"] == False:\n",
    "                    #//*** Break if Success returns False\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                #//*** Quit Here\n",
    "                break\n",
    "        ########################################################\n",
    "        #//*** END while rawOBJ['success'] == True\n",
    "        #//*** Data successfully gathered to the rd dictionary\n",
    "        ########################################################\n",
    "\n",
    "        #//*** Build the dataframe\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        #//*** Create a column based on the values gathered in rd[column name]\n",
    "        for col in colnames:\n",
    "            df[col] = rd[col]\n",
    "\n",
    "        #//*** return the dataframe, column names, attribute dictionary\n",
    "        return df,colnames,attrib_dict\n",
    "\n",
    "#//*** END build_df_from_CA_API\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 64\n",
      "Quitting Loop\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "#//*** Build ethnic_df from the API\n",
    "#//*** This is broken out as a function to keep the code cleaner\n",
    "####################################################################################################\n",
    "\n",
    "covid_ethnic_df = pd.DataFrame\n",
    "\n",
    "ethnic_url = g['api']['url']+g[\"api\"][\"ethnic\"][\"url\"]\n",
    "covid_ethnic_df = build_df_from_CA_API(ethnic_url)[0]\n",
    "#covid_ethnic_df, g['api']['ethnic']['colnames'], g['api']['ethnic']['attrib'] = buil_df_from_CA_API(ethnic_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 100\n",
      "Processing 85\n",
      "Quitting Loop\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################\n",
    "#//*** Build the covid_cases_df from the API. These are the county COVID numbers by date\n",
    "#//*** This is broken out as a function to keep the code cleaner\n",
    "####################################################################################################\n",
    "cases_url = g['api']['url']+g[\"api\"][\"cases\"][\"url\"]\n",
    "covid_cases_df = build_df_from_CA_API(cases_url)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>county</th>\n",
       "      <th>totalcountconfirmed</th>\n",
       "      <th>totalcountdeaths</th>\n",
       "      <th>newcountconfirmed</th>\n",
       "      <th>newcountdeaths</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>151</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-03-18T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>183.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-03-19T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>246.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-20T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>269.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-03-21T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>284.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-22T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>336.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-23T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>389.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-03-24T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>452.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-25T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>487.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-26T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>557.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-03-27T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>587.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-03-28T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>591.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-03-29T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>745.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-30T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>777.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>32</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-03-31T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>805.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-04-01T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>908.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>103</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-04-02T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>983.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-03T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-04-04T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>1052.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-04-05T00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-04-06T00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _id       county  totalcountconfirmed  totalcountdeaths  \\\n",
       "0     1  Santa Clara                151.0               6.0   \n",
       "1     2  Santa Clara                183.0               8.0   \n",
       "2     3  Santa Clara                246.0               8.0   \n",
       "3     4  Santa Clara                269.0              10.0   \n",
       "4     5  Santa Clara                284.0              13.0   \n",
       "5     6  Santa Clara                336.0              13.0   \n",
       "6     7  Santa Clara                389.0              17.0   \n",
       "7     8  Santa Clara                452.0              20.0   \n",
       "8     9  Santa Clara                487.0              20.0   \n",
       "9    10  Santa Clara                557.0              25.0   \n",
       "10   11  Santa Clara                587.0              27.0   \n",
       "11   12  Santa Clara                591.0              30.0   \n",
       "12   13  Santa Clara                745.0              31.0   \n",
       "13   14  Santa Clara                777.0              30.0   \n",
       "14   15  Santa Clara                805.0              33.0   \n",
       "15   16  Santa Clara                908.0              38.0   \n",
       "16   17  Santa Clara                983.0              39.0   \n",
       "17   18  Santa Clara               1045.0              39.0   \n",
       "18   19  Santa Clara               1052.0              42.0   \n",
       "19   20  Santa Clara               1128.0              43.0   \n",
       "\n",
       "    newcountconfirmed  newcountdeaths                 date  \n",
       "0                 151               6  2020-03-18T00:00:00  \n",
       "1                  32               2  2020-03-19T00:00:00  \n",
       "2                  63               0  2020-03-20T00:00:00  \n",
       "3                  23               2  2020-03-21T00:00:00  \n",
       "4                  15               3  2020-03-22T00:00:00  \n",
       "5                  52               0  2020-03-23T00:00:00  \n",
       "6                  53               4  2020-03-24T00:00:00  \n",
       "7                  63               3  2020-03-25T00:00:00  \n",
       "8                  35               0  2020-03-26T00:00:00  \n",
       "9                  70               5  2020-03-27T00:00:00  \n",
       "10                 30               2  2020-03-28T00:00:00  \n",
       "11                  4               3  2020-03-29T00:00:00  \n",
       "12                154               1  2020-03-30T00:00:00  \n",
       "13                 32              -1  2020-03-31T00:00:00  \n",
       "14                 28               3  2020-04-01T00:00:00  \n",
       "15                103               5  2020-04-02T00:00:00  \n",
       "16                 75               1  2020-04-03T00:00:00  \n",
       "17                 62               0  2020-04-04T00:00:00  \n",
       "18                  7               3  2020-04-05T00:00:00  \n",
       "19                 76               1  2020-04-06T00:00:00  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covid_cases_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'race_ethnicity', 'cases', 'case_percentage', 'deaths',\n",
      "       'death_percentage', 'percent_ca_population', 'date'],\n",
      "      dtype='object')\n",
      "['Latino' 'White' 'Asian' 'Black' 'Multiracial'\n",
      " 'American Indian or Alaska Native' 'Other'\n",
      " 'Native Hawaiian or Pacific Islander' 'Multi-Race'\n",
      " 'Native Hawaiian and other Pacific Islander']\n",
      "[   1    2    3 ... 2462 2463 2464]\n",
      "   _id race_ethnicity  cases  case_percentage  deaths  death_percentage  \\\n",
      "0    1         Latino   5276            35.99     170             28.38   \n",
      "1    2         Latino   5910            37.18     203             29.72   \n",
      "2    3         Latino   6433            37.80     226             29.70   \n",
      "3    4         Latino   7013            38.51     254             29.85   \n",
      "4    5         Latino   7627            39.41     281             30.58   \n",
      "5    6         Latino   8195            40.28     314             31.24   \n",
      "6    7         Latino   8397            40.37     326             31.38   \n",
      "7    8         Latino   9090            40.52     337             31.09   \n",
      "8    9         Latino   9701            41.03     364             31.11   \n",
      "9   10         Latino  10385            42.05     406             32.04   \n",
      "\n",
      "   percent_ca_population                 date  \n",
      "0                   38.9  2020-04-13T00:00:00  \n",
      "1                   38.9  2020-04-14T00:00:00  \n",
      "2                   38.9  2020-04-15T00:00:00  \n",
      "3                   38.9  2020-04-16T00:00:00  \n",
      "4                   38.9  2020-04-17T00:00:00  \n",
      "5                   38.9  2020-04-18T00:00:00  \n",
      "6                   38.9  2020-04-19T00:00:00  \n",
      "7                   38.9  2020-04-20T00:00:00  \n",
      "8                   38.9  2020-04-21T00:00:00  \n",
      "9                   38.9  2020-04-22T00:00:00  \n"
     ]
    }
   ],
   "source": [
    "print(covid_ethnic_df.columns)\n",
    "print(covid_ethnic_df['race_ethnicity'].unique())\n",
    "print(covid_ethnic_df['_id'].unique())\n",
    "print(covid_ethnic_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2\n",
      "2.2\n",
      "0.0\n",
      "23\n",
      "       _id race_ethnicity   cases  case_percentage  deaths  death_percentage  \\\n",
      "2431  2432          Other  306608             11.9     918               2.1   \n",
      "2439  2440          Other  306842             11.8     962               2.2   \n",
      "2447  2448          Other  307134             11.8     973               2.2   \n",
      "2455  2456          Other  307185             11.8     997               2.2   \n",
      "2463  2464          Other  307163             11.7    1007               2.2   \n",
      "\n",
      "      percent_ca_population                 date  \n",
      "2431                    0.0  2021-02-10T00:00:00  \n",
      "2439                    0.0  2021-02-11T00:00:00  \n",
      "2447                    0.0  2021-02-12T00:00:00  \n",
      "2455                    0.0  2021-02-13T00:00:00  \n",
      "2463                    0.0  2021-02-14T00:00:00  \n"
     ]
    }
   ],
   "source": [
    "print(covid_ethnic_df[covid_ethnic_df['race_ethnicity'] == 'Multi-Race'].iloc[0]['percent_ca_population'])\n",
    "print(covid_ethnic_df[covid_ethnic_df['race_ethnicity'] == 'Multiracial'].iloc[0]['percent_ca_population'])\n",
    "print(covid_ethnic_df[covid_ethnic_df['race_ethnicity'] == 'Other'].iloc[0]['percent_ca_population'])\n",
    "print(covid_ethnic_df[covid_ethnic_df['race_ethnicity'] == 'Other'].iloc[0]['deaths'])\n",
    "print(covid_ethnic_df[covid_ethnic_df['race_ethnicity'] == 'Other'].tail(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Process Website using Beautiful Soup\n",
    "response = requests.get(g['weburl'])\n",
    "\n",
    "if response.ok == True:\n",
    "    #//*** Make soup...Beautiful Soup\n",
    "    soup = BeautifulSoup(response.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Date', 'confirmed', 'New cases', 'Confirmed cases', 'Probable Cases']\n",
      "['Date', 'confirmed', 'New cases']\n",
      "dict_keys(['Date', 'confirmed', 'New cases', 'Confirmed cases', 'Probable Cases'])\n",
      "        date confirmed confirmed_new\n",
      "0 2021-02-15   3406365          6487\n",
      "1 2021-02-14   3399878          8842\n",
      "2 2021-02-13   3391036          9421\n",
      "3 2021-02-12   3381615         10059\n",
      "4 2021-02-11   3371556          8575\n"
     ]
    }
   ],
   "source": [
    "table = soup.find('table')\n",
    "\n",
    "#//*** Get the Table Headers. These will be our data frame Columns.\n",
    "ths = table.find_all(\"th\")\n",
    "\n",
    "#//*** initialize a list to hold the column names\n",
    "colnames = []\n",
    "\n",
    "#//*** Columnnames are the first value contained in contents\n",
    "for th in ths:\n",
    "    if th.contents[0] == 'Cases (confirmed plus probable)':\n",
    "        colnames.append('confirmed')    \n",
    "    else: \n",
    "        colnames.append(th.contents[0])\n",
    "\n",
    "print(colnames)\n",
    "\n",
    "#//**********************************\n",
    "#//*** Initialize tableDict.\n",
    "#//**********************************\n",
    "#//*** tableDict is a dictionary container to hold row data.\n",
    "#//*** The tableDict will hold each of the row lists. The keys will be each colname\n",
    "tableDict = {}\n",
    "\n",
    "#//*** Initialize tableDict\n",
    "for name in colnames:\n",
    "    tableDict[name] = []\n",
    "\n",
    "#//***********************************************\n",
    "#//*** Process each tablerow\n",
    "#//*** The sausage is primarily made here\n",
    "#//***********************************************\n",
    "\n",
    "#//*** Get a BS list of table rows \n",
    "trs = table.find_all(\"tr\")\n",
    "\n",
    "#//*** For each table row in tablerows\n",
    "for tr in trs:\n",
    "    #//*** Skip the table header\n",
    "    if len(tr.find_all(\"th\")) == 0:\n",
    "        #//*** Loop through the colnames Index\n",
    "        #//*** The gets the key value to store the TD data\n",
    "        #//*** Get a TD with a corresponding index value and extract the text\n",
    "        for x in range(0,len(colnames)):\n",
    "            #//*** Append the text to the appropriate colname list.\n",
    "            #//*** Using index values keeps everthing aligned.\n",
    "            #print(tr.find_all('td')[x].find_all('span')[1].contents)\n",
    "            tableDict[colnames[x]].append(tr.find_all('td')[x].find_all('span')[1].contents[0])\n",
    "\n",
    "#print(tableDict)\n",
    "\n",
    "#//*** Remove the Probable Cases Column. These are all N/A\n",
    "colnames.remove('Probable Cases')\n",
    "colnames.remove('Confirmed cases')\n",
    "print(colnames)\n",
    "\n",
    "#//*** Build the initial dataframe\n",
    "covid_project_df = pd.DataFrame()\n",
    "\n",
    "#//*** Convert the Date Object to a datetime object\n",
    "tableDict['Date'] = [datetime.datetime.strptime(tableDict['Date'][x],'%B %d, %Y') for x in range(0,len(tableDict['Date'])) ]\n",
    "print(tableDict.keys())\n",
    "for x in range(0,len(tableDict['confirmed'])):\n",
    "    tableDict['confirmed'][x] = tableDict['confirmed'][x].replace(\",\",\"\")\n",
    "    tableDict['New cases'][x] = tableDict['New cases'][x].replace(\",\",\"\")\n",
    "\n",
    "#//*** Loop through each column name in colnames.\n",
    "#//*** Each col is a key in tableDict. Add each key / list to the dataframe\n",
    "for col in colnames:\n",
    "    if col in ['confirmed','New cases']:\n",
    "        covid_project_df[col] = pd.Series(tableDict[col])\n",
    "    else:\n",
    "        covid_project_df[col] = pd.Series(tableDict[col])\n",
    "\n",
    "covid_project_df.rename(columns = {\"New cases\":\"confirmed_new\",\"Date\" : \"date\"},inplace=True)\n",
    "print(covid_project_df.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUMLEV</th>\n",
       "      <th>STATE</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>STNAME</th>\n",
       "      <th>CTYNAME</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>AGEGRP</th>\n",
       "      <th>TOT_POP</th>\n",
       "      <th>TOT_MALE</th>\n",
       "      <th>TOT_FEMALE</th>\n",
       "      <th>...</th>\n",
       "      <th>HWAC_MALE</th>\n",
       "      <th>HWAC_FEMALE</th>\n",
       "      <th>HBAC_MALE</th>\n",
       "      <th>HBAC_FEMALE</th>\n",
       "      <th>HIAC_MALE</th>\n",
       "      <th>HIAC_FEMALE</th>\n",
       "      <th>HAAC_MALE</th>\n",
       "      <th>HAAC_FEMALE</th>\n",
       "      <th>HNAC_MALE</th>\n",
       "      <th>HNAC_FEMALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>California</td>\n",
       "      <td>Alameda County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1671329</td>\n",
       "      <td>823247</td>\n",
       "      <td>848082</td>\n",
       "      <td>...</td>\n",
       "      <td>166972</td>\n",
       "      <td>162697</td>\n",
       "      <td>10421</td>\n",
       "      <td>10961</td>\n",
       "      <td>12411</td>\n",
       "      <td>12008</td>\n",
       "      <td>9100</td>\n",
       "      <td>9346</td>\n",
       "      <td>2296</td>\n",
       "      <td>2392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>California</td>\n",
       "      <td>Alpine County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1129</td>\n",
       "      <td>609</td>\n",
       "      <td>520</td>\n",
       "      <td>...</td>\n",
       "      <td>50</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>California</td>\n",
       "      <td>Amador County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>39752</td>\n",
       "      <td>21638</td>\n",
       "      <td>18114</td>\n",
       "      <td>...</td>\n",
       "      <td>3275</td>\n",
       "      <td>1939</td>\n",
       "      <td>101</td>\n",
       "      <td>49</td>\n",
       "      <td>318</td>\n",
       "      <td>225</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "      <td>35</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>California</td>\n",
       "      <td>Butte County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>219186</td>\n",
       "      <td>108473</td>\n",
       "      <td>110713</td>\n",
       "      <td>...</td>\n",
       "      <td>17400</td>\n",
       "      <td>16812</td>\n",
       "      <td>502</td>\n",
       "      <td>554</td>\n",
       "      <td>1702</td>\n",
       "      <td>1780</td>\n",
       "      <td>406</td>\n",
       "      <td>399</td>\n",
       "      <td>167</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>California</td>\n",
       "      <td>Calaveras County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>45905</td>\n",
       "      <td>22847</td>\n",
       "      <td>23058</td>\n",
       "      <td>...</td>\n",
       "      <td>2720</td>\n",
       "      <td>2644</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>261</td>\n",
       "      <td>286</td>\n",
       "      <td>106</td>\n",
       "      <td>76</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>California</td>\n",
       "      <td>Colusa County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>21547</td>\n",
       "      <td>10975</td>\n",
       "      <td>10572</td>\n",
       "      <td>...</td>\n",
       "      <td>6477</td>\n",
       "      <td>6024</td>\n",
       "      <td>65</td>\n",
       "      <td>54</td>\n",
       "      <td>242</td>\n",
       "      <td>202</td>\n",
       "      <td>68</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>California</td>\n",
       "      <td>Contra Costa County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1153526</td>\n",
       "      <td>564187</td>\n",
       "      <td>589339</td>\n",
       "      <td>...</td>\n",
       "      <td>136151</td>\n",
       "      <td>136348</td>\n",
       "      <td>6839</td>\n",
       "      <td>7116</td>\n",
       "      <td>7438</td>\n",
       "      <td>7178</td>\n",
       "      <td>6960</td>\n",
       "      <td>6950</td>\n",
       "      <td>1570</td>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>California</td>\n",
       "      <td>Del Norte County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>27812</td>\n",
       "      <td>15186</td>\n",
       "      <td>12626</td>\n",
       "      <td>...</td>\n",
       "      <td>3167</td>\n",
       "      <td>1642</td>\n",
       "      <td>74</td>\n",
       "      <td>52</td>\n",
       "      <td>499</td>\n",
       "      <td>392</td>\n",
       "      <td>56</td>\n",
       "      <td>40</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>California</td>\n",
       "      <td>El Dorado County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>192843</td>\n",
       "      <td>96158</td>\n",
       "      <td>96685</td>\n",
       "      <td>...</td>\n",
       "      <td>11740</td>\n",
       "      <td>11679</td>\n",
       "      <td>313</td>\n",
       "      <td>241</td>\n",
       "      <td>1065</td>\n",
       "      <td>936</td>\n",
       "      <td>390</td>\n",
       "      <td>354</td>\n",
       "      <td>113</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>California</td>\n",
       "      <td>Fresno County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>999101</td>\n",
       "      <td>498648</td>\n",
       "      <td>500453</td>\n",
       "      <td>...</td>\n",
       "      <td>248241</td>\n",
       "      <td>242710</td>\n",
       "      <td>7502</td>\n",
       "      <td>7891</td>\n",
       "      <td>15658</td>\n",
       "      <td>15487</td>\n",
       "      <td>6049</td>\n",
       "      <td>6036</td>\n",
       "      <td>1187</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2489</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>California</td>\n",
       "      <td>Glenn County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>28393</td>\n",
       "      <td>14462</td>\n",
       "      <td>13931</td>\n",
       "      <td>...</td>\n",
       "      <td>5894</td>\n",
       "      <td>5394</td>\n",
       "      <td>110</td>\n",
       "      <td>92</td>\n",
       "      <td>389</td>\n",
       "      <td>319</td>\n",
       "      <td>110</td>\n",
       "      <td>72</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>California</td>\n",
       "      <td>Humboldt County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>135558</td>\n",
       "      <td>67241</td>\n",
       "      <td>68317</td>\n",
       "      <td>...</td>\n",
       "      <td>7007</td>\n",
       "      <td>7062</td>\n",
       "      <td>308</td>\n",
       "      <td>246</td>\n",
       "      <td>1269</td>\n",
       "      <td>1270</td>\n",
       "      <td>257</td>\n",
       "      <td>219</td>\n",
       "      <td>93</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>California</td>\n",
       "      <td>Imperial County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>181215</td>\n",
       "      <td>92878</td>\n",
       "      <td>88337</td>\n",
       "      <td>...</td>\n",
       "      <td>73660</td>\n",
       "      <td>73464</td>\n",
       "      <td>1031</td>\n",
       "      <td>1074</td>\n",
       "      <td>2192</td>\n",
       "      <td>2136</td>\n",
       "      <td>1154</td>\n",
       "      <td>1169</td>\n",
       "      <td>220</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3173</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>California</td>\n",
       "      <td>Inyo County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>18039</td>\n",
       "      <td>9036</td>\n",
       "      <td>9003</td>\n",
       "      <td>...</td>\n",
       "      <td>1844</td>\n",
       "      <td>1776</td>\n",
       "      <td>48</td>\n",
       "      <td>41</td>\n",
       "      <td>334</td>\n",
       "      <td>311</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>California</td>\n",
       "      <td>Kern County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>900202</td>\n",
       "      <td>461034</td>\n",
       "      <td>439168</td>\n",
       "      <td>...</td>\n",
       "      <td>236049</td>\n",
       "      <td>219724</td>\n",
       "      <td>6219</td>\n",
       "      <td>6245</td>\n",
       "      <td>12754</td>\n",
       "      <td>12260</td>\n",
       "      <td>4437</td>\n",
       "      <td>4382</td>\n",
       "      <td>1014</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3629</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>California</td>\n",
       "      <td>Kings County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>152940</td>\n",
       "      <td>84342</td>\n",
       "      <td>68598</td>\n",
       "      <td>...</td>\n",
       "      <td>42214</td>\n",
       "      <td>35616</td>\n",
       "      <td>1328</td>\n",
       "      <td>1124</td>\n",
       "      <td>2501</td>\n",
       "      <td>2154</td>\n",
       "      <td>953</td>\n",
       "      <td>693</td>\n",
       "      <td>224</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>California</td>\n",
       "      <td>Lake County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>64386</td>\n",
       "      <td>32194</td>\n",
       "      <td>32192</td>\n",
       "      <td>...</td>\n",
       "      <td>6407</td>\n",
       "      <td>6050</td>\n",
       "      <td>191</td>\n",
       "      <td>188</td>\n",
       "      <td>971</td>\n",
       "      <td>863</td>\n",
       "      <td>143</td>\n",
       "      <td>127</td>\n",
       "      <td>60</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4085</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>35</td>\n",
       "      <td>California</td>\n",
       "      <td>Lassen County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>30573</td>\n",
       "      <td>19026</td>\n",
       "      <td>11547</td>\n",
       "      <td>...</td>\n",
       "      <td>3776</td>\n",
       "      <td>1435</td>\n",
       "      <td>149</td>\n",
       "      <td>63</td>\n",
       "      <td>392</td>\n",
       "      <td>206</td>\n",
       "      <td>114</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4313</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>California</td>\n",
       "      <td>Los Angeles County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>10039107</td>\n",
       "      <td>4949041</td>\n",
       "      <td>5090066</td>\n",
       "      <td>...</td>\n",
       "      <td>2277921</td>\n",
       "      <td>2292049</td>\n",
       "      <td>65044</td>\n",
       "      <td>67836</td>\n",
       "      <td>85395</td>\n",
       "      <td>82360</td>\n",
       "      <td>50549</td>\n",
       "      <td>50659</td>\n",
       "      <td>11319</td>\n",
       "      <td>11383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4541</th>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>39</td>\n",
       "      <td>California</td>\n",
       "      <td>Madera County</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>157327</td>\n",
       "      <td>75885</td>\n",
       "      <td>81442</td>\n",
       "      <td>...</td>\n",
       "      <td>42074</td>\n",
       "      <td>42386</td>\n",
       "      <td>884</td>\n",
       "      <td>966</td>\n",
       "      <td>3240</td>\n",
       "      <td>3105</td>\n",
       "      <td>529</td>\n",
       "      <td>526</td>\n",
       "      <td>226</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SUMLEV  STATE  COUNTY      STNAME              CTYNAME  YEAR  AGEGRP  \\\n",
       "209       50      6       1  California       Alameda County    12       0   \n",
       "437       50      6       3  California        Alpine County    12       0   \n",
       "665       50      6       5  California        Amador County    12       0   \n",
       "893       50      6       7  California         Butte County    12       0   \n",
       "1121      50      6       9  California     Calaveras County    12       0   \n",
       "1349      50      6      11  California        Colusa County    12       0   \n",
       "1577      50      6      13  California  Contra Costa County    12       0   \n",
       "1805      50      6      15  California     Del Norte County    12       0   \n",
       "2033      50      6      17  California     El Dorado County    12       0   \n",
       "2261      50      6      19  California        Fresno County    12       0   \n",
       "2489      50      6      21  California         Glenn County    12       0   \n",
       "2717      50      6      23  California      Humboldt County    12       0   \n",
       "2945      50      6      25  California      Imperial County    12       0   \n",
       "3173      50      6      27  California          Inyo County    12       0   \n",
       "3401      50      6      29  California          Kern County    12       0   \n",
       "3629      50      6      31  California         Kings County    12       0   \n",
       "3857      50      6      33  California          Lake County    12       0   \n",
       "4085      50      6      35  California        Lassen County    12       0   \n",
       "4313      50      6      37  California   Los Angeles County    12       0   \n",
       "4541      50      6      39  California        Madera County    12       0   \n",
       "\n",
       "       TOT_POP  TOT_MALE  TOT_FEMALE  ...  HWAC_MALE  HWAC_FEMALE  HBAC_MALE  \\\n",
       "209    1671329    823247      848082  ...     166972       162697      10421   \n",
       "437       1129       609         520  ...         50           41          4   \n",
       "665      39752     21638       18114  ...       3275         1939        101   \n",
       "893     219186    108473      110713  ...      17400        16812        502   \n",
       "1121     45905     22847       23058  ...       2720         2644         65   \n",
       "1349     21547     10975       10572  ...       6477         6024         65   \n",
       "1577   1153526    564187      589339  ...     136151       136348       6839   \n",
       "1805     27812     15186       12626  ...       3167         1642         74   \n",
       "2033    192843     96158       96685  ...      11740        11679        313   \n",
       "2261    999101    498648      500453  ...     248241       242710       7502   \n",
       "2489     28393     14462       13931  ...       5894         5394        110   \n",
       "2717    135558     67241       68317  ...       7007         7062        308   \n",
       "2945    181215     92878       88337  ...      73660        73464       1031   \n",
       "3173     18039      9036        9003  ...       1844         1776         48   \n",
       "3401    900202    461034      439168  ...     236049       219724       6219   \n",
       "3629    152940     84342       68598  ...      42214        35616       1328   \n",
       "3857     64386     32194       32192  ...       6407         6050        191   \n",
       "4085     30573     19026       11547  ...       3776         1435        149   \n",
       "4313  10039107   4949041     5090066  ...    2277921      2292049      65044   \n",
       "4541    157327     75885       81442  ...      42074        42386        884   \n",
       "\n",
       "      HBAC_FEMALE  HIAC_MALE  HIAC_FEMALE  HAAC_MALE  HAAC_FEMALE  HNAC_MALE  \\\n",
       "209         10961      12411        12008       9100         9346       2296   \n",
       "437             2         28           26          3            1          0   \n",
       "665            49        318          225         94           53         35   \n",
       "893           554       1702         1780        406          399        167   \n",
       "1121           65        261          286        106           76         26   \n",
       "1349           54        242          202         68           48         42   \n",
       "1577         7116       7438         7178       6960         6950       1570   \n",
       "1805           52        499          392         56           40         11   \n",
       "2033          241       1065          936        390          354        113   \n",
       "2261         7891      15658        15487       6049         6036       1187   \n",
       "2489           92        389          319        110           72         25   \n",
       "2717          246       1269         1270        257          219         93   \n",
       "2945         1074       2192         2136       1154         1169        220   \n",
       "3173           41        334          311         30           26          9   \n",
       "3401         6245      12754        12260       4437         4382       1014   \n",
       "3629         1124       2501         2154        953          693        224   \n",
       "3857          188        971          863        143          127         60   \n",
       "4085           63        392          206        114           29         26   \n",
       "4313        67836      85395        82360      50549        50659      11319   \n",
       "4541          966       3240         3105        529          526        226   \n",
       "\n",
       "      HNAC_FEMALE  \n",
       "209          2392  \n",
       "437             1  \n",
       "665            21  \n",
       "893           159  \n",
       "1121           20  \n",
       "1349           39  \n",
       "1577         1491  \n",
       "1805           13  \n",
       "2033          107  \n",
       "2261         1155  \n",
       "2489           29  \n",
       "2717           86  \n",
       "2945          217  \n",
       "3173            9  \n",
       "3401         1011  \n",
       "3629          210  \n",
       "3857           63  \n",
       "4085            6  \n",
       "4313        11383  \n",
       "4541          193  \n",
       "\n",
       "[20 rows x 80 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** Process Flat File: California Ethnicity demographics - cc-est2019-alldata-06.csv\n",
    "raw_ethnic_pop_df = pd.read_csv(\"cc-est2019-alldata-06.csv\")\n",
    "\n",
    "#//*** Data includes values for last twelve years. We only want data for the last year.\n",
    "\n",
    "#//*** Rebuild raw_ethnic_pop_df using only the last year (most recent) data\n",
    "raw_ethnic_pop_df = raw_ethnic_pop_df[raw_ethnic_pop_df['YEAR']==raw_ethnic_pop_df['YEAR'].max()]\n",
    "\n",
    "#//*** Ethnic data is broken down by age. At this stage we will only use the totals of all ages\n",
    "#//*** Only use AGEGRP == 0\n",
    "raw_ethnic_pop_df = raw_ethnic_pop_df[raw_ethnic_pop_df['AGEGRP']==raw_ethnic_pop_df['AGEGRP'].min()]\n",
    "\n",
    "\n",
    "raw_ethnic_pop_df.head(20)\n",
    "\n",
    "#//*** More processing below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Import data from the community resillance estimate\n",
    "raw_res_df = pd.read_csv('cre-2018-a11.csv')\n",
    "\n",
    "#//*** Only collect California Fields.\n",
    "#//*** State Code is 6. Reference the value stored in the raw_ethnic_pop_df to keep everything linked dynamically.\n",
    "#//*** You never know when data sources get moved around. At least the federal definitions of things should remain\n",
    "#//*** constant if they ever have a reason for change.\n",
    "\n",
    "#//*** California Only results\n",
    "raw_res_df = raw_res_df[raw_res_df['state'] == raw_ethnic_pop_df['STATE'].iloc[0]]\n",
    "\n",
    "#//*** Risk Factor Groups are presummed by county in tract 0\n",
    "#//*** Gather all values of tract 0\n",
    "raw_res_df = raw_res_df[raw_res_df['tract'] == 0 ]\n",
    "\n",
    "#//*** This generates a table reflecting three sets of risk factors by county, 0, 1-2, 3 or more risk factors.\n",
    "#//*** Each of these rows needs to be converted to a column that can be added as an attribute for each county in \n",
    "#//*** pop_attrib_df\n",
    "\n",
    "#//*** Use rf (risk factor) as a container for lists that will be turned back into Series.\n",
    "#//*** Adding to existing Series and DataFrames is expensive (whatever that means). \n",
    "#//*** Therefore data should be built into lists and converted back into dataframes once it's all assembled. \n",
    "#//*** Keeping the county fibs value (rf_fibs) since it's the key to keeping the data linked\n",
    "rf = {\"rf_fibs\" : [],\n",
    "      \"0rf_num\" : [],\n",
    "      \"0rf_rate\" : [],\n",
    "      \"0rf_err\" : [],\n",
    "      \"1-2rf_num\" : [],\n",
    "      \"1-2rf_rate\" : [],\n",
    "      \"1-2rf_err\" : [],\n",
    "      \"3plrf_num\" : [],\n",
    "      \"3plrf_rate\" : [],\n",
    "      \"3plrf_err\" : [],\n",
    "}\n",
    "\n",
    "#################################################################################################\n",
    "#//*** rf_key_dict associates the rfgrp value with it's corresponding dictionary list.\n",
    "#//*** The goal is to hardcode these tables, then handle the work with a generic loop thing\n",
    "#//*** If we need to adjust data collection at later time we should only have to adjust these\n",
    "#//*** Structures\n",
    "#################################################################################################\n",
    "rf_key_dict = {\n",
    "    \"0RF\" : {\"prednum\" : \"0rf_num\", \"predrt\" : \"0rf_rate\", \"predrt_moe\" : \"0rf_err\"},\n",
    "    \"1-2RF\" : {\"prednum\" : \"1-2rf_num\", \"predrt\" : \"1-2rf_rate\", \"predrt_moe\" : \"1-2rf_err\"},\n",
    "    \"3PLRF\" : {\"prednum\" : \"3plrf_num\", \"predrt\" : \"3plrf_rate\", \"predrt_moe\" : \"3plrf_err\"}\n",
    "} \n",
    "\n",
    "####################################################################################################\n",
    "#//*** My preference is to get a list of unique counties extract the data with a loop of counties. \n",
    "#//*** Let's do right by DSC530 and use the groupby command\n",
    "############################################################################\n",
    "\n",
    "#//*** BEGIN - raw_res_df.groupby('county')\n",
    "for county_tuple in raw_res_df.groupby('county'):\n",
    "    #//*** The county is the first value of the group tuple, since it's the groupby field.\n",
    "    rf[\"rf_fibs\"].append(county_tuple[0])\n",
    "    \n",
    "    #//*** Get the resulting dataframe containing just the county values\n",
    "    loop_df = county_tuple[1]\n",
    "    \n",
    "    ####################################################################################################\n",
    "    #//*** Loop through the 3 different Risk Factor Groups, by using the key values in rf_key_dict\n",
    "    ####################################################################################################\n",
    "    \n",
    "    #//*** BEGIN - rf_key in rf_key_dict.keys():\n",
    "    for rf_key in rf_key_dict.keys():\n",
    "        \n",
    "        #//*** Loop through the sub dictionary to associate the column/row value with the correct list\n",
    "        #//*** if rf.\n",
    "        #//*** rf_key - Risk Factor group 0rf, 1-2rf, 3plrf. There is one of each value per row\n",
    "        #//*** column - Data frame Column\n",
    "        #//*** key_dict_list - is the key value in rf. Each item is stored in a list.\n",
    "        \n",
    "        #//*** BEGIN - column, key_dict_list in rf_key_dict[rf_key].items():\n",
    "        for column, key_dict_list in rf_key_dict[rf_key].items():\n",
    "            #print(f\"{rf_key} - {column} : {key_dict_list}\")\n",
    "            \n",
    "            #//*** There's a lot going on here, let's spread it out to be more readable\n",
    "            #//*** Grab each risk factor grop value (rfgrp) by column (prednum,predrt,predrt_moe) \n",
    "            loop2_value = loop_df[loop_df['rfgrp'] == rf_key][column].iloc[0]\n",
    "            \n",
    "            #//*** Assign the loop2_value to the appropriate list which is defined by the value: key_dict_list\n",
    "            rf[key_dict_list].append(loop2_value)\n",
    "        \n",
    "        #//*** END - column, key_dict_list in rf_key_dict[rf_key].items():    \n",
    "        \n",
    "    #//*** END - rf_key in rf_key_dict.keys():\n",
    "    \n",
    "#//*** END - raw_res_df.groupby('county')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0rf_num  0rf_rate  0rf_err  1-2rf_num  1-2rf_rate  1-2rf_err  \\\n",
      "rf_fibs                                                                 \n",
      "1          52135      3.16     1.99    1159312       70.37       6.98   \n",
      "3            241     21.89     8.40        579       52.59      10.35   \n",
      "5           7169     20.35     5.97      17817       50.59       7.16   \n",
      "7          44433     19.46     5.32     122804       53.79       6.88   \n",
      "9           9940     21.93     6.38      22900       50.53       7.46   \n",
      "11          4223     19.65     5.75      12343       57.45       7.10   \n",
      "13        150886     13.16     3.91     710710       61.99       6.99   \n",
      "15          5189     20.77     6.47      13874       55.54       7.66   \n",
      "17         55253     29.06     6.34      94483       49.69       7.03   \n",
      "19         68407      6.95     3.13     612805       62.24       7.10   \n",
      "\n",
      "         3plrf_num  3plrf_rate  3plrf_err  \n",
      "rf_fibs                                    \n",
      "1           436060       26.47       6.84  \n",
      "3              281       25.52       9.31  \n",
      "5            10235       29.06       6.49  \n",
      "7            61078       26.75       6.02  \n",
      "9            12478       27.53       6.60  \n",
      "11            4920       22.90       6.19  \n",
      "13          284932       24.85       6.49  \n",
      "15            5915       23.68       6.47  \n",
      "17           40421       21.26       5.76  \n",
      "19          303388       30.81       6.79  \n",
      "       state  county  tract  rfgrp  prednum  prednum_moe  predrt  predrt_moe  \\\n",
      "11238      6       1      0    0RF    52135      32806.7    3.16        1.99   \n",
      "11239      6       1      0  1-2RF  1159312     114962.4   70.37        6.98   \n",
      "11240      6       1      0  3PLRF   436060     112739.6   26.47        6.84   \n",
      "12324      6       3      0    0RF      241         92.5   21.89        8.40   \n",
      "12325      6       3      0  1-2RF      579        114.0   52.59       10.35   \n",
      "12326      6       3      0  3PLRF      281        102.5   25.52        9.31   \n",
      "12330      6       5      0    0RF     7169       2101.6   20.35        5.97   \n",
      "12331      6       5      0  1-2RF    17817       2521.9   50.59        7.16   \n",
      "12332      6       5      0  3PLRF    10235       2284.1   29.06        6.49   \n",
      "12360      6       7      0    0RF    44433      12156.3   19.46        5.32   \n",
      "12361      6       7      0  1-2RF   122804      15708.3   53.79        6.88   \n",
      "12362      6       7      0  3PLRF    61078      13734.3   26.75        6.02   \n",
      "12516      6       9      0    0RF     9940       2890.1   21.93        6.38   \n",
      "12517      6       9      0  1-2RF    22900       3378.6   50.53        7.46   \n",
      "12518      6       9      0  3PLRF    12478       2988.8   27.53        6.60   \n",
      "12549      6      11      0    0RF     4223       1235.4   19.65        5.75   \n",
      "12550      6      11      0  1-2RF    12343       1525.4   57.45        7.10   \n",
      "12551      6      11      0  3PLRF     4920       1330.4   22.90        6.19   \n",
      "12567      6      13      0    0RF   150886      44802.4   13.16        3.91   \n",
      "12568      6      13      0  1-2RF   710710      80159.7   61.99        6.99   \n",
      "12569      6      13      0  3PLRF   284932      74417.3   24.85        6.49   \n",
      "13194      6      15      0    0RF     5189       1614.9   20.77        6.47   \n",
      "13195      6      15      0  1-2RF    13874       1913.3   55.54        7.66   \n",
      "13196      6      15      0  3PLRF     5915       1617.2   23.68        6.47   \n",
      "13221      6      17      0    0RF    55253      12048.6   29.06        6.34   \n",
      "13222      6      17      0  1-2RF    94483      13369.6   49.69        7.03   \n",
      "13223      6      17      0  3PLRF    40421      10958.8   21.26        5.76   \n",
      "13353      6      19      0    0RF    68407      30837.1    6.95        3.13   \n",
      "13354      6      19      0  1-2RF   612805      69918.5   62.24        7.10   \n",
      "13355      6      19      0  3PLRF   303388      66881.8   30.81        6.79   \n",
      "\n",
      "           stname STABREV                   ctname   popuni  \n",
      "11238  California      CA       Alameda County, CA  1647507  \n",
      "11239  California      CA       Alameda County, CA  1647507  \n",
      "11240  California      CA       Alameda County, CA  1647507  \n",
      "12324  California      CA        Alpine County, CA     1101  \n",
      "12325  California      CA        Alpine County, CA     1101  \n",
      "12326  California      CA        Alpine County, CA     1101  \n",
      "12330  California      CA        Amador County, CA    35221  \n",
      "12331  California      CA        Amador County, CA    35221  \n",
      "12332  California      CA        Amador County, CA    35221  \n",
      "12360  California      CA         Butte County, CA   228315  \n",
      "12361  California      CA         Butte County, CA   228315  \n",
      "12362  California      CA         Butte County, CA   228315  \n",
      "12516  California      CA     Calaveras County, CA    45318  \n",
      "12517  California      CA     Calaveras County, CA    45318  \n",
      "12518  California      CA     Calaveras County, CA    45318  \n",
      "12549  California      CA        Colusa County, CA    21486  \n",
      "12550  California      CA        Colusa County, CA    21486  \n",
      "12551  California      CA        Colusa County, CA    21486  \n",
      "12567  California      CA  Contra Costa County, CA  1146528  \n",
      "12568  California      CA  Contra Costa County, CA  1146528  \n",
      "12569  California      CA  Contra Costa County, CA  1146528  \n",
      "13194  California      CA     Del Norte County, CA    24978  \n",
      "13195  California      CA     Del Norte County, CA    24978  \n",
      "13196  California      CA     Del Norte County, CA    24978  \n",
      "13221  California      CA     El Dorado County, CA   190157  \n",
      "13222  California      CA     El Dorado County, CA   190157  \n",
      "13223  California      CA     El Dorado County, CA   190157  \n",
      "13353  California      CA        Fresno County, CA   984600  \n",
      "13354  California      CA        Fresno County, CA   984600  \n",
      "13355  California      CA        Fresno County, CA   984600  \n"
     ]
    }
   ],
   "source": [
    "#//*** Build a dataframe to check our work\n",
    "risk_factors_df = pd.DataFrame()\n",
    "\n",
    "#//*** Add columns to the DataFrame by looping through rf\n",
    "for key,value in rf.items():\n",
    "        risk_factors_df[key] = pd.Series(value)\n",
    "\n",
    "#//*** Reindex to county fibs designation\n",
    "risk_factors_df = risk_factors_df.set_index('rf_fibs')\n",
    "\n",
    "#//*** Print the dataframes and check the columns match\n",
    "print(risk_factors_df.head(10))\n",
    "print(raw_res_df.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                county  population   Latino    White    Asian   Black  \\\n",
      "cty_fibs                                                                \n",
      "1              Alameda     1671329   373055   512134   529698  169954   \n",
      "3               Alpine        1129      139      692       18       4   \n",
      "5               Amador       39752     5753    30742      575     994   \n",
      "7                Butte      219186    37731   155415    10573    3526   \n",
      "9            Calaveras       45905     5967    36672      719     420   \n",
      "11              Colusa       21547    13018     7344      266     220   \n",
      "13        Contra Costa     1153526   300420   492393   204045  100798   \n",
      "15           Del Norte       27812     5596    17236      802     917   \n",
      "17           El Dorado      192843    25378   148903     8974    1696   \n",
      "19              Fresno      999101   537180   286049   103430   46274   \n",
      "21               Glenn       28393    12079    14334      752     240   \n",
      "23            Humboldt      135558    16354   100078     3671    1686   \n",
      "25            Imperial      181215   154088    18161     2134    4386   \n",
      "27                Inyo       18039     4230    10970      271     184   \n",
      "29                Kern      900202   491545   295715    42400   46976   \n",
      "31               Kings      152940    84514    47938     5787    9662   \n",
      "33                Lake       64386    14171    44367      756    1156   \n",
      "35              Lassen       30573     5910    19796      399    2432   \n",
      "37         Los Angeles    10039107  4881970  2615947  1485197  798279   \n",
      "39              Madera      157327    92483    52197     3244    5016   \n",
      "\n",
      "          American Indian or Alaska Native  Hawaiian  Multiracial  0rf_num  \\\n",
      "cty_fibs                                                                     \n",
      "1                                     4157     13474        68857    52135   \n",
      "3                                      243         0           33      241   \n",
      "5                                      606        83          999     7169   \n",
      "7                                     3390       465         8086    44433   \n",
      "9                                      562        98         1467     9940   \n",
      "11                                     293        73          333     4223   \n",
      "13                                    3126      5379        47365   150886   \n",
      "15                                    2059        42         1160     5189   \n",
      "17                                    1500       328         6064    55253   \n",
      "19                                    5967      1437        18764    68407   \n",
      "21                                     451        32          505     6805   \n",
      "23                                    7138       359         6272    28592   \n",
      "25                                    1326       122          998    11322   \n",
      "27                                    1916        22          446     3994   \n",
      "29                                    5476      1092        16998    76248   \n",
      "31                                    1351       311         3377     7324   \n",
      "33                                    1629       151         2156    13872   \n",
      "35                                     863       245          928     6083   \n",
      "37                                   18763     22853       216098   294048   \n",
      "39                                    1712       174         2501    20490   \n",
      "\n",
      "          0rf_rate  0rf_err  1-2rf_num  1-2rf_rate  1-2rf_err  3plrf_num  \\\n",
      "cty_fibs                                                                   \n",
      "1             3.16     1.99    1159312       70.37       6.98     436060   \n",
      "3            21.89     8.40        579       52.59      10.35        281   \n",
      "5            20.35     5.97      17817       50.59       7.16      10235   \n",
      "7            19.46     5.32     122804       53.79       6.88      61078   \n",
      "9            21.93     6.38      22900       50.53       7.46      12478   \n",
      "11           19.65     5.75      12343       57.45       7.10       4920   \n",
      "13           13.16     3.91     710710       61.99       6.99     284932   \n",
      "15           20.77     6.47      13874       55.54       7.66       5915   \n",
      "17           29.06     6.34      94483       49.69       7.03      40421   \n",
      "19            6.95     3.13     612805       62.24       7.10     303388   \n",
      "21           24.45     6.91      14119       50.73       7.93       6910   \n",
      "23           21.41     5.51      71198       53.33       6.97      33727   \n",
      "25            6.52     3.74     101655       58.55       8.14      60654   \n",
      "27           22.43     5.93       8887       49.90       7.22       4929   \n",
      "29            8.77     3.61     544009       62.58       7.37     249042   \n",
      "31            5.31     2.45      90742       65.77       6.79      39912   \n",
      "33           21.68     6.15      33225       51.94       7.14      16875   \n",
      "35           26.03     6.11      11664       49.91       7.04       5624   \n",
      "37            2.94     2.00    6698377       66.87       7.15    3024086   \n",
      "39           13.61     4.27      87476       58.08       7.12      42636   \n",
      "\n",
      "          3plrf_rate  3plrf_err  \n",
      "cty_fibs                         \n",
      "1              26.47       6.84  \n",
      "3              25.52       9.31  \n",
      "5              29.06       6.49  \n",
      "7              26.75       6.02  \n",
      "9              27.53       6.60  \n",
      "11             22.90       6.19  \n",
      "13             24.85       6.49  \n",
      "15             23.68       6.47  \n",
      "17             21.26       5.76  \n",
      "19             30.81       6.79  \n",
      "21             24.83       6.56  \n",
      "23             25.26       6.02  \n",
      "25             34.93       7.76  \n",
      "27             27.68       6.43  \n",
      "29             28.65       6.95  \n",
      "31             28.93       6.59  \n",
      "33             26.38       6.17  \n",
      "35             24.06       5.91  \n",
      "37             30.19       7.03  \n",
      "39             28.31       6.54  \n"
     ]
    }
   ],
   "source": [
    "#//*** Convert Applicable federal based census codes to California Census Codes.\n",
    "#//*** Description of Federal Column Values\n",
    "#//*** https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2019/cc-est2019-alldata.pdf\n",
    "\n",
    "#//*** Notably, Federal census regards Hispanic as an ethnicity not a race. For Example: People can be Hispanic White,\n",
    "#//*** Hispanic Black, or Hispanic Asian.\n",
    "#//*** California treats all hispanics as Latino\n",
    "#//*** Latino = H_MALE, H_FEMALE Hispanic\n",
    "#//*** White - NHWA_MALE, NHWA_FEMALE (Not Hispanic White)\n",
    "#//*** Asian - NHAA_MALE, NHAA_FEMALE (Not Hispanic Asian) \n",
    "#//*** Black - NHBA_MALE, NHBA_FEMALE (Not Hispanic Black) \n",
    "\n",
    "#//*** Amer Indian - NHIA_MALE, NHIA_FEMALE (Not Hispanic, American Indian) \n",
    "\n",
    "#//*** Hawaiian - NHNA_MALE, NHNA_FEMALE (Not Hispanic, Hawaiian) \n",
    "\n",
    "#//*** California has the following columns: Multiracial, Other, Multirace. I could not find a good definition of these\n",
    "#//*** These represent less than 5% of the population. Small but not too small to be ignored. These will combined into\n",
    "#//*** Single attribute Other and combined with NHTOM_MALE, NHTOM_FEMALE - Not Hispanic Two or more races\n",
    "\n",
    "#//*** Build a new data frame to hold the sanitized values.\n",
    "pop_attrib_df = pd.DataFrame()\n",
    "\n",
    "#//*** The County Fibs code is shared between the federal census data and the Community Resilliance Estimate\n",
    "pop_attrib_df['cty_fibs'] = raw_ethnic_pop_df['COUNTY']\n",
    "\n",
    "#//*** County Name will be the Common attribute to link to the timeseries Data.\n",
    "#//*** Standardize the County name. Remove County from the column name \n",
    "pop_attrib_df['county'] = raw_ethnic_pop_df['CTYNAME'].str.replace(\" County\",\"\")\n",
    "pop_attrib_df['population'] = raw_ethnic_pop_df['TOT_POP']\n",
    "\n",
    "clean_cols = { 'Latino' : ['H_MALE', 'H_FEMALE'], \n",
    "              'White' : ['NHWA_MALE', 'NHWA_FEMALE'],\n",
    "              'Asian' : ['NHAA_MALE', 'NHAA_FEMALE'],\n",
    "              'Black' : ['NHBA_MALE', 'NHBA_FEMALE'],\n",
    "              'American Indian or Alaska Native' : ['NHIA_MALE','NHIA_FEMALE'],\n",
    "              'Hawaiian' : ['NHNA_MALE', 'NHNA_FEMALE'],\n",
    "              'Multiracial' : ['NHTOM_MALE', 'NHTOM_FEMALE']\n",
    "            \n",
    "            }\n",
    "\n",
    "#//*** Combine male and female columns and store to column with same name as California Data\n",
    "#//*** Loop through the clean_cols dictionary, key is California name, value is Federal columns to combine\n",
    "#//*** These are the easy 1:1 columns\n",
    "#//*** Hawaiian and Other will need adjustment in the Califnornia Side of the Dataset.\n",
    "\n",
    "\n",
    "#//*** California Column name = Federal category male + Federal Category female\n",
    "for ca_name,fed_names in clean_cols.items():\n",
    "    pop_attrib_df[ca_name] = raw_ethnic_pop_df[fed_names[0]] + raw_ethnic_pop_df[fed_names[1]] \n",
    "\n",
    "#              'Native Hawaiian or Pacific Islander' :\n",
    "#              'Native Hawaiian and other Pacific Islander'\n",
    "#            'Other'\n",
    "\n",
    "#//*** Assign the index to the county fibs number\n",
    "pop_attrib_df = pop_attrib_df.set_index('cty_fibs')\n",
    "\n",
    "#//*** Join risk factors with pop attrib\n",
    "pop_attrib_df = pop_attrib_df.join(risk_factors_df)\n",
    "\n",
    "#//*** We've successfully combined ethnic/racial population data with estimated COVID risk factors.\n",
    "#//*** I should run some correlations just for fun. I suspect there is something interesting to find\n",
    "\n",
    "print(pop_attrib_df.head(20))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Export all Data frames to CSVs\n",
    "\n",
    "#//*** Export API DataFrames to File\n",
    "covid_ethnic_df.to_csv(\"z_covid_ethnic_df.csv\")\n",
    "covid_cases_df.to_csv(\"z_covid_cases_df.csv\")\n",
    "\n",
    "#//*** Export pop_attrib_df to CSV\n",
    "pop_attrib_df.to_csv(\"z_pop_attrib_df.csv\")\n",
    "\n",
    "#//*** Export Covid Tracking Project Dataframe to CSV\n",
    "covid_project_df.to_csv(\"z_covid_project_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Columns to remove from imported CSVs. We should be able to kill these on import if we were cool.\n",
    "#//*** But we're not, so we'll use an expedient column delete list.\n",
    "\n",
    "del_cols = ['Unnamed: 0', '_id']\n",
    "#//*** Load datframes from file, because we mess them up\n",
    "covid_ethnic_df = pd.read_csv(\"z_covid_ethnic_df.csv\")\n",
    "covid_cases_df = pd.read_csv(\"z_covid_cases_df.csv\")\n",
    "pop_attrib_df = pd.read_csv(\"z_pop_attrib_df.csv\")\n",
    "covid_project_df = pd.read_csv(\"z_covid_project_df.csv\")\n",
    "\n",
    "#//***********************************************************************************\n",
    "#//*** Remove excess columns from read_csv\n",
    "#//*** Use the loop in case we need to delete columns that are not exclusive to all\n",
    "#//***********************************************************************************\n",
    "for x in del_cols:\n",
    "    if x in covid_cases_df.columns:\n",
    "        covid_cases_df.drop([x], axis=1, inplace=True)\n",
    "\n",
    "    if x in covid_ethnic_df.columns:\n",
    "        covid_ethnic_df.drop([x], axis=1, inplace=True)\n",
    "    \n",
    "    if x in pop_attrib_df.columns:\n",
    "        pop_attrib_df.drop([x], axis=1, inplace=True)\n",
    "    \n",
    "    if x in covid_project_df.columns:\n",
    "        covid_project_df.drop([x], axis=1, inplace=True)\n",
    "        \n",
    "#print(covid_cases_df.head())\n",
    "#print(covid_ethnic_df.head())\n",
    "#print(pop_attrib_df.head())\n",
    "#print(covid_project_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latino 308\n",
      "White 308\n",
      "Asian 308\n",
      "Black 308\n",
      "Multiracial 49\n",
      "American Indian or Alaska Native 308\n",
      "Other 308\n",
      "Native Hawaiian or Pacific Islander 49\n",
      "Multi-Race 259\n",
      "Native Hawaiian and other Pacific Islander 259\n"
     ]
    }
   ],
   "source": [
    "races = covid_ethnic_df['race_ethnicity'].unique()\n",
    "\n",
    "for x in races:\n",
    "    print(f\"{x} {covid_ethnic_df[ covid_ethnic_df['race_ethnicity'] == x ]['race_ethnicity'].count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ethinic State: 2020-04-13T00:00:00\n",
      "                          race_ethnicity  cases  case_percentage  deaths  \\\n",
      "0                                 Latino   5276            35.99     170   \n",
      "193  Native Hawaiian or Pacific Islander    243             1.66       4   \n",
      "160     American Indian or Alaska Native     33             0.23       3   \n",
      "226                                Other   1269             8.66       9   \n",
      "64                                 Asian   1902            12.97      98   \n",
      "\n",
      "     death_percentage  percent_ca_population                 date  \n",
      "0               28.38                   38.9  2020-04-13T00:00:00  \n",
      "193              0.67                    0.3  2020-04-13T00:00:00  \n",
      "160              0.50                    0.5  2020-04-13T00:00:00  \n",
      "226              1.50                    0.0  2020-04-13T00:00:00  \n",
      "64              16.36                   15.4  2020-04-13T00:00:00  \n",
      "             county  totalcountconfirmed  totalcountdeaths  newcountconfirmed  \\\n",
      "8364      El Dorado                 30.0               0.0                  2   \n",
      "696   Santa Barbara                271.0               2.0                 10   \n",
      "6693           Inyo                 12.0               0.0                  0   \n",
      "3033           Yuba                 13.0               1.0                  0   \n",
      "5361          Butte                 13.0               0.0                  0   \n",
      "\n",
      "      newcountdeaths                 date  \n",
      "8364               0  2020-04-13T00:00:00  \n",
      "696                0  2020-04-13T00:00:00  \n",
      "6693               0  2020-04-13T00:00:00  \n",
      "3033               0  2020-04-13T00:00:00  \n",
      "5361               0  2020-04-13T00:00:00  \n"
     ]
    }
   ],
   "source": [
    "#//*** Sort Time Series by date and reset index\n",
    "covid_cases_df = covid_cases_df.sort_values(by='date')\n",
    "covid_ethnic_df = covid_ethnic_df.sort_values(by='date')\n",
    "\n",
    "#//*** Reset the index\n",
    "#covid_ethnic_df.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#//*** Get first Ethnic_df date\n",
    "ethnic_start_date = covid_ethnic_df['date'].iloc[0]\n",
    "print(f\"Ethinic State: {ethnic_start_date}\")\n",
    "\n",
    "#//*************************************************************************************************\n",
    "#//*** Get the iloc (index #) of the first covid_case_df entry to match the date in covid_ethic_df\n",
    "#//*** Compound code\n",
    "#//*** 1. Get the entries where the date matches ethnic start date\n",
    "#//*** 2. Get the first value from the list\n",
    "#//*** 3. Get the Index (name) of that entry\n",
    "#//*** 4. Get the iloc value of the name entry. This is the value to slice from covid_cases_df\n",
    "#//*************************************************************************************************\n",
    "#//*** I hate these, but I see the appeal\n",
    "#//*************************************************************************************************\n",
    "covid_start_iloc = covid_cases_df.index.get_loc(covid_cases_df[ covid_cases_df['date'] == ethnic_start_date].iloc[0].name)\n",
    "\n",
    "#print(covid_cases_df.iloc[covid_start_iloc])\n",
    "#//*** Merge Time Series covid_ethnic_df - covid_cases_df\n",
    "\n",
    "\n",
    "#//*** Start the Bg Table DF with a subset of\n",
    "bt_df = covid_cases_df.iloc[covid_start_iloc:]\n",
    "print\n",
    "print(covid_ethnic_df.head())\n",
    "print(bt_df.head())\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latino 308\n",
      "Native Hawaiian or Pacific Islander 49\n",
      "American Indian or Alaska Native 308\n",
      "Other 308\n",
      "Asian 308\n",
      "White 308\n",
      "Black 308\n",
      "Multiracial 49\n",
      "Native Hawaiian and other Pacific Islander 259\n",
      "Multi-Race 259\n"
     ]
    }
   ],
   "source": [
    "races = covid_ethnic_df['race_ethnicity'].unique()\n",
    "\n",
    "for x in races:\n",
    "    print(f\"{x} {covid_ethnic_df[ covid_ethnic_df['race_ethnicity'] == x ]['race_ethnicity'].count()}\")\n",
    "    \n",
    "#//*** Reokace Native hawaiian and/or Paciic islander with Hawaiian\n",
    "#//*** It makes sense to combine these categories. Calling them all Hawaiian is a tad insensitive. I should change it.\n",
    "\n",
    "#covid_ethnic_df['race_ethnicity']=covid_ethnic_df['race_ethnicity'].str.replace('Native Hawaiian or Pacific Islander','Hawaiian')\n",
    "#covid_ethnic_df['race_ethnicity']=covid_ethnic_df['race_ethnicity'].str.replace('Native Hawaiian and other Pacific Islander','Hawaiian')\n",
    "#covid_ethnic_df['race_ethnicity']=covid_ethnic_df['race_ethnicity'].str.replace('Multi-Race','Multiracial' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latino 308\n",
      "Native Hawaiian or Pacific Islander 49\n",
      "American Indian or Alaska Native 308\n",
      "Other 308\n",
      "Asian 308\n",
      "White 308\n",
      "Black 308\n",
      "Multiracial 49\n",
      "Native Hawaiian and other Pacific Islander 259\n",
      "Multi-Race 259\n",
      "                          race_ethnicity  cases  case_percentage  deaths  \\\n",
      "0                                 Latino   5276            35.99     170   \n",
      "193  Native Hawaiian or Pacific Islander    243             1.66       4   \n",
      "160     American Indian or Alaska Native     33             0.23       3   \n",
      "226                                Other   1269             8.66       9   \n",
      "64                                 Asian   1902            12.97      98   \n",
      "32                                 White   4639            31.64     246   \n",
      "96                                 Black   1030             7.03      61   \n",
      "128                          Multiracial    268             1.83       8   \n",
      "\n",
      "     death_percentage  percent_ca_population                 date  \n",
      "0               28.38                   38.9  2020-04-13T00:00:00  \n",
      "193              0.67                    0.3  2020-04-13T00:00:00  \n",
      "160              0.50                    0.5  2020-04-13T00:00:00  \n",
      "226              1.50                    0.0  2020-04-13T00:00:00  \n",
      "64              16.36                   15.4  2020-04-13T00:00:00  \n",
      "32              41.07                   36.6  2020-04-13T00:00:00  \n",
      "96              10.18                    6.0  2020-04-13T00:00:00  \n",
      "128              1.34                    2.2  2020-04-13T00:00:00  \n",
      "                county  totalcountconfirmed  totalcountdeaths  \\\n",
      "11353          Alameda                821.0              31.0   \n",
      "4693            Alpine                  1.0               0.0   \n",
      "19009           Amador                  6.0               0.0   \n",
      "5361             Butte                 13.0               0.0   \n",
      "4370         Calaveras                  5.0               0.0   \n",
      "9699            Colusa                  3.0               0.0   \n",
      "17005     Contra Costa                581.0              13.0   \n",
      "17339        Del Norte                  2.0               0.0   \n",
      "8364         El Dorado                 30.0               0.0   \n",
      "6365            Fresno                209.0               5.0   \n",
      "12668            Glenn                  3.0               0.0   \n",
      "18341         Humboldt                 44.0               0.0   \n",
      "19343         Imperial                 83.0               3.0   \n",
      "6693              Inyo                 12.0               0.0   \n",
      "16003             Kern                379.0               3.0   \n",
      "15669            Kings                 10.0               0.0   \n",
      "10032             Lake                  3.0               0.0   \n",
      "9370            Lassen                  0.0               0.0   \n",
      "14668      Los Angeles               9367.0             320.0   \n",
      "13338           Madera                 29.0               2.0   \n",
      "11689            Marin                144.0              10.0   \n",
      "8029          Mariposa                  0.0               0.0   \n",
      "6031         Mendocino                  4.0               0.0   \n",
      "15336           Merced                 60.0               3.0   \n",
      "10350            Modoc                  0.0               0.0   \n",
      "4036              Mono                 21.0               1.0   \n",
      "2702          Monterey                 89.0               3.0   \n",
      "14334             Napa                 30.0               2.0   \n",
      "5027            Nevada                 24.0               1.0   \n",
      "3702            Orange               1313.0              21.0   \n",
      "12333   Out Of Country                  0.0               0.0   \n",
      "1696            Placer                116.0               7.0   \n",
      "18675           Plumas                  3.0               0.0   \n",
      "16337        Riverside               1460.0              50.0   \n",
      "15004       Sacramento                724.0              27.0   \n",
      "11018       San Benito                 33.0               2.0   \n",
      "17673   San Bernardino                925.0              31.0   \n",
      "12023        San Diego               1849.0              66.0   \n",
      "3367     San Francisco                959.0              15.0   \n",
      "7027       San Joaquin                259.0              17.0   \n",
      "2031   San Luis Obispo                107.0               1.0   \n",
      "361          San Mateo                679.0              25.0   \n",
      "696      Santa Barbara                271.0               2.0   \n",
      "27         Santa Clara               1542.0              60.0   \n",
      "5696        Santa Cruz                 82.0               1.0   \n",
      "9034            Shasta                 24.0               3.0   \n",
      "1361            Sierra                  0.0               0.0   \n",
      "13003         Siskiyou                  5.0               0.0   \n",
      "2365            Solano                137.0               2.0   \n",
      "8699            Sonoma                133.0               2.0   \n",
      "18007       Stanislaus                132.0               2.0   \n",
      "13999           Sutter                 18.0               2.0   \n",
      "13674           Tehama                  1.0               0.0   \n",
      "7695           Trinity                  0.0               0.0   \n",
      "10684           Tulare                186.0              13.0   \n",
      "1030          Tuolumne                  0.0               0.0   \n",
      "16671       Unassigned                  2.0               0.0   \n",
      "7362           Ventura                311.0               9.0   \n",
      "19677             Yolo                 81.0               2.0   \n",
      "3033              Yuba                 13.0               1.0   \n",
      "\n",
      "       newcountconfirmed  newcountdeaths                 date  \n",
      "11353                 47               5  2020-04-13T00:00:00  \n",
      "4693                   0               0  2020-04-13T00:00:00  \n",
      "19009                  0               0  2020-04-13T00:00:00  \n",
      "5361                   0               0  2020-04-13T00:00:00  \n",
      "4370                   0               0  2020-04-13T00:00:00  \n",
      "9699                   0               0  2020-04-13T00:00:00  \n",
      "17005                 28               1  2020-04-13T00:00:00  \n",
      "17339                  0               0  2020-04-13T00:00:00  \n",
      "8364                   2               0  2020-04-13T00:00:00  \n",
      "6365                   4               1  2020-04-13T00:00:00  \n",
      "12668                  0               0  2020-04-13T00:00:00  \n",
      "18341                  1               0  2020-04-13T00:00:00  \n",
      "19343                  5               0  2020-04-13T00:00:00  \n",
      "6693                   0               0  2020-04-13T00:00:00  \n",
      "16003                 60               0  2020-04-13T00:00:00  \n",
      "15669                  1               0  2020-04-13T00:00:00  \n",
      "10032                  0               0  2020-04-13T00:00:00  \n",
      "9370                   0               0  2020-04-13T00:00:00  \n",
      "14668                234              24  2020-04-13T00:00:00  \n",
      "13338                  0               0  2020-04-13T00:00:00  \n",
      "11689                  6               0  2020-04-13T00:00:00  \n",
      "8029                   0               0  2020-04-13T00:00:00  \n",
      "6031                   0               0  2020-04-13T00:00:00  \n",
      "15336                  2               0  2020-04-13T00:00:00  \n",
      "10350                  0               0  2020-04-13T00:00:00  \n",
      "4036                   1               0  2020-04-13T00:00:00  \n",
      "2702                   4               0  2020-04-13T00:00:00  \n",
      "14334                  1               0  2020-04-13T00:00:00  \n",
      "5027                   0               0  2020-04-13T00:00:00  \n",
      "3702                  30               0  2020-04-13T00:00:00  \n",
      "12333                  0               0  2020-04-13T00:00:00  \n",
      "1696                   2               0  2020-04-13T00:00:00  \n",
      "18675                  0               0  2020-04-13T00:00:00  \n",
      "16337                130              11  2020-04-13T00:00:00  \n",
      "15004                 35               2  2020-04-13T00:00:00  \n",
      "11018                  0               0  2020-04-13T00:00:00  \n",
      "17673                 98               1  2020-04-13T00:00:00  \n",
      "12023                 43              11  2020-04-13T00:00:00  \n",
      "3367                  73               3  2020-04-13T00:00:00  \n",
      "7027                  13               2  2020-04-13T00:00:00  \n",
      "2031                   5               0  2020-04-13T00:00:00  \n",
      "361                   15               0  2020-04-13T00:00:00  \n",
      "696                   10               0  2020-04-13T00:00:00  \n",
      "27                    81               7  2020-04-13T00:00:00  \n",
      "5696                   2               0  2020-04-13T00:00:00  \n",
      "9034                   0               0  2020-04-13T00:00:00  \n",
      "1361                   0               0  2020-04-13T00:00:00  \n",
      "13003                  0               0  2020-04-13T00:00:00  \n",
      "2365                   1               0  2020-04-13T00:00:00  \n",
      "8699                   2               0  2020-04-13T00:00:00  \n",
      "18007                 15               1  2020-04-13T00:00:00  \n",
      "13999                  0               0  2020-04-13T00:00:00  \n",
      "13674                  0               0  2020-04-13T00:00:00  \n",
      "7695                   0               0  2020-04-13T00:00:00  \n",
      "10684                 20               2  2020-04-13T00:00:00  \n",
      "1030                   0               0  2020-04-13T00:00:00  \n",
      "16671                  0               0  2020-04-13T00:00:00  \n",
      "7362                   5               0  2020-04-13T00:00:00  \n",
      "19677                 14               0  2020-04-13T00:00:00  \n",
      "3033                   0               0  2020-04-13T00:00:00  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "races = covid_ethnic_df['race_ethnicity'].unique()\n",
    "\n",
    "for x in races:\n",
    "    print(f\"{x} {covid_ethnic_df[ covid_ethnic_df['race_ethnicity'] == x ]['race_ethnicity'].count()}\")\n",
    "\n",
    "#//*** Convert daily ethnic covid numbers to attributes\n",
    "ethnic_dates = covid_ethnic_df.groupby('date')\n",
    "\n",
    "for date_df in ethnic_dates:\n",
    "   # print(date_df[1].stack())\n",
    "    print(date_df[1])\n",
    "    break\n",
    "\n",
    "bt_dates = bt_df.groupby('date')\n",
    "\n",
    "for date_df in bt_dates:\n",
    "    print(date_df[1].sort_values('county'))\n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "covid_ethnic_df\n"
     ]
    }
   ],
   "source": [
    "#['Native Hawaiian or Pacific Islander','Native Hawaiian and other Pacific Islander']\n",
    "#'Hawaiian'\n",
    "\n",
    "print(f\"{covid_ethnic_df=}\".split('=')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\family\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2653: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  sql.to_sql(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function Connection.__exit__>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//**** Dump all data to a database\n",
    "#//*** Build a new database\n",
    "#//*** Start from scratch each run. Therefore delete any previous version\n",
    "#//*** Databases DON'T run this way. This is for expedience. The alternative is to create a living database and \n",
    "#//*** Update the tables as needed. That's a bit \n",
    "db_filename = 'covid_data.sqldb'\n",
    "\n",
    "#//*** Delete the previous db instance if it exists.\n",
    "if os.path.exists(db_filename):\n",
    "    os.remove(db_filename)\n",
    "    \n",
    "#//*** Start a database instance\n",
    "con = sqlite3.connect(db_filename)\n",
    "\n",
    "#//*** Send each Dataframe to the database.\n",
    "#//*** We'll use a string list to name the dataframes, then convert the string name to the loop_df (loop dataframe)\n",
    "#//*** Which will do the individual database loading process\n",
    "for df_name in ['covid_ethnic_df','covid_cases_df','pop_attrib_df','covid_project_df']:\n",
    "\n",
    "    #//******************************************    \n",
    "    #//*** Build loop_df based on string name\n",
    "    #//******************************************\n",
    "    if df_name == 'covid_ethnic_df':\n",
    "        loop_df = covid_ethnic_df\n",
    "    elif df_name == 'covid_cases_df':\n",
    "        loop_df = covid_cases_df\n",
    "    elif df_name == 'pop_attrib_df':\n",
    "        loop_df = pop_attrib_df\n",
    "    elif df_name == 'covid_project_df':\n",
    "        loop_df = covid_project_df\n",
    "    else:\n",
    "        #//*** Display and error message for items missed. \n",
    "        print(f\"Failed to process: {df_name}\")\n",
    "        continue\n",
    "    loop_df.to_sql(df_name, con=con)\n",
    "\n",
    "\n",
    "#//*** Close and Exit the Database. For \n",
    "con.close()\n",
    "con.__exit__\n",
    "\n",
    "#print(covid_ethnic_df.dtypes)\n",
    "\n",
    "#for x in range(0,len(covid_ethnic_df.columns)):\n",
    "#    print(f\"{covid_ethnic_df.columns[x]} {covid_ethnic_df.dtypes[x]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
