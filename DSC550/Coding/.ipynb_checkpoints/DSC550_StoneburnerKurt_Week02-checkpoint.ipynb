{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 550 - Week 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //****************************************************************************************\n",
    "# //*** Set Working Directory to thinkstats folder.\n",
    "# //*** This pseudo-relative path call should work on all Stoneburner localized projects. \n",
    "# //****************************************************************************************\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json \n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Exercise: Build Your Text Classifiers ###\n",
    "\n",
    "**1. You can find the dataset controversial-comments.jsonl for this exercise in the Weekly Resources: Week 2 Data Files.**\n",
    "\n",
    "Pre-processing Text: For this part, you will start by reading the controversial-comments.jsonl file into a DataFrame. Then,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Temporary dictionary holds lists of JSON objects. pd.read_json generated an error. Likely due to the file\n",
    "#//*** Not being a complete JSON object. Each line is its on JSON object. \n",
    "#//*** Read the file line by line\n",
    "#//*** Parse each line of JSON. Parse each Key / Value pair. Each value is appeneded to a list. The lists are managed\n",
    "#//*** with tdict[key]. As long as the input file has the same number of keys for each line, then this works.\n",
    "#//*** Not sure what the canonical method is for converting items into a dataframe. But this technique has worked well\n",
    "#//*** in DSC530 and DSC540.\n",
    "\n",
    "#//*** Temporary Dictionary\n",
    "tdict = {}\n",
    "\n",
    "#//*** Read JSON into lists based on keys.\n",
    "with open('z_controversial-comments.jsonl', \"r\") as f:\n",
    "    \n",
    "    #//*** Initialize tdict. Each Key is used in both the JSON and tdict. This works on JSON of any length but is\n",
    "    #//*** limited to a flat construct which is fine for 2-D arrays.\n",
    "    #//*** 1.) Read the first line of the file\n",
    "    #//*** 2.) Convert the first line of JSON to a dictionary\n",
    "    #//*** 3.) Get each key/value in dictionary items\n",
    "    for key,value in json.loads(f.readline()).items():\n",
    "            #//*** Initialize a list of value, using tdict[key]\n",
    "            tdict[key] = [value]\n",
    "    \n",
    "    #//*** Process each remaining lines.\n",
    "    for line in f:\n",
    "        \n",
    "        #//*** 1.) Convert each line to a dictionary\n",
    "        #//*** 2.) get each key/value in dictionary\n",
    "        for key,value in json.loads(line).items():\n",
    "            \n",
    "            #//*** Add Value to the list associated with tdict[key]\n",
    "            tdict[key].append(value)\n",
    "#//*** Initialize a new dataframe\n",
    "con_df = pd.DataFrame()\n",
    "\n",
    "#//*** Loop through tdict, add each key as a column with value as the column data\n",
    "for key,value in tdict.items():\n",
    "    con_df[key] = value\n",
    "\n",
    "#//*** Delete tdict. It is unused and a 200mb+ object\n",
    "del tdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Convert all text to lowercase letters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Convert to lower case\n",
    "con_df['txt'] = con_df['txt'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Remove all punctuation from the text.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Remove new lines, I didn't see any samples of \\r\\n. But it is common enough. Replace it if it exists\n",
    "con_df['txt'] = con_df['txt'].str.replace(r'\\r?\\n',\"\")\n",
    "#//*** Remove plain ]n new lines\n",
    "con_df['txt'] = con_df['txt'].str.replace(r'\\n',\"\")\n",
    "\n",
    "#//*** Remove html entities, observed entities are &gt; and &lt;. All HTML entities begin with & and end with ;.\n",
    "#//*** Let's use regex to remove html entities\n",
    "con_df['txt'] = con_df['txt'].str.replace(r'&.*;',\"\")\n",
    "\n",
    "#//*** Remove elements flagged as [removed]\n",
    "con_df['txt'] = con_df['txt'].str.replace(r'\\[removed\\]',\"\")\n",
    "\n",
    "#//*** Remove elements flagged as [deleted]\n",
    "con_df['txt'] = con_df['txt'].str.replace(r'\\[deleted\\]',\"\")\n",
    "\n",
    "#//*** Some text should be empty with the removal of [removed] and [deleted]\n",
    "#//*** Remove the empty text\n",
    "con_df = con_df[ con_df['txt'].str.len() > 0]\n",
    "\n",
    "#//*** Remove punctuation using the example from the book\n",
    "punctuation = dict.fromkeys(i for i in range(sys.maxunicode) if unicodedata.category(chr(i)).startswith('P') )\n",
    "con_df['txt'] = con_df['txt'].str.translate(punctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Remove stop words.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D. Apply NLTKâ€™s PorterStemmer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439    bill will fuck a bagel if it hasnt been too lo...\n",
      "440                               ucuteman got rekt lulz\n",
      "442    i dont think anyone cares about his business m...\n",
      "443    i mean hes going to take away my and my spouse...\n",
      "444    if you are wanting to argue that something the...\n",
      "445                   as long as we get to keep chicago \n",
      "446    everytime you say that i doubt more and more t...\n",
      "447    working momsnever underestimate how stupid lef...\n",
      "448    if you had put that effort into your first res...\n",
      "449    1 why dont you post any positive trump news in...\n",
      "450    ive been saying and thinking this for a year a...\n",
      "452                           this subreddit is terrible\n",
      "453    mitt romney is so right  for once there is a g...\n",
      "454    are you dense enough to be taking the comments...\n",
      "455    i think it boils down to them not understandin...\n",
      "456    is that true cant the electors vote without th...\n",
      "457    a lotta research on that being done on thedona...\n",
      "458    especially when it was a 17 year old girl who ...\n",
      "459    and here we see more racist north carolina big...\n",
      "460    thats basically what it came down to i do live...\n",
      "Name: txt, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(con_df['txt'][400:420])\n",
    "#print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     con                                                txt\n",
      "100    0  this is the way government is supposed to be! ...\n",
      "101    0  maybe they are cheating, we should keep drugs ...\n",
      "102    1  when trump first hired her, everyone on both s...\n",
      "103    0  uh... fyi who brought up race?and the left is ...\n",
      "104    0  there we go, that i can somewhat agree with.i ...\n",
      "105    0  lol. it is genuinely hilarious how worked up y...\n",
      "106    0  they were betting on continuing the rigged gam...\n",
      "107    0  i don't think you see the point: i don't need ...\n",
      "108    0  well, since they have such a minority she's no...\n",
      "109    0  he's said nothing. stepping down from manageme...\n",
      "110    0  but it was caused by lack of banking regulatio...\n",
      "111    0  the state of indiana will give the company tax...\n",
      "112    0  runs circles around media, controls the narrat...\n",
      "113    0  doesn't exist, anymore than his \"400+ arrested...\n",
      "114    0  for the midwest, yes. for states like north ca...\n",
      "115    0  in this particular instance, it is important t...\n",
      "116    0  honestly that's just embarrassing not for him,...\n",
      "117    0  please for the love of god no jindal. it's bee...\n",
      "118    0  i propose that we combine nebraska and iowa in...\n",
      "119    0  i just think its funny to pretend that the dem...\n",
      "120    0  &gt;  it will take years of subtle interaction...\n",
      "121    0  &gt; so, once again, if someone said&gt; i thi...\n",
      "122    0  trump, the businessman, is going to give up th...\n",
      "123    0                                          [removed]\n",
      "124    0                                          [removed]\n",
      "125    0                         hey!  i like that analogy.\n",
      "126    0  and, to top it off, they were smart enough to ...\n",
      "127    0                                          [deleted]\n",
      "128    0  the people in massachusetts will be so sad to ...\n",
      "129    0  well i think that's not a bad point but i'll r...\n",
      "130    0                           or manhattan real estate\n",
      "131    0                                  he took his time.\n",
      "132    0                                              link?\n",
      "133    0  your second sentence is ignorant and wrong. i ...\n",
      "134    0  &gt; i would expect them not to skew the polls...\n",
      "135    0  no. you're thinking of the libertarian party. ...\n",
      "136    0                                          [deleted]\n",
      "137    0  that article notes ethnicity and other factors...\n",
      "138    0  he is learning though.  he does presidential a...\n",
      "139    0                        let's see, what time is it?\n",
      "140    0                                    too late, barry\n",
      "141    0  twitter has banned over around a quarter milli...\n",
      "142    0  he had 8 years to fix it. what progress did he...\n",
      "143    0  1968 isn't a modern primary. the \"modern prima...\n",
      "144    0  he's right. they should make it legal nationwi...\n",
      "145    0  i am getting a little sick of them knocking ou...\n",
      "146    0      he would stay out of politics i would imagine\n",
      "147    0  but you yourself are saying that t_d mods were...\n",
      "148    0  &gt; reaganthe guy who funded and trained al q...\n",
      "149    0  no, it was put together by turning point usa, ...\n",
      "150    0  you're a racist bigot who doesn't like white p...\n",
      "151    0  you could also explain it via clinton's inepti...\n",
      "152    0  trump did say he won michigan despite fraudule...\n",
      "153    0  hi `hassan-6663`. thank you for participating ...\n",
      "154    0  this is why some of us are still pissed at the...\n",
      "155    0  i hope this isn't some political ploy to help ...\n",
      "156    0  in unfettered social darwinism, the weakest ar...\n",
      "157    0  but...but...hillary.  you forgot to mention, e...\n",
      "158    0  so...about executive order 420... can we get t...\n",
      "159    0  lost the popular vote by the largest margin ever.\n",
      "160    0  something, something, say anything, change not...\n",
      "161    0  why do you feel the need to tell us what hilla...\n",
      "162    0  bs in ae from top 3 school in the usa. smoked ...\n",
      "163    0                that and fat checks from wallstreet\n",
      "164    0                                          [removed]\n",
      "165    0  plenty of businesses make a point of buying an...\n",
      "166    1  it is a flaw in reddit's design.  it would be ...\n",
      "167    0  i don't think bloomberg would've made much of ...\n",
      "168    0    then you might be in line for a promotion soon!\n",
      "169    0  and she didn't answer the questions. she dodge...\n",
      "170    0  yes, i absolutely think hillary would have bee...\n",
      "171    0                                          [deleted]\n",
      "172    0  &gt; trump probably is corrupt but he hasn't d...\n",
      "173    0  the local democrat establishment was against l...\n",
      "174    0             http://m.huffpost.com/us/entry/2546178\n",
      "175    0  no, because context changes the situation.blac...\n",
      "176    0  &gt; move onwhat does that even mean? this is ...\n",
      "177    0  am i the only one who is worried obama outspok...\n",
      "178    0  how do you?we have this little thing called in...\n",
      "179    0  our economy is completely intertwined. the blu...\n",
      "180    0  say it with me....the value of anything is wha...\n",
      "181    0  what's the difference between the new phrases ...\n",
      "182    0                                   tremendous work.\n",
      "183    0  doesn't matter the jobs arn't good enough, we ...\n",
      "184    0  i didn't dispute it because i understood it. c...\n",
      "185    0                :::leans down towards mic:::  wrong\n",
      "186    0                                          \"lol\"-dea\n",
      "187    0  this. i am stunned that so many libs are writi...\n",
      "188    0  i agree, i'm just trying to call this guy out ...\n",
      "189    0  and yet he keeps it classified as a schedule 1...\n",
      "190    0                            tl:dr the last 8 years.\n",
      "191    0                                       what a crock\n",
      "192    0  i'm not the one incorrectly claiming they *lit...\n",
      "193    0  this submission has been automatically removed...\n",
      "194    0  how are you going to prove what happened in a ...\n",
      "195    0  that's my take as a fellow trump-loather. ever...\n",
      "196    0  c'mon barry, we've been waiting for eight year...\n",
      "197    0                                stockholm syndrome?\n",
      "198    0  try marx or adam smith. it's been going on for...\n",
      "199    0     would not be surprised if kellyanne is a host.\n"
     ]
    }
   ],
   "source": [
    "print(con_df[100:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Now that the data is pre-processed, you will apply three different techniques to get it into a usable form for model-building. Apply each of the following steps (individually) to the pre-processed data.**\n",
    "\n",
    "A. Convert each text entry into a word-count vector (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "B. Convert each text entry into a part-of-speech tag vector (see section 6.7 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "C. Convert each entry into a term frequency-inverse document frequency (tfidf) vector (see section 6.9 in the Machine Learning with Python Cookbook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Follow-Up Question**\n",
    "\n",
    "For the three techniques in problem (2) above, give an example where each would be useful.\n",
    "\n",
    "NOTE\n",
    "\n",
    "Running these steps on all of the data can take a while, so feel free to cut down on the number of texts (maybe 50,000) if your program takes too long to run. But be sure to select the text entries randomly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
