{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt #\n",
    "- ## DSC 550 - Week 07\n",
    "- ## Milestone #5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooke is roughly organized into\n",
    "- Preprocesing and cleaning\n",
    "\n",
    "- Modeling\n",
    "    \n",
    "    Functions of note:\n",
    "    \n",
    "    - calculate_coefficients: Generates a heavily regression biased model towards the first regression attribute.\n",
    "    \n",
    "    - calculate_coefficients_v2: Improves the model results by scaling the inputs to offset the modeling bias.\n",
    "    \n",
    "    - coef_to_percent() - This converts the coefficients to percentages\n",
    "\n",
    "\n",
    "- Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some thoughts about the data and processing ##\n",
    "\n",
    "### **Wrangling Racial Data** ###\n",
    "\n",
    "As expected, great care and effort was taken to clean and wrangle the data to create both consistency and continuity between the data sets. Aligning the Federal Census bureau racial categories with California’s race data was a challenge. The Census bureau measures race and ethnicity differently than California. \n",
    "\n",
    "California breaks race into 9 categories: \n",
    "\n",
    "American Indian or Alaska Native, Asian, Black, Latino, Multi-Race, Native Hawaiian and other Pacific Islander, Other, White. \n",
    "\n",
    "The census bureau breaks race and ethnicity into 35 attributes split across male and female values for a total of 70 attributes. \n",
    "\n",
    "WA_MALE,WA_FEMALE,BA_MALE,BA_FEMALE,IA_MALE,IA_FEMALE,AA_MALE,AA_FEMALE,NA_MALE,NA_FEMALE,TOM_MALE,TOM_FEMALE,WAC_MALE,WAC_FEMALE,BAC_MALE,BAC_FEMALE,IAC_MALE,IAC_FEMALE,AAC_MALE,AAC_FEMALE,NAC_MALE,NAC_FEMALE,NH_MALE,NH_FEMALE,NHWA_MALE,NHWA_FEMALE,NHBA_MALE,NHBA_FEMALE,NHIA_MALE,NHIA_FEMALE,NHAA_MALE,NHAA_FEMALE,NHNA_MALE,NHNA_FEMALE,NHTOM_MALE,NHTOM_FEMALE,NHWAC_MALE,NHWAC_FEMALE,NHBAC_MALE,NHBAC_FEMALE,NHIAC_MALE,NHIAC_FEMALE,NHAAC_MALE,NHAAC_FEMALE,NHNAC_MALE,NHNAC_FEMALE,H_MALE,H_FEMALE,HWA_MALE,HWA_FEMALE,HBA_MALE,HBA_FEMALE,HIA_MALE,HIA_FEMALE,HAA_MALE,HAA_FEMALE,HNA_MALE,HNA_FEMALE,HTOM_MALE,HTOM_FEMALE,HWAC_MALE,HWAC_FEMALE,HBAC_MALE,HBAC_FEMALE,HIAC_MALE,HIAC_FEMALE,HAAC_MALE,HAAC_FEMALE,HNAC_MALE,HNAC_FEMALE \n",
    "\n",
    "The biggest disparity is the handling categorization of Latinos. The Census Bureau treats Hispanic as an ethnicity. Meaning, an individual may be, Hispanic White, Hispanic Black, Hispanic Asian, etc. Whereas California treats anyone who identifies as Hispanic as a monolithic racial category called Latino. In terms of categorization, Latinos were counted as H_MALE and H_FEMALE which are total Hispanic numbers. The remaining racial groups were taken from their Non-Hispanic (NH) racial categories.  \n",
    "\n",
    "The racial data was combined into the following named categories: \n",
    "\n",
    "    Latino \n",
    "\n",
    "    White \n",
    "\n",
    "    Asian \n",
    "\n",
    "    Black \n",
    "\n",
    "    Native \n",
    "\n",
    "    Hawaiian \n",
    "\n",
    "    Multiracial \n",
    "\n",
    "In hindsight these categories should be restructured to more appropriately reflect current racial sensibilities. Simply categorizing ‘Hawaiian and Other Pacific Islander’ as Hawaiian reflects a sense of racial appropriation that doesn’t respect the history Hawaiian natives, and broadly dismisses the diversity of the pacific islander population. A more appropriate designation is AAPI (Asian American Pacific Islander) which combines Asian and ‘Hawaiian and Other Pacific Islander’ categories into a single category. This aligns with the racial categorization that is reflected within my community. Additionally, I would have combined the lower population demographics of Native and Multiracial with the California Other category. This should boost some of the oddities with modeling races with low population. Although, this would eliminate the representation of racial diversity.  \n",
    "\n",
    "Appropriately, categorizing individuals is unexpectedly difficult and comes with the burden of accurate representation. There are no easy answers. \n",
    "\n",
    "### **Data Consistency and Transformation** ###\n",
    "\n",
    "This data involves matching three different sets of data. Statewide racial totals (Total Asian, total Latino, etc..) per day, total statewide COVID cases, and daily county COVID cases. One significant challenge is that none of totals numbers matched. The sum of the statewide race totals is different that the reported statewide cases, which is different than summing all county COVID cases. \n",
    "\n",
    "I surmise the difference in data reporting is due to inconsistencies in the data reporting process. Although COVID case numbers are reported daily, the final daily COVID numbers may change due to testing delays which were especially pronounced early in the pandemic through the summer of 2020. California reports on COVID cases and reported COVID cases. The reported cases represent positive tests reported on a given day. The reported tests generally represent tests performed on an earlier date (unless it was a same day test). The case count is a retroactively adjusted value   to reflect actual case counts. I’m unsure if this retroactive process was applied to all the data fields. I suspect not. For data consistency, all totals are based off county sums.  \n",
    "\n",
    "Generating daily race totals was more involved. The racial percentages were recalculated daily. The state provided the racial percentages, but recalculated values were generated with a higher precision. The daily racial percentages were applied to the state totals. This preserved the reported ratio of racial cases, but applied them to a consistent case total.  \n",
    "\n",
    "This balanced the racial totals, state totals, and summed county case totals. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference link for future use**\n",
    "\n",
    "These links are for future lookup. I find myself returning to past assignments and projects looking for reference code. Keeping good references helps during follow-on classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at Support Vector Regression\n",
    "#https://www.mygreatlearning.com/blog/support-vector-regression/\n",
    "\n",
    "#//*** GEOPANDAS sources\n",
    "#https://jcutrer.com/python/learn-geopandas-plotting-usmaps\n",
    "#https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "#https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d\n",
    "#https://geopandas.org/docs/user_guide/mapping.html\n",
    "\n",
    "#//*** Build Custom Color Gradients\n",
    "#https://coolors.co/gradient-palette/ffffff-e0472b?number=9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "could not find or load spatialindex_c-64.dll",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-20686d67dd8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mListedColormap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLinearSegmentedColormap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\geopandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeoseries\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoSeries\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeodataframe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoDataFrame\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_points_from_xy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpoints_from_xy\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mread_file\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\geopandas\\geoseries.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mshapely\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGeoPandasBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_delegate_property\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_series\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\geopandas\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mrtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRTreeError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mHAS_SINDEX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\rtree\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'0.9.7'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRtree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m  \u001b[1;31m# noqa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\rtree\\index.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\rtree\\core.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;31m# load the shared library by looking in likely places\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m \u001b[0mrt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError_GetLastErrorNum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\rtree\\finder.py\u001b[0m in \u001b[0;36mload\u001b[1;34m()\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PATH'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moldenv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"could not find or load {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlib_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'posix'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: could not find or load spatialindex_c-64.dll"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "#//*** Use the whole window in the IPYNB editor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import time \n",
    "import random\n",
    "\n",
    "\n",
    "import geopandas\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "#//*** Maximize columns and rows displayed by pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "pd.set_option('display.width', 200)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deduplicate Legend**\n",
    "\n",
    "Primarily scans the handles and labels for multiple instances of the same element. This is very helpful when drawing graphs with loops that may draw multiple legend items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# //*** Legends automatically generate too many labels based on my looping method.\n",
    "# //*** Remove the Duplicate Legends. I wrote this for DSC 530 and it keeps on giving.\n",
    "def deduplicate_legend(input_ax):\n",
    "    # //**** Get handle and label list for the current legend\n",
    "    # //**** Use first instance, toss the rest.\n",
    "    handles, labels = input_ax.get_legend_handles_labels()\n",
    "\n",
    "    handle_dict = {}\n",
    "\n",
    "    for x in range(len(labels)):\n",
    "        if labels[x] not in handle_dict.keys():\n",
    "            # //*** Label = handle\n",
    "            handle_dict[labels[x]] = handles[x]\n",
    "\n",
    "    # //*** Build unique output ists and handles\n",
    "    out_handles = []\n",
    "    out_labels = []\n",
    "    \n",
    "    for label,handle in handle_dict.items():\n",
    "        out_handles.append(handle)\n",
    "        out_labels.append(label)\n",
    "    \n",
    "    return out_handles,out_labels\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Only download Data if download_data is True.\n",
    "#//*** Avoids needlessly generating HTTP traffic\n",
    "download_data = False\n",
    "demographic_data_filename = \"z_ca_covid_demo.csv\"\n",
    "cases_data_filename = \"z_ca_covid_cases.csv\"\n",
    "\n",
    "#//***********************************************************************************************\n",
    "#//*** California COVID Data website:\n",
    "#//**************************************\n",
    "#//*** https://data.chhs.ca.gov/dataset/covid-19-time-series-metrics-by-county-and-state\n",
    "#//***********************************************************************************************\n",
    "\n",
    "#//*** Download California Current COVID Demograohic Data\n",
    "if download_data:\n",
    "    try:\n",
    "        response = requests.get(\"https://data.chhs.ca.gov/dataset/f333528b-4d38-4814-bebb-12db1f10f535/resource/e2c6a86b-d269-4ce1-b484-570353265183/download/covid19casesdemographics.csv\")\n",
    "        if response.ok:\n",
    "            print(\"Demographic Data Downloaded\")\n",
    "            f = open(demographic_data_filename, \"w\")\n",
    "            f.write(response.text)\n",
    "            f.close()\n",
    "            print(\"Demographic Data Written to file.\")\n",
    "    except:\n",
    "        print(\"Demographic Data: Trouble Downloading From State of CA\")\n",
    "\n",
    "#//*** Download California Current COVID Case Counts\n",
    "    try:\n",
    "        response = requests.get(\"https://data.chhs.ca.gov/dataset/f333528b-4d38-4814-bebb-12db1f10f535/resource/046cdd2b-31e5-4d34-9ed3-b48cdbc4be7a/download/covid19cases_test.csv\")\n",
    "        if response.ok:\n",
    "            print(\"Case Data Downloaded\")\n",
    "            f = open(cases_data_filename, \"w\")\n",
    "            f.write(response.text)\n",
    "            f.close()\n",
    "            print(\"Case Data Written to file.\")\n",
    "    except:\n",
    "        print(\"Ca Case Data: Trouble Downloading From State of CA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** read Cached Data From Local files\n",
    "\n",
    "#//*** Statewide per county COVID Cases\n",
    "ca_covid_df= pd.read_csv(cases_data_filename)\n",
    "\n",
    "#//*** Racial Totals\n",
    "ca_race_df = pd.read_csv(demographic_data_filename)\n",
    "\n",
    "\n",
    "#//*** df_list keeps track of all the dataframe names. The project is getting too big to keep in my head, so I need to keep references\n",
    "if 'ca_covid_df' not in df_list:\n",
    "    df_list.append('ca_covid_df')\n",
    "\n",
    "if 'ca_race_df' not in df_list:\n",
    "    df_list.append('ca_race_df')\n",
    "\n",
    "print(ca_race_df.columns)\n",
    "#//*** Demographics Contain Age Groups, Gender, and Race Ethnicity.\n",
    "\n",
    "#//*** We'll Focus on just Race Ethnicicty\n",
    "print(f\"Demographic Types: {ca_race_df['demographic_category'].unique()}\")\n",
    "\n",
    "#//*** Get Just Race Ethnicity\n",
    "race_category = ca_race_df['demographic_category'].unique()[2]\n",
    "\n",
    "#//*** Remove the other demographic Types. If we are cool we'd be factoring in age and gender.\n",
    "#//*** But not this time\n",
    "ca_race_df = ca_race_df[ca_race_df['demographic_category'] == race_category]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*******************************\n",
    "#//*** Clean Ca_COVID_df\n",
    "#//*******************************\n",
    "\n",
    "print(ca_covid_df)\n",
    "\n",
    "ca_covid_df.rename( columns= {'area':'county'}, inplace=True)\n",
    "print(f\"# of counties before Cleaning: {len(ca_covid_df['county'].unique())}\")\n",
    "\n",
    "#//*** Convert Date Column to Date Type.\n",
    "ca_covid_df['date'] =  pd.to_datetime(ca_covid_df['date'], infer_datetime_format=True)\n",
    "\n",
    "#print(ca_covid_df[ ca_covid_df['area_type'] == 'State'])\n",
    "ca_covid_df = ca_covid_df.sort_values('date')\n",
    "\n",
    "#\\\\*** DROP ca_covd dates that are not included in ca_race_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Remove the 'Out Of State, Unknown and California listings\n",
    "print(f\"Length Before removing Out Of Country County: {len(ca_covid_df)}\")\n",
    "ca_covid_df = ca_covid_df[~ca_covid_df['county'].isin(['Out of state','Unknown','California'])]\n",
    "\n",
    "print(f\"# of counties After Cleaning: {len(ca_covid_df['county'].unique())}\")\n",
    "\n",
    "\n",
    "#//*** Replace NaN values with 0\n",
    "for col in ca_covid_df.columns:\n",
    "    ca_covid_df[col].fillna(0,inplace=True)\n",
    "    \n",
    "    \n",
    "\n",
    "#//*** Drop Columns\n",
    "dropcols = ['area_type','population','positive_tests','reported_cases','reported_deaths','reported_tests']\n",
    "#dropcols = []\n",
    "ca_covid_orig_df = ca_covid_df.copy()\n",
    "\n",
    "if 'ca_covid_orig_df' not in df_list:\n",
    "    df_list.append('ca_covid_orig_df')\n",
    "\n",
    "for col in dropcols:\n",
    "    if col in ca_covid_df.columns:\n",
    "        del ca_covid_df[col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### //****************************************\n",
    "#//*** Cleanup ca_race_df  attributes\n",
    "#//****************************************\n",
    "print(\"Before Cleaning:\")\n",
    "print(ca_race_df)\n",
    "if 'demographic_value' in ca_race_df.columns:\n",
    "    #//*** Rename the California Racial names to matches the census derived attribute names in pop_attrib_df\n",
    "    ca_race_df['demographic_value']=ca_race_df['demographic_value'].str.replace('Native Hawaiian and other Pacific Islander','Hawaiian')\n",
    "    ca_race_df['demographic_value']=ca_race_df['demographic_value'].str.replace('Multi-Race','Multiracial' )\n",
    "    ca_race_df['demographic_value']=ca_race_df['demographic_value'].str.replace('American Indian or Alaska Native','Native' ) \n",
    "\n",
    "#//*** rename the reported_date column\n",
    "ca_race_df.rename( columns= {'report_date':'date','total_cases':'cum_cases','deaths':'cum_deaths'}, inplace=True)\n",
    "\n",
    "#//*** Delete Columns\n",
    "if 'demographic_category' in ca_race_df.columns:\n",
    "    del ca_race_df['demographic_category']\n",
    "\n",
    "if 'demographic_value' in ca_race_df.columns:\n",
    "    print(ca_race_df['demographic_value'].unique())\n",
    "\n",
    "#//*************************************\n",
    "#//*** Cleanup Statewide COVID values\n",
    "#//*************************************\n",
    "if 'demographic_value' in ca_race_df.columns:\n",
    "    ca_race_df.rename( columns= {'demographic_value':'race'}, inplace=True)\n",
    "\n",
    "#//*** Convert date to datetime format.\n",
    "ca_race_df['date'] =  pd.to_datetime(ca_race_df['date'], infer_datetime_format=True)\n",
    "\n",
    "#//*** Remove Total and Other from Race Types. Total is Statewide infections, Other is other racial categories.\n",
    "#ca_race_df = ca_race_df[~ca_race_df['race'].isin(['Other'])]\n",
    "\n",
    "#//*** Save temp_race_total_df for later use\n",
    "#temp_race_total_df = ca_race_df[ca_race_df['race']=='Total']\n",
    "\n",
    "#//*** Remove values with total (statewide values)\n",
    "ca_race_df = ca_race_df[~ca_race_df['race'].isin(['Other','Total'])]\n",
    "\n",
    "print(\"After Cleaning:\")\n",
    "print(ca_race_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Synchronize dates between ca_covid_df and ca_race_df\n",
    "#//*** Get first date of Race\n",
    "first_date = ca_race_df.iloc[0]['date']\n",
    "#//*** remove values from ca_covid before the date\n",
    "ca_covid_df = ca_covid_df[ca_covid_df['date'] >= first_date].sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ca_race_df)\n",
    "#print(ca_covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_list)\n",
    "#print(ca_covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#//**********************************************************************************************************************************\n",
    "#//*** US Census data on Racial population by County in California\n",
    "#//**********************************************************************************************************************************\n",
    "#//*** Data Source\n",
    "#//**********************************************************************************************************************************\n",
    "#//*** Census Data: https://www.census.gov/data/datasets/time-series/demo/popest/2010s-counties-detail.html\n",
    "#//*** Direct Download: https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/asrh/cc-est2019-alldata-06.csv\n",
    "#//**********************************************************************************************************************************\n",
    "#//*** Process Flat File: California Ethnicity demographics - cc-est2019-alldata-06.csv\n",
    "\n",
    "raw_ethnic_pop_df = pd.read_csv(\"cc-est2019-alldata-06.csv\")\n",
    "\n",
    "#//*** Data includes values for last twelve years. We only want data for the last year.\n",
    "\n",
    "#//*** Rebuild raw_ethnic_pop_df using only the last year (most recent) data\n",
    "raw_ethnic_pop_df = raw_ethnic_pop_df[raw_ethnic_pop_df['YEAR']==raw_ethnic_pop_df['YEAR'].max()]\n",
    "if 'raw_ethnic_pop_df' not in df_list:\n",
    "    df_list.append('raw_ethnic_pop_df')\n",
    "#//*** Ethnic data is broken down by age. At this stage we will only use the totals of all ages\n",
    "#//*** Only use AGEGRP == 0\n",
    "raw_ethnic_pop_df = raw_ethnic_pop_df[raw_ethnic_pop_df['AGEGRP']==raw_ethnic_pop_df['AGEGRP'].min()]\n",
    "\n",
    "#//*** Demographics are based on gender as well as Federal Race and Ethnic attributes. These attributes are different than the values reported\n",
    "#//*** By the State of California. These attributes will require cleaning and transformation.\n",
    "raw_ethnic_pop_df.head(20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#//*** Convert Applicable federal based census codes to California Census Codes.\n",
    "#//*** Description of Federal Column Values\n",
    "#//*** https://www2.census.gov/programs-surveys/popest/technical-documentation/file-layouts/2010-2019/cc-est2019-alldata.pdf\n",
    "#//*** Census Data: https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/\n",
    "\n",
    "#//*** Notably, Federal census regards Hispanic as an ethnicity not a race. For Example: People can be Hispanic White,\n",
    "#//*** Hispanic Black, or Hispanic Asian.\n",
    "#//*** California treats all hispanics as Latino\n",
    "#//*** Latino = H_MALE, H_FEMALE Hispanic\n",
    "#//*** White - NHWA_MALE, NHWA_FEMALE (Not Hispanic White)\n",
    "#//*** Asian - NHAA_MALE, NHAA_FEMALE (Not Hispanic Asian) \n",
    "#//*** Black - NHBA_MALE, NHBA_FEMALE (Not Hispanic Black) \n",
    "\n",
    "#//*** Amer Indian - NHIA_MALE, NHIA_FEMALE (Not Hispanic, American Indian) \n",
    "\n",
    "#//*** Hawaiian - NHNA_MALE, NHNA_FEMALE (Not Hispanic, Hawaiian) \n",
    "\n",
    "#//*** California has the following columns: Multiracial, Other, Multirace. I could not find a good definition of these\n",
    "#//*** These represent less than 5% of the population. Small but not too small to be ignored. These will combined into\n",
    "#//*** Single attribute Other and combined with NHTOM_MALE, NHTOM_FEMALE - Not Hispanic Two or more races\n",
    "\n",
    "#//*** Build a new data frame to hold the sanitized values.\n",
    "pop_attrib_df = pd.DataFrame()\n",
    "\n",
    "if 'pop_attrib_df' not in df_list:\n",
    "    df_list.append('pop_attrib_df')\n",
    "\n",
    "    #//*** The County Fibs code is shared between the federal census data and the Community Resilliance Estimate\n",
    "pop_attrib_df['cty_fibs'] = raw_ethnic_pop_df['COUNTY']\n",
    "\n",
    "#//*** County Name will be the Common attribute to link to the timeseries Data.\n",
    "#//*** Standardize the County name. Remove County from the column name \n",
    "pop_attrib_df['county'] = raw_ethnic_pop_df['CTYNAME'].str.replace(\" County\",\"\")\n",
    "pop_attrib_df['population'] = raw_ethnic_pop_df['TOT_POP']\n",
    "\n",
    "clean_cols = { 'Latino' : ['H_MALE', 'H_FEMALE'], \n",
    "              'White' : ['NHWA_MALE', 'NHWA_FEMALE'],\n",
    "              'Asian' : ['NHAA_MALE', 'NHAA_FEMALE'],\n",
    "              'Black' : ['NHBA_MALE', 'NHBA_FEMALE'],\n",
    "              'Native' : ['NHIA_MALE','NHIA_FEMALE'],\n",
    "              'Hawaiian' : ['NHNA_MALE', 'NHNA_FEMALE'],\n",
    "              'Multiracial' : ['NHTOM_MALE', 'NHTOM_FEMALE']\n",
    "            \n",
    "            }\n",
    "\n",
    "#//*** Combine male and female columns and store to column with same name as California Data\n",
    "#//*** Loop through the clean_cols dictionary, key is California name, value is Federal columns to combine\n",
    "#//*** These are the easy 1:1 columns\n",
    "#//*** Hawaiian and Other will need adjustment in the Califnornia Side of the Dataset.\n",
    "\n",
    "\n",
    "#//*** California Column name = Federal category male + Federal Category female\n",
    "for ca_name,fed_names in clean_cols.items():\n",
    "    pop_attrib_df[ca_name] = raw_ethnic_pop_df[fed_names[0]] + raw_ethnic_pop_df[fed_names[1]] \n",
    "\n",
    "#              'Native Hawaiian or Pacific Islander' :\n",
    "#              'Native Hawaiian and other Pacific Islander'\n",
    "#            'Other'\n",
    "\n",
    "#//*** Assign the index to the county fibs number\n",
    "pop_attrib_df = pop_attrib_df.set_index('cty_fibs')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Merge Population Attributes with COVID County info\n",
    "#//*** Only Merge if we haven't merged yet. I got 99 iPython problems but this aint one.\n",
    "if \"Latino\" not in ca_covid_df.columns:\n",
    "    ca_covid_df = pd.merge(ca_covid_df,pop_attrib_df,how=\"left\",on=['county'])\n",
    "\n",
    "\n",
    "#//*** Build per 100k Stats\n",
    "ca_100k_df = ca_covid_df.copy()\n",
    "if 'ca_100k_df' not in df_list:\n",
    "    df_list.append('ca_100k_df')\n",
    "\n",
    "#//*** Define Population Columns to convert to 100k. These Columns shouldn't change. Trying to setup a flexible\n",
    "#//*** Systems where I can add other attributes later if needed\n",
    "population_cols = [ 'population','Latino', 'White', 'Asian', 'Black', 'Native', 'Hawaiian','Multiracial' ]\n",
    "\n",
    "#//*** Convert Popultion values to 100k units. ie divide by 100,000\n",
    "for col in population_cols:\n",
    "    ca_100k_df[col] = ca_100k_df[col]/100000\n",
    "\n",
    "\n",
    "\n",
    "#//*** Convert cases, deaths, test to per 100k units\n",
    "attrib_cols = ['date','county']\n",
    "\n",
    "#//*** Ignore values in attrib_cols, and population_cols\n",
    "#//*** Convert remianing attributes to values per 100,000.\n",
    "#//*** This method makes it easier to change the 100k attributes later.\n",
    "for col in ca_100k_df.columns:\n",
    "    if col not in attrib_cols and col not in population_cols:\n",
    "        #//*** Convert column to per 100k value. Which is Columns value divided population per 100k\n",
    "        ca_100k_df[col] = ca_100k_df[col]/ca_100k_df['population'] \n",
    "\"\"\"\n",
    "plt.rcParams['figure.figsize'] = [50,20]\n",
    "#//*** Check our Work.\n",
    "#//*** Cases per 100k should be relatively similar in values.\n",
    "display_size = 40\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "for county in ca_100k_df['county'].unique():\n",
    "    \n",
    "    loop_df = ca_100k_df[ca_100k_df['county'] ==  county]\n",
    "    ax.plot(loop_df['date'],loop_df['cases'].rolling(5).mean(),label=county)\n",
    "\n",
    "\n",
    "    plt.xticks(rotation=30,fontsize=display_size)\n",
    "    plt.yticks(fontsize=display_size)\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "plt.legend(fontsize=display_size*.25,loc='upper left')\n",
    "plt.title(f\"Scaled County Data (per 100k)\",fontsize=display_size)\n",
    "#plt.ylabel(\"Total Cases by County (millions)\",fontsize=display_size)\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build a list of counties ordered by total COVID prevalence (most Cases per 100k) \n",
    "\n",
    "#//*** Get the Statewide 100k value. \n",
    "#//*** Get total Case Count from orig_df, dvided by total population / 100000\n",
    "state_100k = ca_covid_orig_df['cases'].sum()/(ca_covid_orig_df['population'].unique().sum()/100000)\n",
    "\n",
    "if 'state_100k' not in df_list:\n",
    "    df_list.append('state_100k')\n",
    "\n",
    "county_list = ca_100k_df['county'].unique()\n",
    "\n",
    "county_100k = []\n",
    "\n",
    "#//*** Get a list of counties with population greater than 100,000\n",
    "for county in county_list:\n",
    "    #if ca_100k_df[ca_100k_df['county']==county].iloc[0]['population'] > 1:\n",
    "    county_100k.append(county)\n",
    "case_totals = []\n",
    "\n",
    "#//*** Get the total Cases for each county per 100k\n",
    "for county in county_100k:\n",
    "    case_totals.append(ca_100k_df[ca_100k_df['county']==county]['cases'].sum())\n",
    "\n",
    "#//*** Build a series with the county name and the total per100k value for each county. Sort by the Prevalence value.\n",
    "ts = pd.Series(index = county_100k, data=case_totals).sort_values(ascending=False)\n",
    "if 'ts' not in df_list:\n",
    "    df_list.append('ts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#//******************************************************************************************************************************************************************************\n",
    "#//*** Build: ca_cases_broad_df\n",
    "#//*** Counties are converted to per day attributes. The Values are a single CA_COVID_value for the whole table.\n",
    "#//*** The Broad tables are needed for building linear regressions across the whole State. The Coefficients are used to generate granualar data about each county per day\n",
    "#//*** This DF looks at building COVID cases per day, using ca_covid_df and ca_race_df\n",
    "#//******************************************************************************************************************************************************************************\n",
    "\n",
    "def build_broad_county_attribute(input_df,input_col):\n",
    "\n",
    "    #//*** Temp dataframe to hold the output\n",
    "    output_df = pd.DataFrame()\n",
    "    for group in input_df[['date','county',input_col]].groupby('date'):\n",
    "\n",
    "        #//*** Get County and Values. Each county is its own value. Use transpose() to make the counties attribute\n",
    "        loop_df = group[1][['county',input_col]].transpose().copy()\n",
    "        #//*** Set the Column names to the counties which are in the first line\n",
    "        loop_df.columns = list(loop_df.iloc[0])\n",
    "\n",
    "        #//*** Remove the first line, since the counties are now the columns/attributes\n",
    "        loop_df = loop_df.drop('county')\n",
    "\n",
    "        #//*** Change the index from Cases to 0. This is mostly cosmetic\n",
    "        loop_df.index = [0]\n",
    "\n",
    "        #//*** Add Date Column\n",
    "        loop_df['date'] = group[0]\n",
    "\n",
    "        #//*** Add Total Column which is a sum() of all values\n",
    "        loop_df['total'] = group[1][[case_col_col]].values.sum()\n",
    "\n",
    "        #//*** Build a new columm list that moves date and total to the first two columns\n",
    "        #cols = ['date','total']+list(ts.index)\n",
    "\n",
    "        cols = ['date','total']+ list(ca_covid_df['county'].unique())\n",
    "\n",
    "        #//*** Save the df with the reordered columns\n",
    "        loop_df = loop_df[cols]\n",
    "\n",
    "        #//*** concat/append this row to the temp_df/output_df\n",
    "        output_df = pd.concat([output_df,loop_df])\n",
    "\n",
    "    return output_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if 'ca_cases_broad_df' not in df_list:\n",
    "    df_list.append('ca_cases_broad_df')\n",
    "\n",
    "#//*** The column used to build broad statistic\n",
    "case_col_col = 'cases'\n",
    "\n",
    "ca_cases_broad_df = build_broad_county_attribute(ca_covid_df,'cases')\n",
    "\n",
    "print(ca_cases_broad_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** State Race numbers don't quite add up with the State COVID totals.\n",
    "#//*** We'll re-normalize the values by\n",
    "#//*** 1.) Recalculate the percent of cases to a higher degree of accuracy\n",
    "#//*** 2.) Recalculate the Race Cases based on updated percentages\n",
    "\n",
    "#//*** Temp variables\n",
    "t_date = []\n",
    "t_race = []\n",
    "t_percent_cases = []\n",
    "tdf = pd.DataFrame()\n",
    "\n",
    "#//*** Convert Date Column to Date Type.\n",
    "#ca_covid_df['date'] =  pd.to_datetime(ca_covid_df['date'], infer_datetime_format=True)\n",
    "\n",
    "#//*******************\n",
    "\n",
    "#//*** iPython Trap\n",
    "if 'cum_cases' in ca_race_df:\n",
    "    for group in ca_race_df.groupby('date'):\n",
    "        \n",
    "        \n",
    "        \n",
    "        #//*** Get the Total Cases for the day, from the Race labeled Total\n",
    "        #total_cases = temp_race_total_df[temp_race_total_df['date']==group[0]]['cum_cases'].values[0]\n",
    "        #total_deaths = temp_race_total_df[temp_race_total_df['date']==group[0]]['cum_deaths'].values[0]\n",
    "        \n",
    "        total_cases = group[1]['cum_cases'].sum()\n",
    "        total_deaths = group[1]['cum_deaths'].sum()\n",
    "        loop_df = group[1].copy()\n",
    "        #//*** Recalculate percent_cases\n",
    "        loop_df['percent_cases'] = loop_df['cum_cases'] / total_cases\n",
    "\n",
    "        #//*** Recalculate percent_deaths\n",
    "        loop_df['percent_deaths'] = loop_df['cum_deaths'] / total_deaths\n",
    "\n",
    "        #//*** Generate the Daily Race Cases based of total reported COVID cases\n",
    "        \n",
    "        \n",
    "        #//*** Cross Check\n",
    "        #print(\"Cross Check Cases: \",ca_covid_df[ca_covid_df['date']==group[0]]['cases'].sum())\n",
    "        #print(\"Cross Check Deaths: \",ca_covid_df[ca_covid_df['date']==group[0]]['deaths'].sum())\n",
    "        state_cases = ca_cases_broad_df[ca_cases_broad_df['date']==group[0]]['total'].values[0]\n",
    "        state_deaths = ca_covid_df[ca_covid_df['date']==group[0]]['deaths'].sum()\n",
    "        print(\"State Cases: \",state_cases)\n",
    "        #print(\"State Deaths: \",state_deaths)\n",
    "\n",
    "        #print(ca_covid_df[ca_covid_df['date']==group[0]])\n",
    "        #//*** Convert cum_cases to daily cases\n",
    "        #print(loop_df)\n",
    "        loop_df['cum_cases'] = loop_df['percent_cases'] * state_cases\n",
    "        loop_df['cum_deaths'] = loop_df['percent_deaths'] * state_deaths\n",
    "        \n",
    "        #//*** Checking Work\n",
    "        #print(\"[1 == \",loop_df['percent_cases'].sum(), \" ] \",loop_df['cum_cases'].sum(),\" == \", state_cases)\n",
    "        \n",
    "        #print(loop_df)\n",
    "        #print(state_cases,\" \",state_deaths)\n",
    "        tdf = pd.concat([tdf,loop_df])\n",
    "    \n",
    "        #print()\n",
    "        #//*** Get the Percentage of cumulative Cases per day. This is cum_cases / total_cases\n",
    "        #daily_percent = group[1][group[1]['race']!='Total']['cum_cases']/total_cases\n",
    "        #group[1][group[1]['race']!='Total'] = daily_percent\n",
    "        #print(group[1])\n",
    "\n",
    "        \n",
    "\n",
    "    print(tdf[ ['date','race','cum_cases','cum_deaths','percent_cases','percent_deaths','percent_of_ca_population'] ])\n",
    "    ca_race_df = tdf[ ['date','race','cum_cases','cum_deaths','percent_cases','percent_deaths','percent_of_ca_population'] ].copy()\n",
    "\n",
    "    if 'percent_of_ca_population' in ca_race_df.columns:\n",
    "        del ca_race_df['percent_of_ca_population']\n",
    "\n",
    "    ca_race_df.columns = ['date','race','cases','deaths','percent_cases','percent_deaths']\n",
    "\n",
    "del tdf\n",
    "del t_date\n",
    "del t_race\n",
    "del t_percent_cases\n",
    "del loop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Verified ca_race_df and ca_covid_df ca_cases_broad_df are all balanced. Daily totals are based on the total county cases\n",
    "\n",
    "#print(df_list)\n",
    "#//*** Check our Work use Random to pick a random day\n",
    "t_date = ca_cases_broad_df.iloc[random.randint(0,len(ca_cases_broad_df))]['date']\n",
    "\n",
    "\n",
    "print(\"Should all be the same for this Date: \",t_date)\n",
    "print(\"ca_covid_df Cases:        \",ca_covid_df[ca_covid_df['date']==t_date]['cases'].sum())\n",
    "print(\"ca_cases_broad_df Cases: \",ca_cases_broad_df[ca_cases_broad_df['date']==t_date]['total'].values[0])\n",
    "print(\"ca_race_df Cases:        \",ca_race_df[ca_race_df['date']==t_date]['cases'].sum())\n",
    "\n",
    "#del race_tdf\n",
    "del t_date\n",
    "print(ca_race_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//********************************************************************\n",
    "#//*** Add State Wide Race per 100k values.\n",
    "#//********************************************************************\n",
    "\n",
    "state_pop = {}\n",
    "print(ca_race_df['race'].unique())\n",
    "for col in pop_attrib_df.columns[1:]:\n",
    "    state_pop[col] = pop_attrib_df[col].sum()/100000\n",
    "\n",
    "print(ca_race_df['race'].apply(lambda x : state_pop[x]))\n",
    "\n",
    "ca_race_df['cases_100k'] = ca_race_df['cases'] / ca_race_df['race'].apply(lambda x : state_pop[x])\n",
    "ca_race_df['deaths_100k'] = ca_race_df['deaths'] / ca_race_df['race'].apply(lambda x : state_pop[x])\n",
    "\n",
    "#//*** temp list to hold per 100k values\n",
    "#tl_case = []\n",
    "#t1_death = []\n",
    "#print(ca_race_df)\n",
    "#for index,row in ca_race_df.iterrows():\n",
    "    \n",
    "    #//*** Get State population based on race column\n",
    "#    state_pop[ row['race'] ]\n",
    "\n",
    "for date in ca_race_df['date'].unique():\n",
    "    print(ca_race_df[ ca_race_df['date'] == date ])\n",
    "    break\n",
    "#print(ca_race_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_list)\n",
    "#print(ca_100k_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#//******************************************************************************************************************************************************************************\n",
    "#//*** Build: ca_races_broad_df\n",
    "#//*** Daily Race Values are converted to per day attributes. The Values are a single race value for the whole table.\n",
    "#//*** The Broad tables are needed for building linear regressions across the whole State. The Coefficients are used to generate granualar data about each county per day\n",
    "#//*** This DF looks at building COVID cases per day, using ca_broad_df['total] which is the same as ca_covid_df.sum()\n",
    "#//******************************************************************************************************************************************************************************\n",
    "def build_broad_race_attribute(input_df,input_cols):\n",
    "\n",
    "    #//*** Temp dataframe to hold the output\n",
    "    output_df = pd.DataFrame()\n",
    "    for group in input_df[['date','race',input_cols]].groupby('date'):\n",
    "\n",
    "\n",
    "        #//*** Get County and Values. Each county is its own value. Use transpose() to make the counties attribute\n",
    "        loop_df = group[1][['race',input_cols]].transpose().copy()\n",
    "        #//*** Set the Column names to the counties which are in the first line\n",
    "        loop_df.columns = list(loop_df.iloc[0])\n",
    "\n",
    "        #//*** Remove the first line, since the counties are now the columns/attributes\n",
    "        loop_df = loop_df.drop('race')\n",
    "        #print(loop_df)\n",
    "        #//*** Change the index from Cases to 0. This is mostly cosmetic\n",
    "        loop_df.index = [0]\n",
    "\n",
    "        #//*** Add Date Column\n",
    "        loop_df['date'] = group[0]\n",
    "\n",
    "\n",
    "\n",
    "        #//*** Build a new columm list that moves date and total to the first two columns\n",
    "        cols = ['date']+list(loop_df.columns[:-1])\n",
    "\n",
    "        #//*** Save the df with the reordered columns\n",
    "        loop_df = loop_df[cols]\n",
    "\n",
    "        #//*** concat/append this row to the temp_df/output_df\n",
    "        output_df = pd.concat([output_df,loop_df])\n",
    "\n",
    "    return output_df\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** The column used to build broad statistic\n",
    "race_col_col = 'cases'\n",
    "\n",
    "#//*** Assign output_df to ca_races_broad_df \n",
    "ca_races_broad_df = build_broad_race_attribute(ca_race_df,'cases')\n",
    "\n",
    "#ca_rac= build_broad_attribute(ca_100k_df,'cases')\n",
    "\n",
    "if 'ca_races_broad_df' not in df_list:\n",
    "    df_list.append('ca_races_broad_df')\n",
    "    \n",
    "print(ca_races_broad_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Check our Work use Random to pick a random day\n",
    "#//*** The case totals should be close or identical\n",
    "t_date = ca_cases_broad_df.iloc[random.randint(0,len(ca_cases_broad_df))]['date']\n",
    "\n",
    "\n",
    "print(\"Should all be the same for this Date:\\n\",t_date)\n",
    "print(\"ca_covid_df Cases:       \",ca_covid_df[ca_covid_df['date']==t_date]['cases'].sum())\n",
    "print(\"ca_cases_broad_df Cases: \",ca_cases_broad_df[ca_cases_broad_df['date']==t_date]['total'].values[0])\n",
    "print(\"ca_race_df Cases:        \",ca_race_df[ca_race_df['date']==t_date]['cases'].sum())\n",
    "\n",
    "print(\"ca_races_broad_df Cases  \",ca_races_broad_df[ca_races_broad_df['date']==t_date].transpose()[1:].sum().values[0])\n",
    "del t_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//*** Check our work with a selection of ilocs. Sum of the Coefficients + intercept should be close to the total values.\n",
    "#//*** It's very close, very low error\n",
    "\n",
    "#for x in [50,100,150,200,250,300]:\n",
    "#    print(f\"{state_coef_df.iloc[x]['date'].values[0]} - {state_coef_df[x_column].iloc[x].sum() + state_coef_df.iloc[x]['intercept'].values[0]} == {state_coef_df.iloc[x]['total'].values[0]}\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_counties = (list(pop_attrib_df[['county','population']].sort_values('population',ascending=False)['county']))\n",
    "race = 'Latino'\n",
    "#print(list(pop_attrib_df[['county',race]].sort_values(race,ascending=False)[race]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ca_races_broad_df)\n",
    "#print(ca_cases_broad_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ca_100k_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Coefficients**\n",
    "\n",
    "Runs a linear regression between Statewide Racial numbers and Daily COVID Cases by County.\n",
    "\n",
    "This is the unbiased model that generates exponentially higher values to the first county. This remains for reference and to run a separate version for comparison against the scaled biased version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//***************************************************************************************************************************************************************************\n",
    "#//*** Generatate a Individual Race Coeffecients for each county per day.\n",
    "#//*** The the sum of racial coefficients should equal the state coefficent for the county. \n",
    "#//*** Build the coefficients for the entire data set. Each day will calculate the coefficients from the previous 30 days. The First 30 days will use one set of coeffients. The rest will use\n",
    "#//*** The current day: -30 to generate the coefficients. This will be an overfitted solution which is exactly what we are going for.\n",
    "#//***************************************************************************************************************************************************************************\n",
    "def calculate_coefficients(left_df, right_df, x_col_index, y_col_index):\n",
    "    print(\"Calculating racial coefficients...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #//*** Initialize the output dataframe\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    #//*** Combining with car_race_df and Latino value. It's not strictly needed, but the additional column will make combining the dataframes later, easier.\n",
    "    #//*** Reusing Code: This loop only needs to run once\n",
    "    for race in left_df.columns[1:]:\n",
    "\n",
    "        #//*** Build model for the first 30 days, combines the race from ca_race (which is only needed as an extra field, to evenly space the columms)\n",
    "        model_df = left_df[['date',race]].merge(right_df, left_on='date', right_on='date')[:30]\n",
    "\n",
    "        #//*************************\n",
    "        #//*** BEGIN regression\n",
    "        #//*************************\n",
    "\n",
    "\n",
    "        #//**** Build the x Values - Dependent Variables. These will be all the counties which start at the column index \n",
    "        #//*** The X Value is the index where the attributes start, there are 58 of them :)\n",
    "        #x_column = model_df.columns[x_col_index:]\n",
    "\n",
    "        #//*** Generate ordered list of Counties by current race population.\n",
    "        #//*** The assumptions is the counties with higher populations will exert a greater weight on the model.\n",
    "        #//*** Otherwise the tiny county of Alpine gets way overly represented\n",
    "        race_columns = (pop_attrib_df[['county',race]].sort_values(race,ascending=False)['county'])\n",
    "\n",
    "        #print(model_df[race_columns])\n",
    "        #//*** Build the X attributes using the x_column. These are separated for readability and modularity\n",
    "        x_model = model_df[race_columns]\n",
    "\n",
    "        #print(x_model)\n",
    "        #//*** Build the independent variable using the Index Column defined above as y_col_index.\n",
    "        y_column = model_df.columns[y_col_index]\n",
    "\n",
    "        #//*** Build the Y model using the y_column attribute. This is less readable and intuitive, but it lets the columns be \n",
    "        #//*** easily assigned at the top of this section\n",
    "        y_model = model_df[y_column]\n",
    "\n",
    "        #//*** Define the Linear Model\n",
    "        regr = linear_model.LinearRegression(n_jobs=-1)\n",
    "\n",
    "        #//*** Make Regression Magic\n",
    "        regr.fit(x_model, y_model)\n",
    "\n",
    "        #//*** Apply the regression coefficients\n",
    "        #//*** v1 Change: Apply coef to actual values\n",
    "        model_df[race_columns] = (model_df[race_columns])*regr.coef_\n",
    "        \n",
    "        \n",
    "        #//*** Dead End: v2 Change: Try just the coefficients \n",
    "        #model_df[race_columns] = regr.coef_\n",
    "\n",
    "\n",
    "\n",
    "        #//*** Replace the Statewide Total Column. With the Statewide Race Totals\n",
    "        model_df['total'] = model_df[race]\n",
    "\n",
    "        #//*** Change The race column to hold the race name\n",
    "        model_df[race] = race\n",
    "\n",
    "        #//*** Rename the race (Latino, Native, etc) to 'race'\n",
    "        cols = list(model_df.columns)\n",
    "        cols[1] = 'race'\n",
    "        model_df.columns = cols\n",
    "\n",
    "        model_df['intercept'] = regr.intercept_\n",
    "\n",
    "        #//*** Move intercept to be the column after Total\n",
    "        #//*** Gets Columns as a list, removes intercept of end and inserts into position\n",
    "        #//*** Model_df is saved with ordered list of columns.\n",
    "        #//*** Kinda Cool\n",
    "        model_df = model_df[ list(model_df.columns[:-1].insert(3,'intercept')) ]\n",
    "\n",
    "        #//*** Reorder Counties\n",
    "        #//*** Keep the First four Columns, then use ordered_counties\n",
    "        model_df = model_df[list(model_df.columns[:4])+ordered_counties]\n",
    "\n",
    "        #print(model_df)\n",
    "        #//*** Add the First 30 days Model to the output_df dataframe\n",
    "        output_df = pd.concat([output_df,model_df])\n",
    "\n",
    "        #//*** Checking our work. The sum of the coefficients * cases + intercept should be close the independent value in Total Cases.\n",
    "        print(\"Checking our Work. These values should be close:\")\n",
    "        print(model_df.iloc[1]['total'], \" == \", model_df[race_columns].iloc[1].sum()+regr.intercept_)    \n",
    "\n",
    "        #print(model_df)\n",
    "        \n",
    "        #break\n",
    "        #//*** Build each day individually, based on the previous 30 days\n",
    "        #//*** Start at index 31 \n",
    "        for index in range(31,len(left_df)+1):\n",
    "\n",
    "            #//*** Define the start and indexes for linear modeling. This is the row_index - 30\n",
    "            min_index = index-30\n",
    "\n",
    "            #//*** Build model_df using min_index and index as a 30 day range)\n",
    "            model_df = left_df[['date',race]].merge(right_df, left_on='date', right_on='date')[min_index:index]\n",
    "            \n",
    "            #//*** Build the X attributes using the x_column. These are separated for readability and modularity\n",
    "            x_model = model_df[race_columns]\n",
    "\n",
    "            #//*** Build the Y model using the y_column attribute. This is less readable and intuitive, but it lets the columns be \n",
    "            #//*** easily assigned at the top of this section\n",
    "            y_model = model_df[y_column]\n",
    "\n",
    "            #//*** Build a New the Linear Model\n",
    "            regr = linear_model.LinearRegression(n_jobs=-1)\n",
    "\n",
    "            #//*** Make Regression Magic\n",
    "            regr.fit(x_model, y_model)\n",
    "\n",
    "            #//*** Replace the Statewide Total Column. With the Statewide Race Totals\n",
    "            model_df['total'] = model_df[race]\n",
    "\n",
    "            #//*** Change The race column to hold the race name\n",
    "            model_df[race] = race\n",
    "\n",
    "            #//*** Rename the race (Latino, Native, etc) to 'race'\n",
    "            cols = list(model_df.columns)\n",
    "            cols[1] = 'race'\n",
    "            model_df.columns = cols\n",
    "\n",
    "            #//*** Apply the regression coefficients to all columns, even though we only need the last one\n",
    "            #//*** v1 Change: Apply coef to actual values\n",
    "            model_df[race_columns] = (model_df[race_columns])*regr.coef_\n",
    "\n",
    "            #//*** Dead End: v2 Change: Try just the coefficients\n",
    "            #model_df[race_columns] = regr.coef_\n",
    "\n",
    "            model_df['intercept'] = regr.intercept_\n",
    "\n",
    "            #//*** Move intercept to be the column after Total\n",
    "            #//*** Gets Columns as a list, removes intercept of end and inserts into position\n",
    "            #//*** Model_df is saved with ordered list of columns.\n",
    "            #//*** Kinda Cool\n",
    "            model_df = model_df[ list(model_df.columns[:-1].insert(3,'intercept')) ]\n",
    "\n",
    "            #//*** Reorder Counties\n",
    "            #//*** Keep the First four Columns, then use ordered_counties\n",
    "            model_df = model_df[list(model_df.columns[:4])+ordered_counties]\n",
    "\n",
    "            #//*** Add the last day of model_df to output_df. \n",
    "            #//*** It's not exactly efficient, but it is functional\n",
    "            #output_df = pd.concat([output_df,model_df.iloc[-1]])\n",
    "            output_df = output_df.append(model_df.iloc[-1])\n",
    "    \n",
    "    print(f\"CoEfficients Calculated: {round(time.time()-start_time,0)}s\")\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calculate Coefficients v2**\n",
    "\n",
    "Runs a linear regression between Statewide Racial numbers and Daily COVID Cases by County.\n",
    "\n",
    "This version "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//***************************************************************************************************************************************************************************\n",
    "#//*** Generatate a Individual Race Coeffecients for each county per day.\n",
    "#//*** The the sum of racial coefficients should equal the state coefficent for the county. \n",
    "#//*** Build the coefficients for the entire data set. Each day will calculate the coefficients from the previous 30 days. The First 30 days will use one set of coeffients. The rest will use\n",
    "#//*** The current day: -30 to generate the coefficients. This will be an overfitted solution which is exactly what we are going for.\n",
    "#//***************************************************************************************************************************************************************************\n",
    "def calculate_coefficients_v2(left_df, right_df, x_col_index, y_col_index):\n",
    "    \n",
    "    #//*** build county population percentages\n",
    "    \n",
    "    #//*** tdf is a placeholder for Temporary DataFrame\n",
    "    #//*** pop_attrib_df holds the county populations which will be converted to percentages\n",
    "    tdf = pop_attrib_df.copy()\n",
    "    \n",
    "    #//*** Convert to percentages. I'm doing a 1- population percentage, to invert the values\n",
    "    #//*** which Makes the small numbers big and the big one small.\n",
    "    tdf['percent'] = (1-(tdf['population']/tdf['population'].sum()))\n",
    "    \n",
    "    tdf = tdf.sort_values('percent',ascending=False)[['county','percent']]\n",
    "    \n",
    "    #//*** convert From a single attribute of counties and percentages to broad format \n",
    "    #//*** Where each county is an attribute, like the broad formatted dataframes\n",
    "    tdf = tdf.transpose()\n",
    "    #//*** Set columns to the county row\n",
    "    tdf.columns = tdf.loc['county']\n",
    "    #//*** Drop the county row\n",
    "    tdf = tdf.drop(tdf.index[0])\n",
    "    #//*** Make doubly sure the county columns are ordered the same as the dataframes below\n",
    "    tdf = tdf[ordered_counties]\n",
    "    #tdf = pow(1-(tdf*2),2)\n",
    "    \n",
    "    #//*** Apply a power transformation, to scale the first counties to a much smaller weighted\n",
    "    #//*** value, and progressively add weight to the otehr counties.\n",
    "    #//*** or at least that is what I was trying to do. This is achieved through trial and error,\n",
    "    #//*** and achieves a cululative result similar to the actual COVID counts. I could probably\n",
    "    #//*** Iteratively tweak this value for a better result. But since rescaling the data is not \n",
    "    #//*** Great approach in general. I'll leave it like it is.\n",
    "    tdf = pow(pow(1-(tdf*2),2)*1.5,2.1)\n",
    "    print(tdf)\n",
    "    \n",
    "    \n",
    "    print(\"Calculating racial coefficients...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #//*** Initialize the output dataframe\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    #//*** Combining with car_race_df and Latino value. It's not strictly needed, but the additional column will make combining the dataframes later, easier.\n",
    "    #//*** Reusing Code: This loop only needs to run once\n",
    "    for race in left_df.columns[1:]:\n",
    "\n",
    "        #//*** Build model for the first 30 days, combines the race from ca_race (which is only needed as an extra field, to evenly space the columms)\n",
    "        model_df = left_df[['date',race]].merge(right_df, left_on='date', right_on='date')[:30]\n",
    "\n",
    "        #//*************************\n",
    "        #//*** BEGIN regression\n",
    "        #//*************************\n",
    "\n",
    "\n",
    "        #//**** Build the x Values - Dependent Variables. These will be all the counties which start at the column index \n",
    "        #//*** The X Value is the index where the attributes start, there are 58 of them :)\n",
    "        #x_column = model_df.columns[x_col_index:]\n",
    "\n",
    "        #//*** Generate ordered list of Counties by current race population.\n",
    "        #//*** The assumptions is the counties with higher populations will exert a greater weight on the model.\n",
    "        #//*** Otherwise the tiny county of Alpine gets way overly represented\n",
    "        race_columns = (pop_attrib_df[['county',race]].sort_values(race,ascending=False)['county'])\n",
    "\n",
    "        #print(model_df[race_columns])\n",
    "        #//*** Build the X attributes using the x_column. These are separated for readability and modularity\n",
    "        x_model = model_df[race_columns].copy()\n",
    "        \n",
    "        #//*** Weight by population percentage\n",
    "        for col in race_columns:\n",
    "            x_model[col] = x_model[col]*tdf[col].values\n",
    "        \n",
    "        #print(x_model)\n",
    "        #//*** Build the independent variable using the Index Column defined above as y_col_index.\n",
    "        y_column = model_df.columns[y_col_index]\n",
    "\n",
    "        #//*** Build the Y model using the y_column attribute. This is less readable and intuitive, but it lets the columns be \n",
    "        #//*** easily assigned at the top of this section\n",
    "        y_model = model_df[y_column]\n",
    "\n",
    "        #//*** Define the Linear Model\n",
    "        regr = linear_model.LinearRegression(n_jobs=-1)\n",
    "\n",
    "        #//*** Make Regression Magic\n",
    "        regr.fit(x_model, y_model)\n",
    "\n",
    "        #//*** Apply the regression coefficients\n",
    "        #//*** v1 Change: Apply coef to actual values\n",
    "        model_df[race_columns] = (model_df[race_columns])*regr.coef_\n",
    "        \n",
    "        \n",
    "        #//*** Replace the Statewide Total Column. With the Statewide Race Totals\n",
    "        model_df['total'] = model_df[race]\n",
    "\n",
    "        #//*** Change The race column to hold the race name\n",
    "        model_df[race] = race\n",
    "\n",
    "        #//*** Rename the race (Latino, Native, etc) to 'race'\n",
    "        cols = list(model_df.columns)\n",
    "        cols[1] = 'race'\n",
    "        model_df.columns = cols\n",
    "\n",
    "        model_df['intercept'] = regr.intercept_\n",
    "\n",
    "        #//*** Move intercept to be the column after Total\n",
    "        #//*** Gets Columns as a list, removes intercept of end and inserts into position\n",
    "        #//*** Model_df is saved with ordered list of columns.\n",
    "        #//*** Kinda Cool\n",
    "        model_df = model_df[ list(model_df.columns[:-1].insert(3,'intercept')) ]\n",
    "\n",
    "        #//*** Reorder Counties\n",
    "        #//*** Keep the First four Columns, then use ordered_counties\n",
    "        model_df = model_df[list(model_df.columns[:4])+ordered_counties]\n",
    "\n",
    "        #print(model_df)\n",
    "        \n",
    "        #//*** Add the First 30 days Model to the output_df dataframe\n",
    "        output_df = pd.concat([output_df,model_df])\n",
    "\n",
    "        #//*** Checking our work. The sum of the coefficients * cases + intercept should be close the independent value in Total Cases.\n",
    "        print(\"Checking our Work. These values should be close:\")\n",
    "        print(model_df.iloc[1]['total'], \" == \", model_df[race_columns].iloc[1].sum()+regr.intercept_)    \n",
    "\n",
    "        #print(model_df[race_columns].iloc[0])\n",
    "        \n",
    "        #print(model_df[race_columns].iloc[0]*tdf[race_columns])\n",
    "        \n",
    "        #break\n",
    "        #//*** Build each day individually, based on the previous 30 days\n",
    "        #//*** Start at index 31 \n",
    "        for index in range(31,len(left_df)+1):\n",
    "\n",
    "            #//*** Define the start and indexes for linear modeling. This is the row_index - 30\n",
    "            min_index = index-30\n",
    "\n",
    "            #//*** Build model_df using min_index and index as a 30 day range)\n",
    "            model_df = left_df[['date',race]].merge(right_df, left_on='date', right_on='date')[min_index:index]\n",
    "            \n",
    "            #//*** Build the X attributes using the x_column. These are separated for readability and modularity\n",
    "            x_model = model_df[race_columns].copy()\n",
    "\n",
    "            #//*** Weight by population percentage\n",
    "            for col in race_columns:\n",
    "                x_model[col] = x_model[col]*tdf[col].values\n",
    "\n",
    "            #//*** Build the Y model using the y_column attribute. This is less readable and intuitive, but it lets the columns be \n",
    "            #//*** easily assigned at the top of this section\n",
    "            y_model = model_df[y_column]\n",
    "\n",
    "            #//*** Build a New the Linear Model\n",
    "            regr = linear_model.LinearRegression(n_jobs=-1)\n",
    "\n",
    "            #//*** Make Regression Magic\n",
    "            regr.fit(x_model, y_model)\n",
    "\n",
    "            #//*** Replace the Statewide Total Column. With the Statewide Race Totals\n",
    "            model_df['total'] = model_df[race]\n",
    "\n",
    "            #//*** Change The race column to hold the race name\n",
    "            model_df[race] = race\n",
    "\n",
    "            #//*** Rename the race (Latino, Native, etc) to 'race'\n",
    "            cols = list(model_df.columns)\n",
    "            cols[1] = 'race'\n",
    "            model_df.columns = cols\n",
    "\n",
    "            #//*** Apply the regression coefficients to all columns, even though we only need the last one\n",
    "            #//*** v1 Change: Apply coef to actual values\n",
    "            model_df[race_columns] = (model_df[race_columns])*regr.coef_\n",
    "            \n",
    "            #//*** Weight by population percentage\n",
    "            for col in race_columns:\n",
    "                model_df[col] = model_df[col]*tdf[col].values\n",
    "\n",
    "\n",
    "            #//*** Dead End: v2 Change: Try just the coefficients\n",
    "            #model_df[race_columns] = regr.coef_\n",
    "\n",
    "            model_df['intercept'] = regr.intercept_\n",
    "\n",
    "            #//*** Move intercept to be the column after Total\n",
    "            #//*** Gets Columns as a list, removes intercept of end and inserts into position\n",
    "            #//*** Model_df is saved with ordered list of columns.\n",
    "            #//*** Kinda Cool\n",
    "            model_df = model_df[ list(model_df.columns[:-1].insert(3,'intercept')) ]\n",
    "\n",
    "            #//*** Reorder Counties\n",
    "            #//*** Keep the First four Columns, then use ordered_counties\n",
    "            model_df = model_df[list(model_df.columns[:4])+ordered_counties]\n",
    "\n",
    "            #//*** Add the last day of model_df to output_df. \n",
    "            #//*** It's not exactly efficient, but it is functional\n",
    "            #output_df = pd.concat([output_df,model_df.iloc[-1]])\n",
    "            output_df = output_df.append(model_df.iloc[-1])\n",
    "        #print(model_df)\n",
    "    print(f\"CoEfficients Calculated: {round(time.time()-start_time,0)}s\")\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**coef_to_percent: **\n",
    "\n",
    "Converts regression coefficients to percentages. This assumes the sum of weighted coefficients equals the predicted value. This is not how coefficients are supposed to be used, but I think I'm correct on this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#//************************************************\n",
    "#//*** Convert Coefficients to percentages\n",
    "#//************************************************\n",
    "#//*** Racial Coefficients are built for each race by day and county.\n",
    "#//*** Group output_df by date, to calculate the race percent for each county by day.\n",
    "#//*** The Racial Percentage is\n",
    "\n",
    "def coef_to_percent(input_df,x_col_index):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    #//*** UH OH....This might be a problem\n",
    "    #//*** This should be input_df not processing_df. Which explains why I had\n",
    "    #//*** Trouble getting my unbiased values to run after the biased ones. \n",
    "    #//*** I 'fixed' it by copy/pasting and reusing processing_df.\n",
    "    #//*** So it \"works\". I don't want to fix it and break something else.\n",
    "\n",
    "    #//*** Get the columns to process starting at the x_col_index value.\n",
    "    x_column = processing_df.columns[x_col_index:]\n",
    "\n",
    "    #//*** Initialize the output dataframe\n",
    "    output_df = pd.DataFrame()\n",
    "\n",
    "    #//*** Process each row of the input dataframe (or processing in this case)\n",
    "    for row in processing_df.iterrows():\n",
    "\n",
    "        #//*** Each Row\n",
    "        loop_row = row[1]\n",
    "\n",
    "\n",
    "        #//*** Square the results to remove negative values\n",
    "        loop_row[4:] = loop_row[4:]**2\n",
    "        \n",
    "        #//*** Avoid Divide by Zero issues\n",
    "        if loop_row[4:].sum() > 0:\n",
    "            #//*** Divide by the sum to get relative percentages\n",
    "            loop_row[4:] = loop_row[4:]/loop_row[4:].sum()\n",
    "        \n",
    "        #//*** Multiply by the total to get the weighted percentage of racial values\n",
    "        loop_row[4:] = loop_row[4:]*loop_row['total']\n",
    "        \n",
    "        #//*** Add the row to the output_df\n",
    "        output_df = pd.concat([output_df,pd.DataFrame(loop_row).transpose()])\n",
    "\n",
    "    #//*** Reindex with an integer. Keeps it clean\n",
    "    output_df.index = np.arange(0,len(output_df))\n",
    "    \n",
    "    #//*** Zero, values generate Divide by Zero NaNs. Replace these with Zero\n",
    "    output_df = output_df.fillna(0)\n",
    "\n",
    "    print(f'Racial Percentages Calculated: {round(time.time()-start_time,0)}s')\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the biased coefficients and derive the racial percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//************************************************************************************************************************************************************************\n",
    "#//*** Calculate the coefficients for Racial data for each county day.\n",
    "#//*** This uses LinearRegression to generate coefficients which are weighted with the county cases of the day.\n",
    "#//*** Coefficients derive individual counties affect on the whole of racial COVID cases. The idea is to estimate every counties given portion of the racial cases.\n",
    "#//*** Each race is modeled separately. The coefficients are converted to percentages in the following step\n",
    "#//************************************************************************************************************************************************************************\n",
    "\n",
    "\n",
    "#//*** left_df contains the broad racial categories\n",
    "left_df = ca_races_broad_df\n",
    "\n",
    "#//*** Right df contains each county as a column, with one value aggregated. Such as raw COVID cases.\n",
    "right_df = ca_cases_broad_df\n",
    "\n",
    "#//*** County Columns start at Index 3.\n",
    "#//*** These values are a little unintuitive, since they are releveant during the function operation. They are used to indicate which columns are used via the first elements index position\n",
    "x_col_index = 3\n",
    "\n",
    "#//*** Target Independent Column Index. Statewide race numbers begin at column 1\n",
    "#//*** These values are a little unintuitive. They are used to indicate which columns are used via the first elements index position\n",
    "y_col_index = 1\n",
    "\n",
    "\n",
    "processing_df = calculate_coefficients_v2(left_df,right_df,x_col_index,y_col_index)\n",
    "\n",
    "#//**** County Column index start\n",
    "x_col_index = 4\n",
    "\n",
    "#//*** Convert coefficients to percentages,\n",
    "\n",
    "print(\"BEGIN PERCENT\")\n",
    "ca_case_race_total_df =coef_to_percent(processing_df,x_col_index)\n",
    "\n",
    "print(ca_case_race_total_df)\n",
    "if 'ca_case_race_total_df' not in df_list:\n",
    "    df_list.append('ca_case_race_total_df')\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model again but using the unbiased transform for reference\n",
    "\n",
    "this is the no_transform_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#//*** Get Sample model without using power transform\n",
    "\n",
    "\n",
    "#//************************************************************************************************************************************************************************\n",
    "#//*** Calculate the coefficients for Racial data for each county day.\n",
    "#//*** This uses LinearRegression to generate coefficients which are weighted with the county cases of the day.\n",
    "#//*** Coefficients derive individual counties affect on the whole of racial COVID cases. The idea is to estimate every counties given portion of the racial cases.\n",
    "#//*** Each race is modeled separately. The coefficients are converted to percentages in the following step\n",
    "#//************************************************************************************************************************************************************************\n",
    "\n",
    "\n",
    "#//*** left_df contains the broad racial categories\n",
    "left_df = ca_races_broad_df\n",
    "\n",
    "#//*** Right df contains each county as a column, with one value aggregated. Such as raw COVID cases.\n",
    "right_df = ca_cases_broad_df\n",
    "\n",
    "#//*** County Columns start at Index 3.\n",
    "#//*** These values are a little unintuitive, since they are releveant during the function operation. They are used to indicate which columns are used via the first elements index position\n",
    "x_col_index = 3\n",
    "\n",
    "#//*** Target Independent Column Index. Statewide race numbers begin at column 1\n",
    "#//*** These values are a little unintuitive. They are used to indicate which columns are used via the first elements index position\n",
    "y_col_index = 1\n",
    "\n",
    "\n",
    "processing_df = calculate_coefficients(left_df,right_df,x_col_index,y_col_index)\n",
    "\n",
    "#//**** County Column index start\n",
    "x_col_index = 4\n",
    "\n",
    "#//*** Convert coefficients to percentages,\n",
    "\n",
    "print(\"BEGIN PERCENT\")\n",
    "no_transform_df =coef_to_percent(processing_df,x_col_index)\n",
    "\n",
    "print(ca_case_race_total_df)\n",
    "if 'ca_case_race_total_df' not in df_list:\n",
    "    df_list.append('ca_case_race_total_df')\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#//***************************************************************************************************************************************************************************\n",
    "#//*** Generatate a Individual Race Coeffecients for each county per day.\n",
    "#//*** The the sum of racial coefficients should equal the state coefficent for the county. \n",
    "#//*** Build the coefficients for the entire data set. Each day will calculate the coefficients from the previous 30 days. The First 30 days will use one set of coeffients. The rest will use\n",
    "#//*** The current day: -30 to generate the coefficients. This will be an overfitted solution which is exactly what we are going for.\n",
    "#//***************************************************************************************************************************************************************************\n",
    "def calculate_coefficients_v2(left_df, right_df, x_col_index, y_col_index):\n",
    "    print(\"Calculating racial coefficients...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #//*** Initialize the output dataframe\n",
    "    output_df = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #//*** Combining with car_race_df and Latino value. It's not strictly needed, but the additional column will make combining the dataframes later, easier.\n",
    "    #//*** Reusing Code: This loop only needs to run once\n",
    "    for race in left_df.columns[1:]:\n",
    "\n",
    "        #//*** Build model for the first 30 days, combines the race from ca_race (which is only needed as an extra field, to evenly space the columms)\n",
    "        model_df = left_df[['date',race]].merge(right_df, left_on='date', right_on='date')\n",
    "        \n",
    "        loop_df = model_df.copy()\n",
    "        \n",
    "        #print(model_df)\n",
    "        #//*************************\n",
    "        #//*** BEGIN regression\n",
    "        #//*************************\n",
    "\n",
    "\n",
    "        #//**** Build the x Values - Dependent Variables. These will be all the counties which start at the column index \n",
    "        #//*** The X Value is the index where the attributes start, there are 58 of them :)\n",
    "        #x_column = model_df.columns[x_col_index:]\n",
    "\n",
    "        #//*** Generate ordered list of Counties by current race population.\n",
    "        #//*** The assumptions is the counties with higher populations will exert a greater weight on the model.\n",
    "        #//*** Otherwise the tiny county of Alpine gets way overly represented\n",
    "        race_columns = list(pop_attrib_df[['county',race]].sort_values(race,ascending=False)['county'])\n",
    "        \n",
    "        for index in range(0,len(race_columns)):\n",
    "            loop_cols = (race_columns[index:] + race_columns[:index])\n",
    "            \n",
    "            #print(model_df[race_columns])\n",
    "            #//*** Build the X attributes using the x_column. These are separated for readability and modularity\n",
    "            x_model = model_df[loop_cols]\n",
    "            \n",
    "            #//*** Build the independent variable using the Index Column defined above as y_col_index.\n",
    "            y_column = model_df.columns[y_col_index]\n",
    "\n",
    "            #//*** Build the Y model using the y_column attribute. This is less readable and intuitive, but it lets the columns be \n",
    "            #//*** easily assigned at the top of this section\n",
    "            y_model = model_df[y_column]\n",
    "\n",
    "            #//*** Define the Linear Model\n",
    "            regr = linear_model.LinearRegression(n_jobs=-1)\n",
    "\n",
    "            #//*** Make Regression Magic\n",
    "            regr.fit(x_model, y_model)\n",
    "\n",
    "            #//*** Apply the regression coefficients\n",
    "            #//*** v1 Change: Apply coef to actual values\n",
    "            model_df[loop_cols] = (model_df[race_columns])*regr.coef_\n",
    "            \n",
    "            #//*** Only keep the coef_ for the first county\n",
    "            loop_df[loop_cols[0]] = model_df[loop_cols[0]]\n",
    "        #print(loop_df)\n",
    "        #break\n",
    "\n",
    "        \n",
    "        #print(x_model)\n",
    "        \n",
    "        \n",
    "        #//*** Dead End: v2 Change: Try just the coefficients \n",
    "        #model_df[race_columns] = regr.coef_\n",
    "\n",
    "\n",
    "\n",
    "        #//*** Replace the Statewide Total Column. With the Statewide Race Totals\n",
    "        loop_df['total'] = loop_df[race]\n",
    "\n",
    "        #//*** Change The race column to hold the race name\n",
    "        loop_df[race] = race\n",
    "\n",
    "        #//*** Rename the race (Latino, Native, etc) to 'race'\n",
    "        cols = list(loop_df.columns)\n",
    "        cols[1] = 'race'\n",
    "        loop_df.columns = cols\n",
    "\n",
    "        loop_df['intercept'] = regr.intercept_\n",
    "\n",
    "        #//*** Move intercept to be the column after Total\n",
    "        #//*** Gets Columns as a list, removes intercept of end and inserts into position\n",
    "        #//*** Model_df is saved with ordered list of columns.\n",
    "        #//*** Kinda Cool\n",
    "        loop_df = loop_df[ list(loop_df.columns[:-1].insert(3,'intercept')) ]\n",
    "\n",
    "        #//*** Reorder Counties\n",
    "        #//*** Keep the First four Columns, then use ordered_counties\n",
    "        loop_df = loop_df[list(loop_df.columns[:4])+ordered_counties]\n",
    "\n",
    "        #print(model_df)\n",
    "        #//*** Add the First 30 days Model to the output_df dataframe\n",
    "        output_df = pd.concat([output_df,loop_df])\n",
    "\n",
    "        #//*** Checking our work. The sum of the coefficients * cases + intercept should be close the independent value in Total Cases.\n",
    "        print(\"Checking our Work. These values should be close:\")\n",
    "        print(model_df.iloc[1]['total'], \" == \", model_df[race_columns].iloc[1].sum()+regr.intercept_)    \n",
    "\n",
    "        #print(output_df)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    print(f\"CoEfficients Calculated: {round(time.time()-start_time,0)}s\")\n",
    "    return output_df\n",
    "\n",
    "\n",
    "#//************************************************************************************************************************************************************************\n",
    "#//*** Calculate the coefficients for Racial data for each county day.\n",
    "#//*** This uses LinearRegression to generate coefficients which are weighted with the county cases of the day.\n",
    "#//*** Coefficients derive individual counties affect on the whole of racial COVID cases. The idea is to estimate every counties given portion of the racial cases.\n",
    "#//*** Each race is modeled separately. The coefficients are converted to percentages in the following step\n",
    "#//************************************************************************************************************************************************************************\n",
    "\n",
    "\n",
    "#//*** left_df contains the broad racial categories\n",
    "left_df = ca_races_broad_df\n",
    "\n",
    "#//*** Right df contains each county as a column, with one value aggregated. Such as raw COVID cases.\n",
    "right_df = ca_cases_broad_df\n",
    "\n",
    "#//*** County Columns start at Index 3.\n",
    "#//*** These values are a little unintuitive, since they are releveant during the function operation. They are used to indicate which columns are used via the first elements index position\n",
    "x_col_index = 3\n",
    "\n",
    "#//*** Target Independent Column Index. Statewide race numbers begin at column 1\n",
    "#//*** These values are a little unintuitive. They are used to indicate which columns are used via the first elements index position\n",
    "y_col_index = 1\n",
    "\n",
    "\n",
    "processing_df = calculate_coefficients_v2(left_df,right_df,x_col_index,y_col_index)\n",
    "\n",
    "#//**** County Column index start\n",
    "x_col_index = 4\n",
    "\n",
    "#//*** Convert coefficients to percentages,\n",
    "\n",
    "print(\"BEGIN PERCENT\")\n",
    "v2_ca_case_race_total_df =coef_to_percent(processing_df,x_col_index)\n",
    "\n",
    "\n",
    "print(v2_ca_case_race_total_df)\n",
    "if 'v2_ca_case_race_total_df' not in df_list:\n",
    "    df_list.append('v2_ca_case_race_total_df')\n",
    "\n",
    "print(\"Done\")\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to check our work. The summed racial totals should equal the summed COVID cases for Imperial county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//*** Checking our work. These numbers should be close. Predicted values are converted to integers so there will be no 'partial' cases. If modeled a\n",
    "\n",
    "\n",
    "t_date = ca_case_race_total_df.iloc[random.randint(0,len(ca_case_race_total_df))]['date']\n",
    "t_total = ca_case_race_total_df[ca_case_race_total_df['date']==t_date]['total']\n",
    "#print(t_date, \" \" , t_total)\n",
    "#print(ca_case_race_total_df.iloc[250][4:].sum())\n",
    "\n",
    "#print(ca_case_race_total_df.iloc[250])\n",
    "print(t_date)\n",
    "tdf1 = ca_cases_broad_df[ca_cases_broad_df['date']== t_date]\n",
    "print(tdf1[tdf1.columns[2:]].transpose().sum())\n",
    "print(\"===================\")\n",
    "print(ca_case_race_total_df[ca_case_race_total_df['date']==t_date].iloc[3][2])\n",
    "print(ca_case_race_total_df[ca_case_race_total_df['date']==t_date].iloc[3][4:].sum())\n",
    "print(\"===================\")\n",
    "print(tdf1)\n",
    "print(\"===================\")\n",
    "print(\"Imperial Broad: \",tdf1['Imperial'].values[0])\n",
    "print(\"Imperial Race:  \", ca_case_race_total_df[ca_case_race_total_df['date']==t_date]['Imperial'].sum())\n",
    "print(\"Race Total   :  \", ca_case_race_total_df[ca_case_race_total_df['date']==t_date]['total'].sum())\n",
    "print(\"===================\")\n",
    "print(\"Total COVID cases by Race on this day: \",ca_races_broad_df[ca_races_broad_df['date']==t_date].transpose()[1:].sum().values[0])\n",
    "print(\"Total COVID cases by County:           \",tdf1['total'].values[0])\n",
    "\n",
    "\n",
    "\n",
    "del t_date\n",
    "del tdf1\n",
    "del t_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skipping my original rescaling solution which was to multiply each county by it's missing values. This step is not needed when scaling the values before they are applied to the model.\n",
    "\n",
    "This was added last. Instead of changing code, I copied ca_case_race_total_df to modified_race_total to keep all the graphs working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "modified_race_total = ca_case_race_total_df.copy()\n",
    "redistrib = 0\n",
    "for county in ordered_counties:\n",
    "    #//*** Get the Actual Summed Totals of cases for the Counties \n",
    "    actual = ca_cases_broad_df[county].sum()\n",
    "    \n",
    "    modeled = modified_race_total[county].sum()\n",
    "    if modeled > actual:\n",
    "        #//*** Modeled is Bigger, need to redistribute the overage\n",
    "        print(actual/modeled)\n",
    "        redistrib = modified_race_total[county].sum()\n",
    "        print(\"Redistrib: \",redistrib)\n",
    "        modified_race_total[county] = modified_race_total[county]*(actual/modeled)\n",
    "    else:\n",
    "        county_target =  modified_race_total[county].sum()/(modeled/actual)\n",
    "        redistrib -=  county_target\n",
    "        #print(actual,\"-\",int(modeled),\" Under: \", modeled/actual, \" \", county, \" \", county_target, \" == \", modified_race_total[county].sum()/(modeled/actual),\" -- \",int(redistrib))\n",
    "        modified_race_total[county] = modified_race_total[county]/(modeled/actual)\n",
    "    #print(actual, \" / \",modeled)\n",
    "\"\"\"\n",
    "print()\n",
    "modified_race_total = ca_case_race_total_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section checks the accuracy of the model for each county. It's OK. Given more time I can improve the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//*** The Rescaled numbers match. But it's kind of hokum\n",
    "#//*** Compare the Modeled County Totals to the Actual Totals. \n",
    "for county in ordered_counties:\n",
    "    #print(county, \" Actual: \",ca_cases_broad_df[county].sum(), \" - Modeled: \",ca_case_race_total_df[county].sum()   )\n",
    "    print(\"A: \",ca_cases_broad_df[county].sum(), \" - M: \",round(modified_race_total[county].sum(),0), \" \", county   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the COVID distribution between the Unbiased model, the Biased model and the actual cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(ca_cases_broad_df[ordered_counties].sum())\n",
    "display_size=15\n",
    "bottom = -1\n",
    "\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(display_size,display_size/2))\n",
    "\n",
    "    \n",
    "ax.bar(no_transform_df[ordered_counties].sum().index,no_transform_df[ordered_counties].sum())\n",
    "        \n",
    "plt.xticks(rotation=90,fontsize=display_size*.8)\n",
    "plt.yticks(fontsize=display_size)\n",
    "\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "\n",
    "plt.title(f\"Raw Model Distribution\",fontsize=display_size)\n",
    "plt.show()\n",
    "\n",
    "graph_df = ca_case_race_total_df.copy()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(display_size,display_size/2))\n",
    "\n",
    "    \n",
    "ax.bar(graph_df[ordered_counties].sum().index,graph_df[ordered_counties].sum())\n",
    "        \n",
    "plt.xticks(rotation=90,fontsize=display_size*.8)\n",
    "plt.yticks(fontsize=display_size)\n",
    "\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "\n",
    "plt.title(f\"Transformed Modeled Distribution\",fontsize=display_size)\n",
    "plt.show()\n",
    "#del graph_df\n",
    "\n",
    "graph_df = ca_cases_broad_df.copy()\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(display_size,display_size/2))\n",
    "\n",
    "ax.bar(graph_df[ordered_counties].sum().index,graph_df[ordered_counties].sum())\n",
    "    \n",
    "#    bottom += graph_df[graph_df.columns[x]]\n",
    "\n",
    "#//*** Draw horizontal line. Draw it twice to get the yellow and back effect. \n",
    "#//*** This technique looks viusually good, but I can't get the legend to draw approrpriately.\n",
    "#ax.axhline(state_100k,color = \"black\", label=\"Statewide Cases 100k\", linestyle = \"-\", lw=2)\n",
    "#ax.axhline(state_100k,color = \"yellow\", linestyle = \"--\", lw=2)\n",
    "        \n",
    "plt.xticks(rotation=90,fontsize=display_size*.8)\n",
    "plt.yticks(fontsize=display_size)\n",
    "\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "\n",
    "#plt.legend(fontsize=display_size*.5)\n",
    "plt.title(f\"Actual COVID Distribution\",fontsize=display_size)\n",
    "#plt.ylabel(\"Total Cases by County (per 100k)\",fontsize=display_size)\n",
    "plt.show()\n",
    "\n",
    "del graph_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#//*** This is the modeled county Data (such as it is) I'm working on a visualization for this\n",
    "\n",
    "\n",
    "#//*** Set Display to 5 significant figures globally\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "for group in modified_race_total.groupby('race'):\n",
    "    x_column = modified_race_total.columns[4:]\n",
    "    print(group[0])\n",
    "    #print(group[1])\n",
    "    loop_series = group[1][x_column].sum().sort_values(ascending=False)\n",
    "    \n",
    "    loop_df = pd.DataFrame(loop_series) \n",
    "    loop_df.columns = ['cases']\n",
    "    loop_df['county'] = loop_df.index\n",
    "    loop_df = loop_df.merge(pop_attrib_df,on='county')\n",
    "    \n",
    "    #loop_df['population'] = loop_df['population']/100000\n",
    "    #loop_df['percent'] = loop_df['cases'] / loop_df[group[0]]\n",
    "    loop_df['percent'] = loop_df['cases'] / (loop_df[group[0]])\n",
    "    loop_df['pop_percent'] = loop_df[group[0]]/loop_df['population']\n",
    "    \n",
    "    print(loop_df.sort_values('percent',ascending=False)[['county','cases','percent','pop_percent']])\n",
    "    print(\"====\")\n",
    "\n",
    "#//*** Reset the notation \n",
    "pd.reset_option('display.float_format')\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section looks at the differences between the modeled values and the expected COVID values based on a racial groups portion of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*********************************************************************\n",
    "#//*** Compare the Regression Model with the expected values\n",
    "#//*********************************************************************\n",
    "#//*** The expected racial values are the total COVID cases by county * racial percentage of the county\n",
    "#//*** This would mean an even distribution of cases\n",
    "#//*********************************************************************\n",
    "\n",
    "#//*** Build Statewide racial differential percentages\n",
    "\n",
    "ca_race_diff = pd.DataFrame()\n",
    "\n",
    "#ca_race_diff['date'] = ca_total_df['date'].copy()\n",
    "ca_race_diff['date'] = ca_cases_broad_df['date'].copy()\n",
    "\n",
    "#print(ca_race_diff)\n",
    "\n",
    "for race in ca_race_df['race'].unique():\n",
    "\n",
    "    race_percent = pop_attrib_df[race].sum() / pop_attrib_df['population'].sum()\n",
    "    #/  ca_total_df['cases']*race_percent\n",
    "    #//**** actual Value\n",
    "    \n",
    "    #//*** Avoid Divide by 0 warrnings. Convert Zeros to 1\n",
    "    actual = ca_race_df[ca_race_df['race']==race]['cases'].replace(0,1)\n",
    "#    expected = ca_total_df['cases']*race_percent\n",
    "    expected = ca_cases_broad_df['total']*race_percent\n",
    "    \n",
    "    #print(expected)\n",
    "    \n",
    "    #ca_race_diff['actual'] = actual.values\n",
    "    #ca_race_diff['expected'] = expected.values\n",
    "    ca_race_diff[race] = ( actual.values - expected.values ) / actual.values\n",
    "    \n",
    "    #print(pd.DataFrame([actual,expected]))\n",
    "    #ax.plot(ca_race_df['date'].unique(),ca_race_df[ca_race_df['race']==race]['cases'].rolling(5).mean(),label='actual')\n",
    "    #ax.plot(ca_race_df['date'].unique(),ca_total_df['cases'].rolling(5).mean()*race_percent,label='expected')\n",
    "#ca_race_diff['Native'] = ca_race_diff['Native'].replace(np.inf,0)\n",
    "ca_race_diff.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "#//*** Replace 1 with Zero. These were Zero value before. Avoids Divide by Zero issues.\n",
    "ca_race_diff.replace(1, 0, inplace=True)\n",
    "ca_race_diff = ca_race_diff.fillna(0)\n",
    "\n",
    "#//***********************************************************************************************************************\n",
    "#//*** Build the Model for all Counties.\n",
    "#//***********************************************************************************************************************\n",
    "#//*** Model takes the daily cases, and estimates the racial cases based on the portion of the population.\n",
    "#//*** Example: 100 cases and Latino is .55. Latinos would be assigned 55 cases.\n",
    "#//***********************************************************************************************************************\n",
    "#//*** The expected racial value is adjusted by the statewide racial percentage\n",
    "#//*** Example: If Latinos comprised .25 of the total State Cases, The modeled Latino cases would be 68.75 (55 *.25)\n",
    "#//***********************************************************************************************************************\n",
    "\n",
    "#//*** Build a dataframe to hold the expected cases\n",
    "ca_covid_est_case_df = ca_covid_df.copy()\n",
    "\n",
    "\n",
    "#//*** Process each race\n",
    "for race in ca_race_df['race'].unique():\n",
    "    #ca_covid_est_case_df[race] =  ( (ca_covid_est_case_df[race] / ca_covid_est_case_df['population'])*ca_covid_est_case_df['cases'] ) + ( ( (ca_covid_est_case_df[race] / loop_df['population'])*ca_covid_est_case_df['cases'] ) * ca_race_diff[race].values )\n",
    "    \n",
    "    #//*** Build the racial population percentage for each county\n",
    "    #//*** Racial Population / total Population = County racial portion\n",
    "    ca_covid_est_case_df[race] = (ca_covid_est_case_df[race] / ca_covid_est_case_df['population']) \n",
    "    \n",
    "    #//*** Build the Expected COVID cases based on population percentage\n",
    "    #//*** Case_[race] columns. County COVID cases * Racial portion \n",
    "    ca_covid_est_case_df[f'case_{race}'] = ca_covid_est_case_df[race] * ca_covid_est_case_df['cases']\n",
    "    \n",
    "\n",
    "#//*** Build model Dataframe. This holds the adjusted cases\n",
    "#//*** This workflow is awkward because I\"m building it for each date. I can probably do this better by merging the ca_race_diff dataframe.\n",
    "ca_model_cases_df = pd.DataFrame()\n",
    "\n",
    "#//*** Process each Date \n",
    "for group in ca_covid_est_case_df.groupby('date'):\n",
    "    loop_date = group[0]\n",
    "    loop_df = group[1].copy()\n",
    "    \n",
    "    #//*** Get the race differential values on the given date\n",
    "    loop_race_diff = ca_race_diff[ ca_race_diff['date']==loop_date] \n",
    "    \n",
    "    #//*** Process the race data for each racial attribute.\n",
    "    #//*** Each loop processes a racial attribute and adds an adjusted_[race] value.\n",
    "    for race in ca_race_df['race'].unique():\n",
    "        #//*** Get the modifier that race on the given day\n",
    "        race_modifier = loop_race_diff[race].values[0]\n",
    "        \n",
    "        #//*** expected value + (expected value * modifier)\n",
    "        #//*** Modifier can be positive or negative.\n",
    "        loop_df[f'adj_{race}'] =  loop_df[f'case_{race}'].values + (loop_df[f'case_{race}'].values * race_modifier) \n",
    "    \n",
    "    #//*** Add the results into ca_model_cases_df. Awkward an inefficient.\n",
    "    ca_model_cases_df = pd.concat([ ca_model_cases_df, loop_df ] ) \n",
    "    \n",
    "\n",
    "#//*** Temp variable cleanup\n",
    "del loop_df\n",
    "del loop_date\n",
    "del loop_race_diff\n",
    "del race_modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Get the Statewide 100k value. \n",
    "#//*** Get total Case Count from orig_df, dvided by total population / 100000\n",
    "state_100k = ca_covid_orig_df['cases'].sum()/(ca_covid_orig_df['population'].unique().sum()/100000)\n",
    "\n",
    "county_list = ca_100k_df['county'].unique()\n",
    "\n",
    "county_100k = []\n",
    "\n",
    "for county in county_list:\n",
    "    #if ca_100k_df[ca_100k_df['county']==county].iloc[0]['population'] > 1:\n",
    "    county_100k.append(county)\n",
    "case_totals = []\n",
    "\n",
    "for county in county_100k:\n",
    "    case_totals.append(ca_100k_df[ca_100k_df['county']==county]['cases'].sum())\n",
    "\n",
    "#//*** Temp Series\n",
    "ts = pd.Series(index = county_100k, data=case_totals).sort_values(ascending=False)\n",
    "\n",
    "#print(ts)\n",
    "\n",
    "high_covid_counties = list(ts[ts > state_100k].index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the correlation between the modeled and the expected values. Not quite sure if this is helpful. If the model reflected the expected values, then this wouldn't detect racial disparities. It's interesting, but unsure if it's good information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//*** Build correlation table. How does the correlation compare between the modeled and Expected Values?\n",
    "#//*** Result: Unsure. Probably not helpful\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "county = 'Los Angeles'\n",
    "loop_dict = {}\n",
    "\n",
    "for county in ca_100k_df['county'].unique():   \n",
    "    #//*** Compare the expected vs scaled modeled values\n",
    "    expected_la = ca_model_cases_df[ca_model_cases_df['county']== county]\n",
    "    \n",
    "    modeled_la = modified_race_total[['date','race',county]]\n",
    "    #modeled_la = ca_case_race_total_df[['date','race',county]]\n",
    "    for race in modeled_la['race'].unique():\n",
    "        loop_model_race = modeled_la[modeled_la['race']==race]\n",
    "#\n",
    "        loop_model_expected = expected_la[['date','county',race,f\"case_{race}\",f\"adj_{race}\",\"cases\"]]\n",
    "        #print(loop_model_race)\n",
    "        #print(loop_model_expected)\n",
    "        corr,_ = pearsonr(loop_model_race[county],loop_model_expected['cases'])\n",
    "        #print(\"Correlation: \", county, \" \",race, \" \",corr)\n",
    "        \n",
    "        if county not in loop_dict.keys():\n",
    "            loop_dict[county] = {}\n",
    "            \n",
    "        loop_dict[county][race] = (corr)\n",
    "cors_df = pd.DataFrame(loop_dict)\n",
    "cor_index = list(cors_df.index)\n",
    "cor_col = list(cors_df.columns)\n",
    "cors_df = cors_df.append(cors_df.sum(),ignore_index=True)\n",
    "cors_df.index = [cor_index + ['total']]\n",
    "cors_df = cors_df.transpose()\n",
    "cors_df['county'] = cors_df.index\n",
    "cors_df.index=range(0,len(cors_df))\n",
    "cors_df.columns = ['Native','Asian','Black','Latino','Multiracial', 'Hawaiian','White','total','county']\n",
    "cors_df = cors_df.sort_values('total',ascending=False)\n",
    "print(\"===============================================\")\n",
    "print(\"Correlation between Expected and Modeled Values\")\n",
    "print(\"===============================================\")\n",
    "print(cors_df)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build modeled population percentages. These are the modeled racial portion of the population. For Example: The model suggests 62% of All Latinos in Los Angeles were COVID-19 positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd_dict = {}\n",
    "\n",
    "input_df=modified_race_total\n",
    "\n",
    "\n",
    "\n",
    "for group in input_df.groupby('race'):\n",
    "\n",
    "    #//*** Initialize Race as a key\n",
    "    pd_dict[group[0]] ={}\n",
    "\n",
    "    #//*** Add the values for each county\n",
    "    for county in group[1].columns[4:]:\n",
    "        \n",
    "        #//*** Assign the total to [race] [county]\n",
    "        pd_dict[group[0]][county] = group[1][county].sum()\n",
    "    \n",
    "\n",
    "#//*** Let's build cumulative Racial Totals\n",
    "#print(modified_race_total)\n",
    "\n",
    "#//*** Convert to data frame\n",
    "modeled_total_counts_df = pd.DataFrame(pd_dict).transpose()\n",
    "\n",
    "#//*** Build a new Dataframe to hold the percentages\n",
    "modeled_percents_df = modeled_total_counts_df.copy()\n",
    "\n",
    "for county in modeled_percents_df.columns:\n",
    "    \n",
    "    modeled_percents_df[county] = modeled_percents_df[county] / modeled_percents_df[county].sum()\n",
    "    \n",
    "\n",
    "#print(modeled_percents_df.transpose().sort_values(\"Latino\",ascending=False))\n",
    "\n",
    "#modeled_percents_df = modeled_percents_df.sort_values(\"Los Angeles\",ascending=False).transpose().sort_values(\"Latino\",ascending=False)\n",
    "modeled_percents_df = modeled_percents_df.sort_values(\"Los Angeles\",ascending=False).transpose()\n",
    "\n",
    "print(modeled_percents_df)\n",
    "#//*** Temp variable cleanup\n",
    "del pd_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a dataframe with the actual population percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Build the Racial percentages for each county\n",
    "pop_percent_df = pop_attrib_df.copy()\n",
    "\n",
    "#//*** Divide each race column by the population to get percentage\n",
    "for col in pop_percent_df.columns[2:]:\n",
    "    pop_percent_df[col] = pop_percent_df[col]/pop_percent_df['population'] \n",
    "\n",
    "#//*** Set index to county\n",
    "pop_percent_df.index=pop_percent_df['county']\n",
    "#//*** Delete county column\n",
    "del pop_percent_df['county']\n",
    "\n",
    "del pop_percent_df['population']\n",
    "\n",
    "#//*** Set index to modeled_percents_df.index. This aligns the county values.\n",
    "pop_percent_df = pop_percent_df.reindex(modeled_percents_df.index)\n",
    "\n",
    "#//*** Align Columns with Modeled Percents for consistent looping\n",
    "pop_percent_df = pop_percent_df[list(modeled_percents_df.columns)]\n",
    "\n",
    "print(pop_percent_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Assigns a color from a palette list to a county. \n",
    "def assign_color(input_item, input_cd,input_palette):\n",
    "    #//*** Check if item already exists, if so, return input_cd\n",
    "    if input_item in input_cd.keys():\n",
    "        return input_cd\n",
    "    \n",
    "    #//*** input_item needs a Color. Walk down the input_palette till one is not found\n",
    "    for color in input_palette:\n",
    "        if color not in input_cd.values():\n",
    "            input_cd[input_item] = color\n",
    "            return input_cd\n",
    "    print(\"UH OH ran out of colors!!!\")\n",
    "    print(f\"Item: {input_item}\")\n",
    "    print(input_cd)\n",
    "    return input_cd\n",
    "\n",
    "#//*** Color Choices: Tucking these aside for later use\n",
    "#//*** Combine these with a dictionary to create color continuity across multiple visualizations.\n",
    "color_palette = [\"#c6eaff\",\"#caa669\",\"#14bae2\",\"#f7cd89\",\"#98a9e7\",\"#e2ffb7\",\"#cb9ec2\",\"#77dcb5\",\"#ffc5b7\",\"#40bdba\",\"#fff4b0\",\"#74d0ff\",\"#e4da8d\",\"#7ceeff\",\"#d0e195\",\"#b7ab8c\",\"#fcffdb\",\"#83b88d\",\"#ffe2c0\",\"#abc37a\"]\n",
    "color_palette = [\"#557788\",\"#e12925\",\"#44af0e\",\"#7834c0\",\"#726d00\",\"#130c6d\",\"#004e12\",\"#f7007d\",\"#017878\",\"#950089\",\"#00a3d7\",\"#4b000e\",\"#0063c2\",\"#f07478\",\"#013b75\",\"#cf81b8\",\"#212238\",\"#af87e7\",\"#320f49\",\"#9c91db\"]\n",
    "county_color_palette = [\"#b4a23b\",\"#4457ca\",\"#9ec535\",\"#a651cb\",\"#59ce59\",\"#6a77f0\",\"#52a325\",\"#b93d9b\",\"#36b25c\",\"#e374d4\",\"#c1c035\",\"#7452af\",\"#96ae3a\",\"#a484e2\",\"#89c466\",\"#e54790\",\"#57c888\",\"#dd3d60\",\"#5bd6c4\",\"#dd4e2d\",\"#45ccdf\",\"#bd3738\",\"#4cb998\",\"#b13a6c\",\"#368433\",\"#588feb\",\"#dcad3d\",\"#4763af\",\"#e49132\",\"#4aa5d4\",\"#c86321\",\"#7695d3\",\"#769233\",\"#925898\",\"#54701c\",\"#c893d6\",\"#3d7b44\",\"#e084ac\",\"#65a76b\",\"#965179\",\"#296437\",\"#e57f5f\",\"#31a8ad\",\"#a44b2c\",\"#368d71\",\"#df7f81\",\"#226a4d\",\"#96465f\",\"#b5b671\",\"#68649c\",\"#ad772e\",\"#a34f52\",\"#758348\",\"#d8a06e\",\"#505e25\",\"#8e5e31\",\"#8e8033\",\"#695f1b\"]\n",
    "county_color_palette = [\"#96465f\",\"#dd3d60\",\"#df7f81\",\"#a34f52\",\"#bd3738\",\"#dd4e2d\",\"#e57f5f\",\"#a44b2c\",\"#c86321\",\"#8e5e31\",\"#d8a06e\",\"#e49132\",\"#ad772e\",\"#dcad3d\",\"#b4a23b\",\"#8e8033\",\"#695f1b\",\"#c1c035\",\"#b5b671\",\"#96ae3a\",\"#505e25\",\"#758348\",\"#9ec535\",\"#769233\",\"#54701c\",\"#52a325\",\"#89c466\",\"#368433\",\"#59ce59\",\"#3d7b44\",\"#65a76b\",\"#296437\",\"#36b25c\",\"#57c888\",\"#226a4d\",\"#368d71\",\"#4cb998\",\"#5bd6c4\",\"#31a8ad\",\"#45ccdf\",\"#4aa5d4\",\"#7695d3\",\"#588feb\",\"#4763af\",\"#6a77f0\",\"#4457ca\",\"#68649c\",\"#a484e2\",\"#7452af\",\"#a651cb\",\"#c893d6\",\"#925898\",\"#e374d4\",\"#b93d9b\",\"#965179\",\"#e084ac\",\"#e54790\",\"#b13a6c\"]\n",
    "county_color_palette = [\"#226a4d\",\"#31a8ad\",\"#68649c\",\"#758348\",\"#505e25\",\"#368d71\",\"#4aa5d4\",\"#965179\",\"#7695d3\",\"#45ccdf\",\"#296437\",\"#96465f\",\"#8e5e31\",\"#b5b671\",\"#d8a06e\",\"#a34f52\",\"#5bd6c4\",\"#695f1b\",\"#4cb998\",\"#df7f81\",\"#3d7b44\",\"#e084ac\",\"#c893d6\",\"#65a76b\",\"#8e8033\",\"#925898\",\"#4763af\",\"#54701c\",\"#ad772e\",\"#a44b2c\",\"#e57f5f\",\"#769233\",\"#57c888\",\"#b13a6c\",\"#588feb\",\"#a484e2\",\"#b4a23b\",\"#368433\",\"#89c466\",\"#7452af\",\"#96ae3a\",\"#dcad3d\",\"#bd3738\",\"#36b25c\",\"#e374d4\",\"#c86321\",\"#b93d9b\",\"#e49132\",\"#dd3d60\",\"#e54790\",\"#c1c035\",\"#4457ca\",\"#6a77f0\",\"#52a325\",\"#9ec535\",\"#dd4e2d\",\"#a651cb\",\"#59ce59\"]\n",
    "color_palette = [\"#e0472b\",\"#ffac4b\",\"#469100\",\"#02c1d7\",\"#66acff\",\"#906fee\",\"#fcaee0\"]\n",
    "race_color = {}\n",
    "\n",
    "for race in pop_percent_df.columns:\n",
    "    race_color = assign_color(race,race_color,color_palette)\n",
    "    \n",
    "print(race_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First attempt at displaying racial distributions across the state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_size = 40\n",
    "\n",
    "graph_df = modeled_percents_df.copy()\n",
    "\n",
    "bottom = -1\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(display_size,display_size/2))\n",
    "\n",
    "ax.bar(graph_df.index,graph_df[graph_df.columns[0]],label=graph_df.columns[0])\n",
    "\n",
    "bottom = graph_df[graph_df.columns[0]]\n",
    "\n",
    "for x in range(1, (len(graph_df.columns))):\n",
    "    \n",
    "    ax.bar(graph_df.index,graph_df[graph_df.columns[x]],bottom=bottom,label=graph_df.columns[x])\n",
    "    \n",
    "    \n",
    "    bottom += graph_df[graph_df.columns[x]]\n",
    "\n",
    "#//*** Draw horizontal line. Draw it twice to get the yellow and back effect. \n",
    "#//*** This technique looks viusually good, but I can't get the legend to draw approrpriately.\n",
    "#ax.axhline(state_100k,color = \"black\", label=\"Statewide Cases 100k\", linestyle = \"-\", lw=2)\n",
    "#ax.axhline(state_100k,color = \"yellow\", linestyle = \"--\", lw=2)\n",
    "        \n",
    "plt.xticks(rotation=90,fontsize=display_size*.8)\n",
    "plt.yticks(fontsize=display_size)\n",
    "\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "\n",
    "plt.legend(fontsize=display_size*.5)\n",
    "plt.title(f\"Racial COVID Distribution by county\",fontsize=display_size)\n",
    "#plt.ylabel(\"Total Cases by County (per 100k)\",fontsize=display_size)\n",
    "plt.show()\n",
    "\n",
    "del graph_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second pass at modelin State and expected values across the state. To get the Y axis to draw correctly, I'll have to move to subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_size = 40\n",
    "\n",
    "graph_df = modeled_percents_df.copy()\n",
    "\n",
    "bottom = -1\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(display_size,display_size/2))\n",
    "\n",
    "ax.bar(graph_df.index,graph_df[graph_df.columns[0]],label=graph_df.columns[0],color=race_color[graph_df.columns[0]])\n",
    "\n",
    "ax.bar(pop_percent_df.index,pop_percent_df[graph_df.columns[0]],color='black',width=.25)\n",
    "\n",
    "#//*** Set the graph bottom  to the greater of graph_df and pop_percent_df max\n",
    "if graph_df[graph_df.columns[0]].max() > pop_percent_df[graph_df.columns[0]].max():\n",
    "    \n",
    "    bottom = graph_df[graph_df.columns[0]].max()+.05\n",
    "    \n",
    "else:\n",
    "    bottom = pop_percent_df[graph_df.columns[0]].max()+.05\n",
    "        \n",
    "\n",
    "for x in range(1, (len(graph_df.columns))):\n",
    "    \n",
    "    ax.bar(graph_df.index,graph_df[graph_df.columns[x]],bottom=bottom,label=graph_df.columns[x],color=race_color[graph_df.columns[x]])\n",
    "    ax.bar(graph_df.index,pop_percent_df[graph_df.columns[x]],color='black',bottom=bottom,width=.25)\n",
    "    \n",
    "    if graph_df[graph_df.columns[x]].max() > pop_percent_df[graph_df.columns[x]].max():\n",
    "        bottom += graph_df[graph_df.columns[x]].max()+.05\n",
    "    else:\n",
    "        bottom += pop_percent_df[graph_df.columns[x]].max()+.05\n",
    "        \n",
    "ax.bar(pop_percent_df.index,pop_percent_df[graph_df.columns[0]],label='Population',color='black',width=.25)\n",
    "    \n",
    "#//*** Draw horizontal line. Draw it twice to get the yellow and back effect. \n",
    "#//*** This technique looks viusually good, but I can't get the legend to draw approrpriately.\n",
    "#ax.axhline(state_100k,color = \"black\", label=\"Statewide Cases 100k\", linestyle = \"-\", lw=2)\n",
    "#ax.axhline(state_100k,color = \"yellow\", linestyle = \"--\", lw=2)\n",
    "        \n",
    "plt.xticks(rotation=90,fontsize=display_size*.8)\n",
    "plt.yticks(fontsize=display_size)\n",
    "\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "\n",
    "plt.legend(fontsize=display_size*.5,loc=\"upper right\")\n",
    "plt.title(f\"Racial COVID Distribution by county\",fontsize=display_size)\n",
    "#plt.ylabel(\"Total Cases by County (per 100k)\",fontsize=display_size)\n",
    "plt.show()\n",
    "\n",
    "del graph_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final attempt at using a bar chart to represent modeled cases vs expected values. This took a long time to finally generate. I'm proud of the work. I wish I figured out Geopandas before I started this though. The "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display_size = 40\n",
    "\n",
    "graph_df = modeled_percents_df.copy()\n",
    "\n",
    "#state_cases = modeled_total_counts_df.transpose().sum().sum()\n",
    "#race_percent = modeled_total_counts_df.transpose().sum().loc[this_race] / state_cases\n",
    "\n",
    "bottom = -1\n",
    "col_count = len(graph_df.columns)\n",
    "fig,axs = plt.subplots(col_count,figsize=(display_size,display_size/2),sharex=True)\n",
    "for x in range(0,col_count):\n",
    "    \n",
    "    this_race = graph_df.columns[x]\n",
    "\n",
    "    this_color = race_color[this_race]\n",
    "    this_ax = col_count-1 - x\n",
    "    axs[this_ax].bar(graph_df.index,graph_df[this_race],color=this_color,label=this_race)\n",
    "    if x == col_count-1:\n",
    "        axs[this_ax].set_title(f\"Racial COVID Distribution by county\\nModeled Cases vs Expected Cases\",fontsize=display_size)\n",
    "\n",
    "    axs[this_ax].bar(pop_percent_df.index,pop_percent_df[this_race],color='black',width=.15,label='Expected')\n",
    "    \n",
    "\n",
    "    #axs[this_ax].axhline(race_percent,color = \"white\", linestyle = \"-\", lw=2, alpha=.5)\n",
    "    #axs[this_ax].axhline(race_percent,color = \"black\", label=\"State Avg\", linestyle = \"--\", lw=2, alpha=.15)\n",
    "    \n",
    "    axs[this_ax].legend(fontsize=display_size*.3,loc=\"upper right\")\n",
    "    \n",
    "    axs[this_ax].set_ylabel(this_race)\n",
    "    axs[this_ax].yaxis.label.set_size(display_size*.5)\n",
    "    \n",
    "    #axes.xaxis.label.set_size(16)\n",
    "\n",
    "        \n",
    "plt.xticks(rotation=90,fontsize=display_size*.5)\n",
    "#plt.yticks(fontsize=display_size)\n",
    "\n",
    "#handles,labels = deduplicate_legend(ax)\n",
    "\n",
    "#plt.legend(fontsize=display_size*.5,loc=\"upper right\")\n",
    "#plt.title(f\"Racial COVID Distribution by county\",fontsize=display_size)\n",
    "#plt.ylabel(\"Total Cases by County (per 100k)\",loc=\"center\",fontsize=display_size)\n",
    "fig.text(.085, 0.5, 'Modeled Cases', va='center', rotation='vertical',fontsize=display_size)\n",
    "#fig.text(.5, -0.05, 'California Counties', va='center',fontsize=display_size)\n",
    "fig.text(.17, -0.055, '(Most Populous Counties)', va='center',fontsize=display_size *.5)\n",
    "fig.text(.265, -0.055, '---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------   (Least Populous Counties)', va='center',fontsize=display_size *.5)\n",
    "fig.text(.267, -0.055, '--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------', va='center',fontsize=display_size *.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_diff_percent = modeled_percents_df- pop_percent_df\n",
    "race_diff_percent['NAME'] = list(race_diff_percent.index)\n",
    "print(race_diff_percent.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(race_color)\n",
    "race_color_map = {}\n",
    "#//*** Build handcrafted Color Maps\n",
    "negative_colors = [\"#8C8C8C\",\"#9A9A9A\",\"#A9A9A9\",\"#B7B7B7\",\"#C6C6C6\",\"#D4D4D4\",\"#E2E2E2\",\"#F1F1F1\"]\n",
    "race_color_map['Latino'] =      ListedColormap( negative_colors + [ \"#FFFFFF\",\"#FBE8E5\",\"#F7D1CA\",\"#F3BAB0\",\"#F0A395\",\"#EC8C7B\",\"#E87560\",\"#E45E46\",\"#E0472B\"])\n",
    "race_color_map['White'] =       ListedColormap( negative_colors + [\"#FFFFFF\",\"#FFF5E9\",\"#FFEAD2\",\"#FFE0BC\",\"#FFD6A5\",\"#FFCB8F\",\"#FFC178\",\"#FFB662\",\"#FFAC4B\"])\n",
    "race_color_map['Asian'] =       ListedColormap( negative_colors + [\"#FFFFFF\",\"#E8F1DF\",\"#D1E4BF\",\"#BAD69F\",\"#A3C880\",\"#8BBA60\",\"#74AD40\",\"#5D9F20\",\"#469100\"])\n",
    "race_color_map['Black'] =       ListedColormap( negative_colors + [\"#FFFFFF\",\"#DFF7FA\",\"#C0F0F5\",\"#A0E8F0\",\"#81E0EB\",\"#61D8E6\",\"#41D1E1\",\"#22C9DC\",\"#02C1D7\"])\n",
    "race_color_map['Multiracial'] = ListedColormap( negative_colors + [\"#FFFFFF\",\"#ECF5FF\",\"#D9EAFF\",\"#C6E0FF\",\"#B3D6FF\",\"#9FCBFF\",\"#8CC1FF\",\"#79B6FF\",\"#66ACFF\"])\n",
    "race_color_map['Hawaiian'] =    ListedColormap( negative_colors + [\"#FFFFFF\",\"#F1EDFD\",\"#E3DBFB\",\"#D5C9F9\",\"#C8B7F7\",\"#BAA5F4\",\"#AC93F2\",\"#9E81F0\",\"#906FEE\"])\n",
    "race_color_map['Native'] =      ListedColormap( negative_colors + [\"#FFFFFF\",\"#FFF5FB\",\"#FEEBF7\",\"#FEE1F3\",\"#FED7F0\",\"#FDCCEC\",\"#FDC2E8\",\"#FCB8E4\",\"#FCAEE0\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://jcutrer.com/python/learn-geopandas-plotting-usmaps\n",
    "#https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "#https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d\n",
    "#https://geopandas.org/docs/user_guide/mapping.html\n",
    "\n",
    "display_size = 20\n",
    "\n",
    "#//**** Read Shape File for all 52 States\n",
    "states = geopandas.read_file('maps\\cb_2018_us_county_20m.shp')\n",
    "\n",
    "#//*** Get just the California Shapes (these are all the counties)\n",
    "#//*** A quick investigation of the dataframes revealed a STATEFP value of 06 is California\n",
    "calif_geo = states[states['STATEFP'] == \"06\"]\n",
    "\n",
    "#//*** Merge with the Race_diff_percent dataframe. These percentages are used to color the counties\n",
    "calif_geo = calif_geo.merge(race_diff_percent,on='NAME')\n",
    "\n",
    "#//*** Set Max and Min Scale for all gradients\n",
    "#//*** Fixing to the greatest and minimum values, creates a standard scale across the graphs\n",
    "vmin,vmax = calif_geo['White'].min(),calif_geo['Latino'].max()\n",
    "\n",
    "plt.rc('axes', labelsize=display_size*2)\n",
    "plt.rc('axes', titlesize=display_size*2)\n",
    "race_axis = {\n",
    "    'Latino' :   (0,0),\n",
    "    'White' :    (0,1),\n",
    "    'Asian' :    (0,2),\n",
    "    'Black' :    (0,3),\n",
    "    'Multiracial' : (1,0),\n",
    "    'Hawaiian' : (1,1),\n",
    "    'Native' :   (1,2)\n",
    "}\n",
    "fig, ax = plt.subplots(2,4, figsize=(display_size, display_size))\n",
    "\n",
    "#fig,axs = plt.subplots(col_count,figsize=(display_size,display_size/2),sharex=True)\n",
    "#axs[this_ax]\n",
    "#//*** Draw a graph for each Race\n",
    "for race in race_color_map.keys():\n",
    "    ax[race_axis[race]].axis('off')\n",
    "    ax[race_axis[race]].set_title(f\"{race}\",fontsize=display_size*.5)\n",
    "    \n",
    "    # add the colorbar to the figure\n",
    "    #//*** The Colormaps are hand coded and stored in a dictionary\n",
    "    cmap = race_color_map[race]\n",
    "    \n",
    "    \n",
    "    # Create colorbar as a legend\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "\n",
    "    # empty array for the data range\n",
    "    sm._A = []\n",
    "\n",
    "\n",
    "    cbar = fig.colorbar(sm,ax=ax[race_axis[race]],shrink=1)\n",
    "\n",
    "    calif_geo.plot(column=race,cmap=cmap, ax=ax[race_axis[race]],linewidth=0.8,edgecolor='0.8')\n",
    "    \n",
    "fig.delaxes(ax[1,3]) #The indexing is zero-based here\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(left=0,\n",
    "                    bottom=.65, \n",
    "                    top=1, \n",
    "                    wspace=-.5, \n",
    "                    hspace=.1)\n",
    "#plt.title(\"\",fontdict={'verticalalignment': 'baseline'})\n",
    "fig.text(.5, 1.025, 'Racial Disparity (by County)', va='center',fontsize=display_size)\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://jcutrer.com/python/learn-geopandas-plotting-usmaps\n",
    "#https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "#https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d\n",
    "#https://geopandas.org/docs/user_guide/mapping.html\n",
    "\n",
    "display_size = 20\n",
    "\n",
    "#//**** Read Shape File for all 52 States\n",
    "states = geopandas.read_file('maps\\cb_2018_us_county_20m.shp')\n",
    "\n",
    "#//*** Get just the California Shapes (these are all the counties)\n",
    "#//*** A quick investigation of the dataframes revealed a STATEFP value of 06 is California\n",
    "calif_geo = states[states['STATEFP'] == \"06\"]\n",
    "\n",
    "#//*** Merge with the Race_diff_percent dataframe. These percentages are used to color the counties\n",
    "calif_geo = calif_geo.merge(race_diff_percent,on='NAME')\n",
    "\n",
    "#//*** Set Max and Min Scale for all gradients\n",
    "#//*** Fixing to the greatest and minimum values, creates a standard scale across the graphs\n",
    "vmin,vmax = calif_geo['White'].min(),calif_geo['Latino'].max()\n",
    "\n",
    "plt.rc('axes', labelsize=display_size*2)\n",
    "plt.rc('axes', titlesize=display_size*2)\n",
    "    \n",
    "#//*** Draw a graph for each Race\n",
    "for race in race_color_map.keys():\n",
    "    \n",
    "    fig, ax = plt.subplots(1, figsize=(display_size/2, display_size/2))\n",
    "\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"{race} Disparity (by County)\",fontsize=display_size*.5)\n",
    "    \n",
    "    # add the colorbar to the figure\n",
    "    #//*** The Colormaps are hand coded and stored in a dictionary\n",
    "    cmap = race_color_map[race]\n",
    "    \n",
    "    if race == 'White':\n",
    "        cmap = ListedColormap( negative_colors + [\"#FFFFFF\"])\n",
    "\n",
    "    if race == 'Asian':\n",
    "        cmap = ListedColormap( negative_colors + [\"#FFFFFF\",\"#E8F1DF\",\"#D1E4BF\"])\n",
    "    \n",
    "    vmin,vmax = calif_geo[race].min(),calif_geo[race].max()\n",
    "\n",
    "    # Create colorbar as a legend\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "\n",
    "    # empty array for the data range\n",
    "    sm._A = []\n",
    "\n",
    "\n",
    "    cbar = fig.colorbar(sm,shrink=.8)\n",
    "\n",
    "    calif_geo.plot(column=race,cmap=cmap, ax=ax,linewidth=0.8,edgecolor='0.8')\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#https://jcutrer.com/python/learn-geopandas-plotting-usmaps\n",
    "#https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "#https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d\n",
    "#https://geopandas.org/docs/user_guide/mapping.html\n",
    "\n",
    "\n",
    "display_size = 20\n",
    "\n",
    "tdf =  pd.DataFrame()\n",
    "tdf['NAME']=ts.index\n",
    "tdf['total_100k'] = ts.values \n",
    "\n",
    "#//**** Read Shape File for all 52 States\n",
    "states = geopandas.read_file('maps\\cb_2018_us_county_20m.shp')\n",
    "\n",
    "\n",
    "#//*** Get just the California Shapes (these are all the counties)\n",
    "#//*** A quick investigation of the dataframes revealed a STATEFP value of 06 is California\n",
    "calif_geo = states[states['STATEFP'] == \"06\"]\n",
    "\n",
    "\n",
    "#//*** Merge with the Race_diff_percent dataframe. These percentages are used to color the counties\n",
    "calif_geo = calif_geo.merge(tdf,on='NAME')\n",
    "print(len(calif_geo))\n",
    "#print(len(calif_geo))\n",
    "#//*** Set Max and Min Scale for all gradients\n",
    "#//*** Fixing to the greatest and minimum values, creates a standard scale across the graphs\n",
    "vmin,vmax = ts.values[len(ts.values)-2],ts.values[0]\n",
    "\n",
    "#plt.rc('axes', labelsize=display_size*2)\n",
    "#plt.rc('axes', titlesize=display_size*2)\n",
    "    \n",
    "    \n",
    "fig, ax = plt.subplots(1, figsize=(display_size/2, display_size/2))\n",
    "\n",
    "ax.axis('off')\n",
    "#ax.set_title(f\"{race} Disparity (by County)\",fontsize=display_size*.5)\n",
    "\n",
    "# add the colorbar to the figure\n",
    "#//*** The Colormaps are hand coded and stored in a dictionary\n",
    "cmap =  ListedColormap( [\"#FFFFFF\",\"#FBE8E5\",\"#F7D1CA\",\"#F3BAB0\",\"#F0A395\",\"#EC8C7B\",\"#E87560\",\"#E45E46\",\"#E0472B\"])\n",
    "cmap =  ListedColormap( [\"#FFFFFF\",\"#FDF5F4\",\"#FCECE9\",\"#FAE2DE\",\"#F8D8D2\",\"#F7CFC7\",\"#F5C5BC\",\"#F4BBB1\",\"#F2B2A6\",\"#F0A89B\",\"#EF9E8F\",\"#ED9484\",\"#EB8B79\",\"#EA816E\",\"#E87763\",\"#E76E58\",\"#E5644C\",\"#E35A41\",\"#E25136\",\"#E0472B\"])\n",
    "\n",
    "\n",
    "# Create colorbar as a legend\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "\n",
    "# empty array for the data range\n",
    "sm._A = []\n",
    "\n",
    "\n",
    "cbar = fig.colorbar(sm,shrink=.7)\n",
    "\n",
    "plt.title(\"Cumulative COVID Prevalence\",fontsize=display_size)\n",
    "fig.text(.78, .2, 'Cumulative Cases (per 100k)', va='center' ,fontsize=display_size/2)\n",
    "calif_geo.plot(column='total_100k',cmap=cmap, ax=ax,linewidth=0.8,edgecolor='.8')\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "del tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_solid_color_map = {}\n",
    "#//*** Build handcrafted Color Maps\n",
    "negative_colors = [\"#8C8C8C\",\"#9A9A9A\",\"#A9A9A9\",\"#B7B7B7\",\"#C6C6C6\",\"#D4D4D4\",\"#E2E2E2\",\"#F1F1F1\"]\n",
    "race_solid_color_map['Latino'] =      ListedColormap( [\"#FFFFFF\",\"#FDF5F4\",\"#FCECE9\",\"#FAE2DE\",\"#F8D8D2\",\"#F7CFC7\",\"#F5C5BC\",\"#F4BBB1\",\"#F2B2A6\",\"#F0A89B\",\"#EF9E8F\",\"#ED9484\",\"#EB8B79\",\"#EA816E\",\"#E87763\",\"#E76E58\",\"#E5644C\",\"#E35A41\",\"#E25136\",\"#E0472B\"])\n",
    "race_solid_color_map['White'] =       ListedColormap( [\"#FFFFFF\",\"#FFFBF6\",\"#FFF6EC\",\"#FFF2E3\",\"#FFEED9\",\"#FFE9D0\",\"#FFE5C6\",\"#FFE0BD\",\"#FFDCB3\",\"#FFD8AA\",\"#FFD3A0\",\"#FFCF97\",\"#FFCB8D\",\"#FFC684\",\"#FFC27A\",\"#FFBD71\",\"#FFB967\",\"#FFB55E\",\"#FFB054\",\"#FFAC4B\"])\n",
    "race_solid_color_map['Asian'] =       ListedColormap( [\"#FFFFFF\",\"#F5F9F2\",\"#ECF3E4\",\"#E2EED7\",\"#D8E8C9\",\"#CEE2BC\",\"#C5DCAE\",\"#BBD6A1\",\"#B1D194\",\"#A7CB86\",\"#9EC579\",\"#94BF6B\",\"#8ABA5E\",\"#80B451\",\"#77AE43\",\"#6DA836\",\"#63A228\",\"#599D1B\",\"#50970D\",\"#469100\"])\n",
    "race_solid_color_map['Black'] =       ListedColormap( [\"#FFFFFF\",\"#F2FCFD\",\"#E4F8FB\",\"#D7F5F9\",\"#CAF2F7\",\"#BCEFF4\",\"#AFEBF2\",\"#A2E8F0\",\"#94E5EE\",\"#87E2EC\",\"#7ADEEA\",\"#6DDBE8\",\"#5FD8E6\",\"#52D5E4\",\"#45D1E2\",\"#37CEDF\",\"#2ACBDD\",\"#1DC8DB\",\"#0FC4D9\",\"#02C1D7\"])\n",
    "race_solid_color_map['Multiracial'] = ListedColormap( [\"#FFFFFF\",\"#F7FBFF\",\"#EFF6FF\",\"#E7F2FF\",\"#DFEEFF\",\"#D7E9FF\",\"#CFE5FF\",\"#C7E0FF\",\"#BFDCFF\",\"#B7D8FF\",\"#AED3FF\",\"#A6CFFF\",\"#9ECBFF\",\"#96C6FF\",\"#8EC2FF\",\"#86BDFF\",\"#7EB9FF\",\"#76B5FF\",\"#6EB0FF\",\"#66ACFF\"])\n",
    "race_solid_color_map['Hawaiian'] =    ListedColormap( [\"#FFFFFF\",\"#F9F7FE\",\"#F3F0FD\",\"#EDE8FC\",\"#E8E1FB\",\"#E2D9FB\",\"#DCD2FA\",\"#D6CAF9\",\"#D0C2F8\",\"#CABBF7\",\"#C5B3F6\",\"#BFACF5\",\"#B9A4F4\",\"#B39CF3\",\"#AD95F2\",\"#A78DF2\",\"#A286F1\",\"#9C7EF0\",\"#9677EF\",\"#906FEE\"])\n",
    "race_solid_color_map['Native'] =      ListedColormap( [\"#FFFFFF\",\"#FFFBFD\",\"#FFF6FC\",\"#FFF2FA\",\"#FEEEF8\",\"#FEEAF7\",\"#FEE5F5\",\"#FEE1F4\",\"#FEDDF2\",\"#FED9F0\",\"#FDD4EF\",\"#FDD0ED\",\"#FDCCEB\",\"#FDC8EA\",\"#FDC3E8\",\"#FDBFE7\",\"#FCBBE5\",\"#FCB7E3\",\"#FCB2E2\",\"#FCAEE0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(modeled_percents_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://jcutrer.com/python/learn-geopandas-plotting-usmaps\n",
    "#https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "#https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d\n",
    "#https://geopandas.org/docs/user_guide/mapping.html\n",
    "\n",
    "display_size = 20\n",
    "\n",
    "\n",
    "tdf = modeled_percents_df.copy()\n",
    "tdf['NAME'] = tdf.index\n",
    "\n",
    "#//**** Read Shape File for all 52 States\n",
    "states = geopandas.read_file('maps\\cb_2018_us_county_20m.shp')\n",
    "\n",
    "#//*** Get just the California Shapes (these are all the counties)\n",
    "#//*** A quick investigation of the dataframes revealed a STATEFP value of 06 is California\n",
    "calif_geo = states[states['STATEFP'] == \"06\"]\n",
    "\n",
    "\n",
    "\n",
    "#//*** Merge with the Race_diff_percent dataframe. These percentages are used to color the counties\n",
    "calif_geo = calif_geo.merge(tdf,on='NAME')\n",
    "\n",
    "#//*** Set Max and Min Scale for all gradients\n",
    "#//*** Fixing to the greatest and minimum values, creates a standard scale across the graphs\n",
    "vmin,vmax = modeled_percents_df.min().min(),modeled_percents_df.max().max()\n",
    "\n",
    "plt.rc('axes', labelsize=display_size*2)\n",
    "plt.rc('axes', titlesize=display_size*2)\n",
    "race_axis = {\n",
    "    'Latino' :   (0,0),\n",
    "    'White' :    (0,1),\n",
    "    'Asian' :    (0,2),\n",
    "    'Black' :    (0,3),\n",
    "    'Multiracial' : (1,0),\n",
    "    'Hawaiian' : (1,1),\n",
    "    'Native' :   (1,2)\n",
    "}\n",
    "fig, ax = plt.subplots(2,4, figsize=(display_size, display_size))\n",
    "\n",
    "#fig,axs = plt.subplots(col_count,figsize=(display_size,display_size/2),sharex=True)\n",
    "#axs[this_ax]\n",
    "#//*** Draw a graph for each Race\n",
    "for race in race_color_map.keys():\n",
    "    ax[race_axis[race]].axis('off')\n",
    "    ax[race_axis[race]].set_title(f\"{race}\",fontsize=display_size*.5)\n",
    "    \n",
    "    # add the colorbar to the figure\n",
    "    #//*** The Colormaps are hand coded and stored in a dictionary\n",
    "    cmap = race_solid_color_map[race]\n",
    "    \n",
    "    \n",
    "    # Create colorbar as a legend\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "\n",
    "    # empty array for the data range\n",
    "    sm._A = []\n",
    "\n",
    "\n",
    "    cbar = fig.colorbar(sm,ax=ax[race_axis[race]],shrink=1)\n",
    "    \n",
    "    vmin,vmax = calif_geo[race].min(),calif_geo[race].max()\n",
    "    \n",
    "    calif_geo.plot(column=race,cmap=cmap, ax=ax[race_axis[race]],linewidth=0.8,edgecolor='0.8')\n",
    "    \n",
    "fig.delaxes(ax[1,3]) #The indexing is zero-based here\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(left=0,\n",
    "                    bottom=.65, \n",
    "                    top=1, \n",
    "                    wspace=-.5, \n",
    "                    hspace=.1)\n",
    "#plt.title(\"\",fontdict={'verticalalignment': 'baseline'})\n",
    "fig.text(.5, 1.015, 'Modeled COVID Racial Prevalence', va='center',fontsize=display_size)\n",
    "#fig.text(.5, 1.025, '(% of county racial population)', va='center',fontsize=display_size*.75)\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://jcutrer.com/python/learn-geopandas-plotting-usmaps\n",
    "#https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "#https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d\n",
    "#https://geopandas.org/docs/user_guide/mapping.html\n",
    "\n",
    "display_size = 20\n",
    "\n",
    "\n",
    "tdf = pop_attrib_df.copy()\n",
    "\n",
    "for col in tdf.columns[2:]:\n",
    "    tdf[col] = tdf[col]/tdf['population']\n",
    "\n",
    "tdf['NAME'] = tdf['county']\n",
    "\n",
    "#//**** Read Shape File for all 52 States\n",
    "states = geopandas.read_file('maps\\cb_2018_us_county_20m.shp')\n",
    "\n",
    "#//*** Get just the California Shapes (these are all the counties)\n",
    "#//*** A quick investigation of the dataframes revealed a STATEFP value of 06 is California\n",
    "calif_geo = states[states['STATEFP'] == \"06\"]\n",
    "\n",
    "\n",
    "\n",
    "#//*** Merge with the Race_diff_percent dataframe. These percentages are used to color the counties\n",
    "calif_geo = calif_geo.merge(tdf,on='NAME')\n",
    "\n",
    "#//*** Set Max and Min Scale for all gradients\n",
    "#//*** Fixing to the greatest and minimum values, creates a standard scale across the graphs\n",
    "\n",
    "plt.rc('axes', labelsize=display_size*2)\n",
    "plt.rc('axes', titlesize=display_size*2)\n",
    "race_axis = {\n",
    "    'Latino' :   (0,0),\n",
    "    'White' :    (0,1),\n",
    "    'Asian' :    (0,2),\n",
    "    'Black' :    (0,3),\n",
    "    'Multiracial' : (1,0),\n",
    "    'Hawaiian' : (1,1),\n",
    "    'Native' :   (1,2)\n",
    "}\n",
    "fig, ax = plt.subplots(2,4, figsize=(display_size, display_size))\n",
    "\n",
    "#fig,axs = plt.subplots(col_count,figsize=(display_size,display_size/2),sharex=True)\n",
    "#axs[this_ax]\n",
    "#//*** Draw a graph for each Race\n",
    "for race in race_color_map.keys():\n",
    "    ax[race_axis[race]].axis('off')\n",
    "    ax[race_axis[race]].set_title(f\"{race}\",fontsize=display_size*.5)\n",
    "    \n",
    "    # add the colorbar to the figure\n",
    "    #//*** The Colormaps are hand coded and stored in a dictionary\n",
    "    cmap = race_solid_color_map[race]\n",
    "    \n",
    "    vmin,vmax = tdf[race].min(),tdf[race].max()\n",
    "    \n",
    "    # Create colorbar as a legend\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "\n",
    "    # empty array for the data range\n",
    "    sm._A = []\n",
    "\n",
    "\n",
    "    cbar = fig.colorbar(sm,ax=ax[race_axis[race]],shrink=1)\n",
    "\n",
    "    calif_geo.plot(column=race,cmap=cmap, ax=ax[race_axis[race]],linewidth=0.8,edgecolor='0.8')\n",
    "    \n",
    "fig.delaxes(ax[1,3]) #The indexing is zero-based here\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(left=0,\n",
    "                    bottom=.65, \n",
    "                    top=1, \n",
    "                    wspace=-.5, \n",
    "                    hspace=.1)\n",
    "#plt.title(\"\",fontdict={'verticalalignment': 'baseline'})\n",
    "fig.text(.5, 1.025, 'Population Distribution by Race', va='center',fontsize=display_size)\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "del tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://jcutrer.com/python/learn-geopandas-plotting-usmaps\n",
    "#https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html\n",
    "#https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d\n",
    "#https://geopandas.org/docs/user_guide/mapping.html\n",
    "\n",
    "display_size = 20\n",
    "\n",
    "\n",
    "tdf = pop_attrib_df.copy()\n",
    "\n",
    "for col in tdf.columns[2:]:\n",
    "    tdf[col] = tdf[col]/tdf['population']\n",
    "\n",
    "tdf['NAME'] = tdf['county']\n",
    "\n",
    "#//**** Read Shape File for all 52 States\n",
    "states = geopandas.read_file('maps\\cb_2018_us_county_20m.shp')\n",
    "\n",
    "#//*** Get just the California Shapes (these are all the counties)\n",
    "#//*** A quick investigation of the dataframes revealed a STATEFP value of 06 is California\n",
    "calif_geo = states[states['STATEFP'] == \"06\"]\n",
    "\n",
    "\n",
    "\n",
    "#//*** Merge with the Race_diff_percent dataframe. These percentages are used to color the counties\n",
    "calif_geo = calif_geo.merge(tdf,on='NAME')\n",
    "\n",
    "#//*** Set Max and Min Scale for all gradients\n",
    "#//*** Fixing to the greatest and minimum values, creates a standard scale across the graphs\n",
    "\n",
    "plt.rc('axes', labelsize=display_size*2)\n",
    "plt.rc('axes', titlesize=display_size*2)\n",
    "race_axis = {\n",
    "    'Latino' :   (0,0),\n",
    "    'White' :    (0,1),\n",
    "    'Asian' :    (0,2),\n",
    "    'Black' :    (0,3),\n",
    "    'Multiracial' : (1,0),\n",
    "    'Hawaiian' : (1,1),\n",
    "    'Native' :   (1,2)\n",
    "}\n",
    "fig, ax = plt.subplots(figsize=(display_size, display_size))\n",
    "\n",
    "#fig,axs = plt.subplots(col_count,figsize=(display_size,display_size/2),sharex=True)\n",
    "#axs[this_ax]\n",
    "#//*** Draw a graph for each Race\n",
    "for race in ['Latino']:\n",
    "    ax.axis('off')\n",
    "    #ax.set_title(f\"{race}\",fontsize=display_size*.5)\n",
    "    \n",
    "    # add the colorbar to the figure\n",
    "    #//*** The Colormaps are hand coded and stored in a dictionary\n",
    "    cmap = race_solid_color_map[race]\n",
    "    \n",
    "    vmin,vmax = tdf[race].min(),tdf[race].max()\n",
    "    \n",
    "    # Create colorbar as a legend\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
    "\n",
    "    # empty array for the data range\n",
    "    sm._A = []\n",
    "\n",
    "\n",
    "    cbar = fig.colorbar(sm,ax=ax,shrink=1)\n",
    "\n",
    "    calif_geo.plot(column=race,cmap=cmap, ax=ax,linewidth=0.8,edgecolor='0.8')\n",
    "    \n",
    "\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(left=0,\n",
    "                    bottom=.65, \n",
    "                    top=1, \n",
    "                    wspace=-.5, \n",
    "                    hspace=.1)\n",
    "#plt.title(\"\",fontdict={'verticalalignment': 'baseline'})\n",
    "fig.text(.5, 1.025, 'Latino Population Distribution', va='center',fontsize=display_size)\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "\n",
    "del tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "county = 'Los Angeles'\n",
    "for county in cors_df['county']:   \n",
    "    \n",
    "    if county not in high_covid_counties:\n",
    "        continue\n",
    "    #//*** Compare the expected vs scaled modeled values\n",
    "    expected_la = ca_model_cases_df[ca_model_cases_df['county']== county]\n",
    "    \n",
    "    \n",
    "    modeled_la = modified_race_total[['date','race',county]]\n",
    "    #modeled_la = v2_ca_case_race_total_df[['date','race',county]]\n",
    "    \n",
    "    modeled_la = ca_case_race_total_df[['date','race',county]]\n",
    "\n",
    "    for race in ['Latino','White',\"Asian\",\"Black\"]:\n",
    "        print(\"=======================================\")\n",
    "        print(\"TESTING visualization Model vs Expected\")\n",
    "        print(\"=======================================\")\n",
    "\n",
    "        \n",
    "        loop_model_race = modeled_la[modeled_la['race']==race]\n",
    "\n",
    "        loop_model_expected = expected_la[['date','county',race,f\"case_{race}\",f\"adj_{race}\",\"cases\"]]\n",
    "        \n",
    "        #//*** Skip Columns where the Max cases is less than 20. These values are a bit unreliable\n",
    "        if loop_model_expected[f\"case_{race}\"].max() < 20:\n",
    "            continue\n",
    "        #loop_model_race = modeled_la[modeled_la['race']==race]\n",
    "\n",
    "        #loop_model_expected = expected_la[['date','county',race,f\"case_{race}\",f\"adj_{race}\",\"cases\"]]\n",
    "        #print(\"Correlation: \", county, \" \",race, \" \",pearsonr(loop_model_race[county],loop_model_expected['cases']))\n",
    "        \n",
    "        #//*** Cases per 100k should be relatively similar in values.\n",
    "        display_size = 20\n",
    "        fig,ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "        ax.plot(loop_model_race['date'],loop_model_race[county].rolling(5).mean(),label=f\"{race}_modeled\")\n",
    "        ax.plot(loop_model_expected['date'],loop_model_expected[f\"case_{race}\"].rolling(5).mean(),label=f\"{race}_expected\")\n",
    "        ax.plot(loop_model_expected['date'],loop_model_expected[f\"cases\"].rolling(5).mean(),label=f\"total\")\n",
    "\n",
    "        plt.xticks(rotation=30,fontsize=display_size)\n",
    "        plt.yticks(fontsize=display_size)\n",
    "        handles,labels = deduplicate_legend(ax)\n",
    "        plt.legend(fontsize=display_size,loc='upper left')\n",
    "        plt.title(f\"{county}\\n Modeled/Expected Correlation: {(pearsonr(loop_model_race[county],loop_model_expected['cases']))}\",fontsize=display_size)\n",
    "        plt.ylabel(\"New cases per day\",fontsize=display_size)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "\n",
    "#//*** Temp variable cleanup\n",
    "del expected_la\n",
    "del modeled_la\n",
    "del loop_model_expected\n",
    "del loop_model_race\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//*** Merge Population Attributes with COVID County info\n",
    "#//*** Only Merge if we haven't merged yet. I got 99 iPython problems but this aint one.\n",
    "if \"Latino\" not in ca_covid_df.columns:\n",
    "    ca_covid_df = pd.merge(ca_covid_df,pop_attrib_df,how=\"left\",on=['county'])\n",
    "\n",
    "\n",
    "#//*** Build per 100k Stats\n",
    "ca_100k_df = ca_covid_df.copy()\n",
    "\n",
    "#//*** Define Population Columns to convert to 100k. These Columns shouldn't change. Trying to setup a flexible\n",
    "#//*** Systems where I can add other attributes later if needed\n",
    "population_cols = [ 'population','Latino', 'White', 'Asian', 'Black', 'Native', 'Hawaiian','Multiracial' ]\n",
    "\n",
    "#//*** Convert Popultion values to 100k units. ie divide by 100,000\n",
    "for col in population_cols:\n",
    "    ca_100k_df[col] = ca_100k_df[col]/100000\n",
    "\n",
    "\n",
    "\n",
    "#//*** Convert cases, deaths, test to per 100k units\n",
    "attrib_cols = ['date','county']\n",
    "\n",
    "#//*** Ignore values in attrib_cols, and population_cols\n",
    "#//*** Convert remianing attributes to values per 100,000.\n",
    "#//*** This method makes it easier to change the 100k attributes later.\n",
    "for col in ca_100k_df.columns:\n",
    "    if col not in attrib_cols and col not in population_cols:\n",
    "        #//*** Convert column to per 100k value. Which is Columns value divided population per 100k\n",
    "        ca_100k_df[col] = ca_100k_df[col]/ca_100k_df['population'] \n",
    "\n",
    "\n",
    "#//*** Check our Work.\n",
    "#//*** Cases per 100k should be relatively similar in values.\n",
    "display_size = 40\n",
    "fig,ax = plt.subplots(figsize=(40,20))\n",
    "\n",
    "for county in ca_100k_df['county'].unique():\n",
    "    \n",
    "    loop_df = ca_100k_df[ca_100k_df['county'] ==  county]\n",
    "    ax.plot(loop_df['date'],loop_df['cases'].rolling(5).mean(),label=county)\n",
    "\n",
    "\n",
    "    plt.xticks(rotation=30,fontsize=display_size)\n",
    "    plt.yticks(fontsize=display_size)\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "plt.legend(fontsize=display_size*.25,loc='upper left')\n",
    "plt.title(f\"Scaled County Data (per 100k)\",fontsize=display_size)\n",
    "#plt.ylabel(\"Total Cases by County (millions)\",fontsize=display_size)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#//*** Scale the State Numbers\n",
    "\n",
    "\n",
    "display_size = 15\n",
    "fig,ax = plt.subplots(figsize=(display_size,display_size/2))\n",
    "for race in ['Latino',\"White\",\"Asian\",\"Black\",\"Native\",\"Multiracial\"]:\n",
    "    if race == 'Total':\n",
    "        continue\n",
    "    \n",
    "    loop_df = ca_race_df[ca_race_df['race'] ==  race]\n",
    "    \n",
    "    if race in ['Latino']:\n",
    "        ax.plot(loop_df['date'],loop_df['cases_100k'].rolling(7).mean(),linewidth=5,label=race,color=race_color[race])\n",
    "    else:\n",
    "        ax.plot(loop_df['date'],loop_df['cases_100k'].rolling(7).mean(),label=race,color=race_color[race])\n",
    "\n",
    "    plt.xticks(rotation=30,fontsize=display_size)\n",
    "    plt.yticks(fontsize=display_size)\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "plt.legend(fontsize=display_size*.5,loc='upper left')\n",
    "plt.title(f\"Statewide Scaled Race Data\\n New Cases per Day(per 100k)\",fontsize=display_size)\n",
    "#plt.ylabel(\"Total Cases by County (millions)\",fontsize=display_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(ca_cases_broad_df['Madera'].sum())\n",
    "\n",
    "for group in ca_case_race_total_df.groupby('race'):\n",
    "    cols = group[1].columns[4:]\n",
    "    print(group[0])\n",
    "    print(group[1][['Los Angeles','Madera']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Assigns a color from a palette list to a county. \n",
    "def assign_color(input_item, input_cd,input_palette):\n",
    "    #//*** Check if item already exists, if so, return input_cd\n",
    "    if input_item in input_cd.keys():\n",
    "        return input_cd\n",
    "    \n",
    "    #//*** input_item needs a Color. Walk down the input_palette till one is not found\n",
    "    for color in input_palette:\n",
    "        if color not in input_cd.values():\n",
    "            input_cd[input_item] = color\n",
    "            return input_cd\n",
    "    print(\"UH OH ran out of colors!!!\")\n",
    "    print(f\"Item: {input_item}\")\n",
    "    print(input_cd)\n",
    "    return input_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Color Choices: Tucking these aside for later use\n",
    "#//*** Combine these with a dictionary to create color continuity across multiple visualizations.\n",
    "color_palette = [\"#c6eaff\",\"#caa669\",\"#14bae2\",\"#f7cd89\",\"#98a9e7\",\"#e2ffb7\",\"#cb9ec2\",\"#77dcb5\",\"#ffc5b7\",\"#40bdba\",\"#fff4b0\",\"#74d0ff\",\"#e4da8d\",\"#7ceeff\",\"#d0e195\",\"#b7ab8c\",\"#fcffdb\",\"#83b88d\",\"#ffe2c0\",\"#abc37a\"]\n",
    "color_palette = [\"#557788\",\"#e12925\",\"#44af0e\",\"#7834c0\",\"#726d00\",\"#130c6d\",\"#004e12\",\"#f7007d\",\"#017878\",\"#950089\",\"#00a3d7\",\"#4b000e\",\"#0063c2\",\"#f07478\",\"#013b75\",\"#cf81b8\",\"#212238\",\"#af87e7\",\"#320f49\",\"#9c91db\"]\n",
    "county_color_palette = [\"#b4a23b\",\"#4457ca\",\"#9ec535\",\"#a651cb\",\"#59ce59\",\"#6a77f0\",\"#52a325\",\"#b93d9b\",\"#36b25c\",\"#e374d4\",\"#c1c035\",\"#7452af\",\"#96ae3a\",\"#a484e2\",\"#89c466\",\"#e54790\",\"#57c888\",\"#dd3d60\",\"#5bd6c4\",\"#dd4e2d\",\"#45ccdf\",\"#bd3738\",\"#4cb998\",\"#b13a6c\",\"#368433\",\"#588feb\",\"#dcad3d\",\"#4763af\",\"#e49132\",\"#4aa5d4\",\"#c86321\",\"#7695d3\",\"#769233\",\"#925898\",\"#54701c\",\"#c893d6\",\"#3d7b44\",\"#e084ac\",\"#65a76b\",\"#965179\",\"#296437\",\"#e57f5f\",\"#31a8ad\",\"#a44b2c\",\"#368d71\",\"#df7f81\",\"#226a4d\",\"#96465f\",\"#b5b671\",\"#68649c\",\"#ad772e\",\"#a34f52\",\"#758348\",\"#d8a06e\",\"#505e25\",\"#8e5e31\",\"#8e8033\",\"#695f1b\"]\n",
    "county_color_palette = [\"#96465f\",\"#dd3d60\",\"#df7f81\",\"#a34f52\",\"#bd3738\",\"#dd4e2d\",\"#e57f5f\",\"#a44b2c\",\"#c86321\",\"#8e5e31\",\"#d8a06e\",\"#e49132\",\"#ad772e\",\"#dcad3d\",\"#b4a23b\",\"#8e8033\",\"#695f1b\",\"#c1c035\",\"#b5b671\",\"#96ae3a\",\"#505e25\",\"#758348\",\"#9ec535\",\"#769233\",\"#54701c\",\"#52a325\",\"#89c466\",\"#368433\",\"#59ce59\",\"#3d7b44\",\"#65a76b\",\"#296437\",\"#36b25c\",\"#57c888\",\"#226a4d\",\"#368d71\",\"#4cb998\",\"#5bd6c4\",\"#31a8ad\",\"#45ccdf\",\"#4aa5d4\",\"#7695d3\",\"#588feb\",\"#4763af\",\"#6a77f0\",\"#4457ca\",\"#68649c\",\"#a484e2\",\"#7452af\",\"#a651cb\",\"#c893d6\",\"#925898\",\"#e374d4\",\"#b93d9b\",\"#965179\",\"#e084ac\",\"#e54790\",\"#b13a6c\"]\n",
    "county_color_palette = [\"#226a4d\",\"#31a8ad\",\"#68649c\",\"#758348\",\"#505e25\",\"#368d71\",\"#4aa5d4\",\"#965179\",\"#7695d3\",\"#45ccdf\",\"#296437\",\"#96465f\",\"#8e5e31\",\"#b5b671\",\"#d8a06e\",\"#a34f52\",\"#5bd6c4\",\"#695f1b\",\"#4cb998\",\"#df7f81\",\"#3d7b44\",\"#e084ac\",\"#c893d6\",\"#65a76b\",\"#8e8033\",\"#925898\",\"#4763af\",\"#54701c\",\"#ad772e\",\"#a44b2c\",\"#e57f5f\",\"#769233\",\"#57c888\",\"#b13a6c\",\"#588feb\",\"#a484e2\",\"#b4a23b\",\"#368433\",\"#89c466\",\"#7452af\",\"#96ae3a\",\"#dcad3d\",\"#bd3738\",\"#36b25c\",\"#e374d4\",\"#c86321\",\"#b93d9b\",\"#e49132\",\"#dd3d60\",\"#e54790\",\"#c1c035\",\"#4457ca\",\"#6a77f0\",\"#52a325\",\"#9ec535\",\"#dd4e2d\",\"#a651cb\",\"#59ce59\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "display_size = 40\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(display_size,display_size/2))\n",
    "\n",
    "ax.bar(ts.index,ts)\n",
    "\n",
    "#//*** Draw horizontal line. Draw it twice to get the yellow and back effect. \n",
    "#//*** This technique looks viusually good, but I can't get the legend to draw approrpriately.\n",
    "ax.axhline(state_100k,color = \"black\", label=\"Statewide Cases 100k\", linestyle = \"-\", lw=2)\n",
    "ax.axhline(state_100k,color = \"yellow\", linestyle = \"--\", lw=2)\n",
    "        \n",
    "plt.xticks(rotation=90,fontsize=display_size*.75)\n",
    "plt.yticks(fontsize=display_size*.75)\n",
    "\n",
    "handles,labels = deduplicate_legend(ax)\n",
    "\n",
    "plt.legend(fontsize=display_size,loc='upper right')\n",
    "plt.title(f\"Total Covid cases for all counties.\\nper 100k\",fontsize=display_size)\n",
    "plt.ylabel(\"Total Cases by County (per 100k)\",fontsize=display_size)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Look at total County COVID numbers by county rates per 100k.\n",
    "\n",
    "\n",
    "#//*** Get the last data\n",
    "\n",
    "\n",
    "#for county in\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#last_day_df = rd[race_list[0]][rd[race_list[0]]['date'] == last_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#//*** Convert Racial percentages into estimated COVID cases per county\n",
    "ca_case_race_total_df = pd.DataFrame()\n",
    "\n",
    "if 'ca_case_race_total_df' not in df_list:\n",
    "    df_list.append('ca_case_race_total_df')\n",
    "    \n",
    "case_county_index = 4\n",
    "x_column = ca_case_race_percent_df.columns[case_county_index:]\n",
    "    \n",
    "#//*** Loop through each day in ca_case_race_percent_df\n",
    "for group in ca_case_race_percent_df.groupby('date'):\n",
    "    \n",
    "    loop_df = group[1].copy()\n",
    "    #print(loop_df[x_column])\n",
    "    \n",
    "    this_day = ca_cases_broad_df[ca_cases_broad_df['date']==group[0]].copy()\n",
    "    \n",
    "    loop_df['intercept'] = this_day['total'].values[0]\n",
    "    \n",
    "    #//*** Keep just the county columns\n",
    "    this_day = this_day[this_day.columns[2:]]\n",
    "    \n",
    "    loop_df[x_column]= (loop_df[x_column]*this_day.values).astype(int)\n",
    "    \n",
    "    \n",
    "    ca_case_race_total_df = pd.concat([ca_case_race_total_df,loop_df])\n",
    "\n",
    "print(ca_case_race_total_df)\n",
    "#//*** Temp Variable Cleanup\n",
    "del loop_df\n",
    "del this_day\n",
    "\"\"\"\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#//*** Version 1: Generate Coefficients from the model\n",
    "\n",
    "#//*** This works on one variable at a time. Keeping this for reference. \n",
    "#//*** Will use builder function.\n",
    "\n",
    "#//***************************************************************************************************************************************************************************\n",
    "#//*** Generatate a Individual Race Coeffecients for each county per day.\n",
    "#//*** The the sum of racial coefficients should equal the state coefficent for the county. \n",
    "#//***************************************************************************************************************************************************************************\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#//*** Build the coefficients for the entire data set. Each day will calculate the coefficients from the previous 30 days. The First 30 days will use one set of coeffients. The rest will use\n",
    "#//*** The current day: -30 to generate the coefficients. This will be an overfitted solution which is exactly what we are going for.\n",
    "start_time = time.time()\n",
    "#//*** Abstract Dataframes to Left and Right for reusability\n",
    "left_df = ca_races_broad_df\n",
    "right_df = ca_cases_broad_df\n",
    "\n",
    "#//*** Get Coefficients for counties predicting the State total Case values\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "#//*** County Columns start at Index 3\n",
    "x_col_index = 3\n",
    "\n",
    "#//*** Target Independent Column Index. Statewide race numbers begin at column 1\n",
    "y_col_index = 1\n",
    "\n",
    "#//*** Sample size\n",
    "#modeling_days = 30\n",
    "\n",
    "\n",
    "print(\"Calculating racial coefficients...\")\n",
    "#//*** Combining with car_race_df and Latino value. It's not strictly needed, but the additional column will make combining the dataframes later, easier.\n",
    "#//*** Reusing Code: This loop only needs to run once\n",
    "for race in left_df.columns[1:]:\n",
    "    \n",
    "    #//*** Build model for the first 30 days, combines the race from ca_race (which is only needed as an extra field, to evenly space the columms)\n",
    "    model_df = left_df[['date',race]].merge(right_df, left_on='date', right_on='date')[:30]\n",
    "    \n",
    "    #//*************************\n",
    "    #//*** BEGIN regression\n",
    "    #//*************************\n",
    "    \n",
    "    \n",
    "    #//**** Build the x Values - Dependent Variables. These will be all the counties which start at the column index \n",
    "    #//*** The X Value is the index where the attributes start, there are 58 of them :)\n",
    "    #x_column = model_df.columns[x_col_index:]\n",
    "    \n",
    "    #//*** Generate ordered list of Counties by current race population.\n",
    "    #//*** The assumptions is the counties with higher populations will exert a greater weight on the model.\n",
    "    #//*** Otherwise the tiny county of Alpine gets way overly represented\n",
    "    race_columns = (pop_attrib_df[['county',race]].sort_values(race,ascending=False)['county'])\n",
    "\n",
    "    #print(model_df[race_columns])\n",
    "    #//*** Build the X attributes using the x_column. These are separated for readability and modularity\n",
    "    x_model = model_df[race_columns]\n",
    "\n",
    "    #print(x_model)\n",
    "    #//*** Build the independent variable using the Index Column defined above as y_col_index.\n",
    "    y_column = model_df.columns[y_col_index]\n",
    "    \n",
    "    #//*** Build the Y model using the y_column attribute. This is less readable and intuitive, but it lets the columns be \n",
    "    #//*** easily assigned at the top of this section\n",
    "    y_model = model_df[y_column]\n",
    "    \n",
    "    #//*** Define the Linear Model\n",
    "    regr = linear_model.LinearRegression(n_jobs=-1)\n",
    "    \n",
    "    #//*** Make Regression Magic\n",
    "    regr.fit(x_model, y_model)\n",
    "    \n",
    "    #//*** Apply the regression coefficients\n",
    "    model_df[race_columns] = (model_df[race_columns])*regr.coef_\n",
    "    \n",
    "    \n",
    "\n",
    "    #//*** Replace the Statewide Total Column. With the Statewide Race Totals\n",
    "    model_df['total'] = model_df[race]\n",
    "    \n",
    "    #//*** Change The race column to hold the race name\n",
    "    model_df[race] = race\n",
    "    \n",
    "    #//*** Rename the race (Latino, Native, etc) to 'race'\n",
    "    cols = list(model_df.columns)\n",
    "    cols[1] = 'race'\n",
    "    model_df.columns = cols\n",
    "    \n",
    "    model_df['intercept'] = regr.intercept_\n",
    "\n",
    "    #//*** Move intercept to be the column after Total\n",
    "    #//*** Gets Columns as a list, removes intercept of end and inserts into position\n",
    "    #//*** Model_df is saved with ordered list of columns.\n",
    "    #//*** Kinda Cool\n",
    "    model_df = model_df[ list(model_df.columns[:-1].insert(3,'intercept')) ]\n",
    "\n",
    "    #//*** Reorder Counties\n",
    "    #//*** Keep the First four Columns, then use ordered_counties\n",
    "    model_df = model_df[list(model_df.columns[:4])+ordered_counties]\n",
    "    \n",
    "    #print(model_df)\n",
    "    #//*** Add the First 30 days Model to the output_df dataframe\n",
    "    output_df = pd.concat([output_df,model_df])\n",
    "\n",
    "    #//*** Checking our work. The sum of the coefficients * cases + intercept should be close the independent value in Total Cases.\n",
    "    print(\"Checking our Work. These values should be close:\")\n",
    "    print(model_df.iloc[1]['total'], \" == \", model_df[x_column].iloc[1].sum()+regr.intercept_)    \n",
    "     \n",
    "   \n",
    "    #//*** Build each day individually, based on the previous 30 days\n",
    "    #//*** Start at index 31 \n",
    "    for index in range(31,len(left_df)):\n",
    "        \n",
    "        #//*** Define the start and indexes for linear modeling. This is the row_index - 30\n",
    "        min_index = index-30\n",
    "        \n",
    "        #//*** Build model_df using min_index and index as a 30 day range)\n",
    "        model_df = left_df[['date',race]].merge(right_df, left_on='date', right_on='date')[min_index:index]\n",
    "        \n",
    "        #//*** Build the X attributes using the x_column. These are separated for readability and modularity\n",
    "        x_model = model_df[race_columns]\n",
    "\n",
    "        #//*** Build the Y model using the y_column attribute. This is less readable and intuitive, but it lets the columns be \n",
    "        #//*** easily assigned at the top of this section\n",
    "        y_model = model_df[y_column]\n",
    "\n",
    "        #//*** Build a New the Linear Model\n",
    "        regr = linear_model.LinearRegression(n_jobs=-1)\n",
    "\n",
    "        #//*** Make Regression Magic\n",
    "        regr.fit(x_model, y_model)\n",
    "\n",
    "        #//*** Replace the Statewide Total Column. With the Statewide Race Totals\n",
    "        model_df['total'] = model_df[race]\n",
    "\n",
    "        #//*** Change The race column to hold the race name\n",
    "        model_df[race] = race\n",
    "\n",
    "        #//*** Rename the race (Latino, Native, etc) to 'race'\n",
    "        cols = list(model_df.columns)\n",
    "        cols[1] = 'race'\n",
    "        model_df.columns = cols\n",
    "\n",
    "        #//*** Apply the regression coefficients to all columns, even though we only need the last one\n",
    "        model_df[race_columns] = (model_df[race_columns])*regr.coef_\n",
    "        model_df['intercept'] = regr.intercept_\n",
    "\n",
    "        #//*** Move intercept to be the column after Total\n",
    "        #//*** Gets Columns as a list, removes intercept of end and inserts into position\n",
    "        #//*** Model_df is saved with ordered list of columns.\n",
    "        #//*** Kinda Cool\n",
    "        model_df = model_df[ list(model_df.columns[:-1].insert(3,'intercept')) ]\n",
    "\n",
    "        #//*** Reorder Counties\n",
    "        #//*** Keep the First four Columns, then use ordered_counties\n",
    "        model_df = model_df[list(model_df.columns[:4])+ordered_counties]\n",
    "\n",
    "        #//*** Add the last day of model_df to output_df. \n",
    "        #//*** It's not exactly efficient, but it is functional\n",
    "        #output_df = pd.concat([output_df,model_df.iloc[-1]])\n",
    "        output_df = output_df.append(model_df.iloc[-1])\n",
    "\n",
    "processing_df = output_df.copy()\n",
    "\n",
    "del output_df\n",
    "print(\"Done\")\n",
    "\"\"\"\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#//**** Archived Reference in case I muck it up\n",
    "\n",
    "#//************************************************\n",
    "#//*** Convert Coefficients to percentages\n",
    "#//************************************************\n",
    "#//*** Racial Coefficients are built for each race by day and county.\n",
    "#//*** Group output_df by date, to calculate the race percent for each county by day.\n",
    "#//*** The Racial Percentage is\n",
    "\n",
    "print(f\"CoEfficients Calculated: {round(time.time()-start_time,0)}s\")\n",
    "start_time = time.time()\n",
    "\n",
    "x_col_index = 4\n",
    "x_column = model_df.columns[x_col_index:]\n",
    "output2_df = pd.DataFrame()\n",
    "for group in output_df.groupby('date'):\n",
    "    \n",
    "    #//*** Make a coopy of sliced dataframe. This prevents index errors\n",
    "    loop_df = group[1].copy()\n",
    "    \n",
    "    #//*** Avoid Divide by zero errors and replace 0 with 1. When processed 0's will become 0.142857, which can be replace with 0 again\n",
    "    loop_df = loop_df.replace(0,1)\n",
    "    \n",
    "    #//*** Each racial row of coefficints summed + intercept will equal the racial total for the day.\n",
    "    #//*** The relavtive weights of each racial coefficient need to be converted in to percentages.\n",
    "    #//*** Coefficients are positive and negative. Which adds a challenge of calculating weights which is usually value/sum. \n",
    "    #//*** If values are negative, it disrupts the sum. The solution is to sum the absolute value of the coefficients. Percentages are calculated as value/ abs().sum()\n",
    "    \n",
    "    \n",
    "    \n",
    "    #print((abs(loop_df[x_column])/max_val).sum())\n",
    "    loop_df[x_column] = (abs(loop_df[x_column])/abs(loop_df[x_column]).sum())\n",
    "    \n",
    "    #//*** replace the exactly even percentage distributions with 0's. These were the initially 0's replaced with 1's\n",
    "    loop_df = loop_df.replace(.14285714285714285,0)\n",
    "    output2_df = pd.concat([output2_df,loop_df])\n",
    "    #print(loop_df)\n",
    "\n",
    "    \n",
    "ca_case_race_percent_df = output2_df.copy().fillna(0)\n",
    "\n",
    "ca_case_race_percent_df.index = np.arange(0,len(ca_case_race_percent_df))\n",
    "\n",
    "print(f'Racial Percentages Calculated: {round(time.time()-start_time,0)}s')\n",
    "print(ca_case_race_percent_df)\n",
    "if 'ca_case_race_percent_df' not in df_list:\n",
    "    df_list.append('ca_case_race_percent_df')\n",
    "#//*** Temp Variable Cleanup\n",
    "#del output_df\n",
    "#del output2_df\n",
    "#del loop_df\n",
    "#del model_df\n",
    "\"\"\"\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pop_attrib_df.copy()\n",
    "tdf['population'] = tdf['population']/tdf['population'].sum()\n",
    "print(tdf.sort_values('population',ascending=False))\n",
    "del tdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "if 'state_coef_df' not in df_list:\n",
    "    df_list.append('state_coef_df')\n",
    "    \n",
    "#//*** Generate Coefficients for the State - Orphaned Code\n",
    "#//***************************************************************************************************************************************************************************\n",
    "#//*** Generatate a State Coeffecient. These are best used to check our work.\n",
    "#//*** The State Coeefficients are useful for comparing the sum of racial coefficients. If the regressions are consistent, the state coefficient should be close to the \n",
    "#//*** sum of the racial coeffificents\n",
    "#//***************************************************************************************************************************************************************************\n",
    "\n",
    "#//*** Build the coefficients for the entire data set. Each day will calculate the coefficients from the previous 30 days. The First 30 days will use one set of coeffients. The rest will use\n",
    "#//*** The current day: -30 to generate the coefficients. This will be an overfitted solution which is exactly what we are going for.\n",
    "\n",
    "#//*** Abstract Dataframes to Left and Right for reusability\n",
    "left_df = ca_races_broad_df\n",
    "right_df = ca_cases_broad_df\n",
    "\n",
    "#//*** Get Coefficients for counties predicting the State total Case values\n",
    "output_df = pd.DataFrame()\n",
    "\n",
    "#//*** County Columns start at Index 3\n",
    "x_col_index = 3\n",
    "\n",
    "#//*** Target Independent Column Index. Statewide numbers begin at column 2\n",
    "y_col_index = 2\n",
    "\n",
    "#//*** Sample size\n",
    "#modeling_days = 30\n",
    "\n",
    "#//*** Combining with car_race_df and Latino value. It's not strictly needed, but the additional column will make combining the dataframes later, easier.\n",
    "#//*** Reusing Code: This loop only needs to run once\n",
    "for race in ['Latino']:\n",
    "    \n",
    "    #//*** Build model for the first 30 days, combines the race from ca_race (which is only needed as an extra field, to evenly space the columms)\n",
    "    model_df = left_df[['date',race]].merge(right_df, left_on='date', right_on='date')[:30]\n",
    "    #print(model_df)\n",
    "    \n",
    "    #//*************************\n",
    "    #//*** BEGIN regression\n",
    "    #//*************************\n",
    "    \n",
    "    #//**** Build the x Values - Dependent Variables. These will be all the counties which start at the column index \n",
    "    #//*** The X Value is the index where the attributes start, there are 58 of them :)\n",
    "    x_column = model_df.columns[x_col_index:]\n",
    "\n",
    "    #//*** Build the X attributes using the x_column. These are separated for readability and modularity\n",
    "    x_model = model_df[x_column]\n",
    "    \n",
    "\n",
    "    #//*** Build the independent variable using the Index Column defined above as y_col_index.\n",
    "    y_column = model_df.columns[y_col_index]\n",
    "    \n",
    "    #//*** Build the Y model using the y_column attribute. This is less readable and intuitive, but it lets the columns be \n",
    "    #//*** easily assigned at the top of this section\n",
    "    y_model = model_df[y_column]\n",
    "    \n",
    "    #//*** Define the Linear Model\n",
    "    regr = linear_model.LinearRegression()\n",
    "    \n",
    "    #//*** Make Regression Magic\n",
    "    regr.fit(x_model, y_model)\n",
    "\n",
    "    #//*** Apply the regression coefficients\n",
    "    model_df[x_column] = (model_df[x_column])*regr.coef_\n",
    "    \n",
    "    #//*** Add the First 30 days Model to the output_df dataframe\n",
    "    output_df = pd.concat([output_df,model_df])\n",
    "    \n",
    "    #//*** Checking our work. The sum of the coefficients * cases + intercept should be close the independent value in Total Cases.\n",
    "    print(\"Checking our Work. These values should be close:\")\n",
    "    print(model_df.iloc[1]['total'], \" == \", model_df[x_column].iloc[1].sum()+regr.intercept_)    \n",
    "\n",
    "    #//*** Build each day individually, based on the previous 30 days\n",
    "    #//*** Start at index 31 \n",
    "    for index in range(31,len(left_df)):\n",
    "        \n",
    "        #//*** Define the start and indexes for linear modeling. This is the row_index - 30\n",
    "        min_index = index-30\n",
    "        \n",
    "        #//*** Build model_df using min_index and index as a 30 day range)\n",
    "        model_df = left_df[['date',race]].merge(right_df, left_on='date', right_on='date')[min_index:index]\n",
    "        \n",
    "        #//*** Build the X attributes using the x_column. These are separated for readability and modularity\n",
    "        x_model = model_df[x_column]\n",
    "\n",
    "        #//*** Build the Y model using the y_column attribute. This is less readable and intuitive, but it lets the columns be \n",
    "        #//*** easily assigned at the top of this section\n",
    "        y_model = model_df[y_column]\n",
    "\n",
    "        #//*** Build a New the Linear Model\n",
    "        regr = linear_model.LinearRegression()\n",
    "\n",
    "        #//*** Make Regression Magic\n",
    "        regr.fit(x_model, y_model)\n",
    "\n",
    "        #//*** Apply the regression coefficients to all columns, even though we only need the last one\n",
    "        model_df[x_column] = (model_df[x_column])*regr.coef_\n",
    "        model_df[model_df.columns[1]] = regr.intercept_\n",
    "        #//*** Add the last day of model_df to output_df. \n",
    "        #//*** It's not exactly efficient, but it is functional\n",
    "        #output_df = pd.concat([output_df,model_df.iloc[-1]])\n",
    "        output_df = output_df.append(model_df.iloc[-1])\n",
    "        \n",
    "        \n",
    "state_coef_df = output_df.copy()\n",
    "state_coef_df.columns = [ ['date','intercept','total'] + list(x_column) ]\n",
    "print(\"State Coef\")\n",
    "print(state_coef_df)\n",
    "if 'state_coef_df' not in df_list:\n",
    "    df_list.append('state_coef_df')\n",
    "#//*** Eliminate lingering temp variables\n",
    "del output_df\n",
    "del model_df\n",
    "\"\"\"\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#//*** Version 1: Covert Coefficients to percentages\n",
    "\n",
    "#//************************************************\n",
    "#//*** Convert Coefficients to percentages\n",
    "#//************************************************\n",
    "#//*** Racial Coefficients are built for each race by day and county.\n",
    "#//*** Group output_df by date, to calculate the race percent for each county by day.\n",
    "#//*** The Racial Percentage is\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "x_col_index = 4\n",
    "x_column = model_df.columns[x_col_index:]\n",
    "output2_df = pd.DataFrame()\n",
    "\n",
    "break_counter = 0\n",
    "for row in processing_df.iterrows():\n",
    "    \n",
    "\n",
    "    loop_row = row[1]\n",
    "    \n",
    "    \n",
    "    total = row[1][2]\n",
    "    #print(\"Total: \",total)\n",
    "    intercept = row[1][3]\n",
    "    #print(\"Intercept: \",total-intercept)\n",
    "    loop_row[4:] = loop_row[4:]\n",
    "    #x_range = loop_row[4:].max() - loop_row[4:].min()\n",
    "    #x_range = total - loop_row[4:].min()\n",
    "    #print(\"x_norm: \", x_norm)\n",
    "    #print((loop_row[4:]-min_val)/x_range)\n",
    "    \n",
    "    #loop_row[4:] = loop_row[4:].replace(0,1)\n",
    "    #print(loop_row[4:].sum())\n",
    "    \n",
    "    #//*** ABSOLUTE Value method\n",
    "    #loop_row[4:] = abs(loop_row[4:])/abs(loop_row[4:]).sum()\n",
    "    \n",
    "    #//*** Find double the minimum value. This is the offset value.\n",
    "    #//*** Used to make negative values positive\n",
    "    offset_value = abs(loop_row[4:].min()*2)\n",
    "    \n",
    "    #//*** The total offset which is added to all the values.\n",
    "    #//*** The Offset_total has to be added to the maximum value in order to keep the proportions correct\n",
    "    offset_total = offset_value*len(loop_row[4:])\n",
    "    \n",
    "    #print(\"Offset: \",offset_total)\n",
    "\n",
    "    \n",
    "    #//*** If all values were positive and there was no need for adjusted, the max value would be the loop_row['total'] \n",
    "    #//*** Max_value is calculated as Race Total (loop_row['total']) + offset_total - intercept.\n",
    "    #//*** We can verify this value by compaing it to the sum() of all the values.\n",
    "    max_value = (loop_row['total'] + offset_total) - loop_row['intercept']\n",
    "    #print(loop_row['date'],\" \", loop_row['race'],\"- [\",max_value, \" == \",(loop_row[4:]+offset_value).sum(), \"] [ 1 == \", ((loop_row[4:]+offset_value)/max_value).sum(),\"]\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #//*** Calculate the modeled percentage of each caounty's contribution\n",
    "    #//*** Percentages: value + offset / max_value\n",
    "    #//*** Case contribution: race total * value + offset / max_value\n",
    "    #//*** Original formula\n",
    "    #loop_row[4:] = ((loop_row[4:]+offset_value)/max_value)*loop_row['total']\n",
    "    \n",
    "    #//*** Reformulated\n",
    "    #//*** Square the results to remove negative values\n",
    "    loop_row[4:] = loop_row[4:]**2\n",
    "    \n",
    "    #//*** Divide by the sum to get relative percentages\n",
    "    loop_row[4:] = loop_row[4:]/loop_row[4:].sum()\n",
    "    \n",
    "    #//*** Multiply by the total to get the weighted percentage of racial values\n",
    "    loop_row[4:] = loop_row[4:]*loop_row['total']\n",
    "    \n",
    "    #print((((loop_row[4:]+offset_value)/max_value)*loop_row['total']).sum())\n",
    "    #print( (loop_row[4:]*loop_row['total']))\n",
    "    #print(pd.DataFrame(loop_row).transpose())\n",
    "    #loop_row[4:] = ( (loop_row[4:].pow(2)/ (total+intercept)**2 ).pow(1./2) )\n",
    "    #print( abs(loop_row[4:]).sum())  \n",
    "    #print( loop_row[4:])  \n",
    "    #print(abs((loop_row[4:]/(total))).sum())    \n",
    "    #min_val = loop_row[4:].min()\n",
    "    #print(\"min: \", loop_row[4:].min())\n",
    "    #//*** Make a coopy of sliced dataframe. This prevents index errors\n",
    "    #loop_df = group[1].copy()\n",
    "    \n",
    "\n",
    "    output2_df = pd.concat([output2_df,pd.DataFrame(loop_row).transpose()])\n",
    "    #print(loop_row['total'])\n",
    "    #print(loop_row)\n",
    "    break_counter = break_counter + 1\n",
    "    \n",
    "#    if break_counter > 250:\n",
    "#        print(loop_row[4:].sum())\n",
    "#        print(loop_row)\n",
    "#        break\n",
    "    \n",
    "    \n",
    "ca_case_race_total_df = output2_df.copy().fillna(0)\n",
    "\n",
    "ca_case_race_total_df.index = np.arange(0,len(ca_case_race_total_df))\n",
    "\n",
    "print(f'Racial Percentages Calculated: {round(time.time()-start_time,0)}s')\n",
    "print(ca_case_race_total_df)\n",
    "if 'ca_case_race_total_df' not in df_list:\n",
    "    df_list.append('ca_case_race_total_df')\n",
    "#//*** Temp Variable Cleanup\n",
    "#del output_df\n",
    "#del output2_df\n",
    "#del loop_df\n",
    "#del model_df\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "100k Modeling is a fail\n",
    "\n",
    "#ca_broad_race_100k_df\n",
    "#ca_broad_cases_100k_df\n",
    "#ca_case_race_100k_df\n",
    "\n",
    "t_date = ca_case_race_100k_df.iloc[random.randint(0,len(ca_case_race_100k_df))]['date']\n",
    "t_total = ca_case_race_100k_df[ca_case_race_100k_df['date']==t_date]['total']\n",
    "\n",
    "print(t_date)\n",
    "\n",
    "tdf1 = ca_broad_cases_100k_df[ca_broad_cases_100k_df['date']== t_date]\n",
    "print(tdf1[tdf1.columns[2:]].transpose().sum())\n",
    "print(\"===================\")\n",
    "print(ca_case_race_100k_df[ca_case_race_100k_df['date']==t_date].iloc[3][2])\n",
    "print(ca_case_race_100k_df[ca_case_race_100k_df['date']==t_date].iloc[3][4:].sum())\n",
    "print(\"===================\")\n",
    "print(tdf1)\n",
    "print(\"===================\")\n",
    "print(\"Total COVID cases by Race on this day: \",ca_broad_race_100k_df[ca_broad_race_100k_df['date']==t_date].transpose()[1:].sum().values[0])\n",
    "print(\"Total COVID cases by County:           \",tdf1['total'].values[0])\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "100k Modeling is a fail\n",
    "\n",
    "#//*** Compare the Modeled County Totals to the Actual Totals. \n",
    "for county in ordered_counties:\n",
    "    #print(county, \" Actual: \",ca_cases_broad_df[county].sum(), \" - Modeled: \",ca_case_race_total_df[county].sum()   )\n",
    "    print(\"A: \",ca_cases_broad_df[county].sum(), \" - M: \",round(ca_case_race_100k_df[county].sum(),0), \" \", county   )\n",
    "print(ca_cases_broad_df['Los Angeles'].sum())\n",
    "\n",
    "print(ca_case_race_total_df['Los Angeles'].sum())\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "100k Linear Regression is not the way to go.\n",
    "\n",
    "ca_broad_cases_100k_df = build_broad_county_attribute(ca_100k_df,'cases')\n",
    "\n",
    "ca_broad_race_100k_df = build_broad_race_attribute(ca_race_df,'cases_100k')\n",
    "#build_broad_race_attribute\n",
    "\n",
    "#print(ca_100k_cases_df)\n",
    "\n",
    "#//************************************************************************************************************************************************************************\n",
    "#//*** Calculate the coefficients for Racial data for each county day.\n",
    "#//*** This uses LinearRegression to generate coefficients which are weighted with the county cases of the day.\n",
    "#//*** Coefficients derive individual counties affect on the whole of racial COVID cases. The idea is to estimate every counties given portion of the racial cases.\n",
    "#//*** Each race is modeled separately. The coefficients are converted to percentages in the following step\n",
    "#//************************************************************************************************************************************************************************\n",
    "\n",
    "\n",
    "#//*** left_df contains the broad racial categories\n",
    "left_df = ca_broad_race_100k_df\n",
    "\n",
    "#//*** Right df contains each county as a column, with one value aggregated. Such as raw COVID cases.\n",
    "right_df = ca_broad_cases_100k_df\n",
    "\n",
    "#//*** County Columns start at Index 3.\n",
    "#//*** These values are a little unintuitive, since they are releveant during the function operation. They are used to indicate which columns are used via the first elements index position\n",
    "x_col_index = 3\n",
    "\n",
    "#//*** Target Independent Column Index. Statewide race numbers begin at column 1\n",
    "#//*** These values are a little unintuitive. They are used to indicate which columns are used via the first elements index position\n",
    "y_col_index = 1\n",
    "\n",
    "processing_df = calculate_coefficients(left_df,right_df,x_col_index,y_col_index)\n",
    "\n",
    "#//**** County Column index start\n",
    "x_col_index = 4\n",
    "\n",
    "#//*** Convert coefficients to percentages,\n",
    "\n",
    "ca_case_race_100k_df =coef_to_percent(processing_df,x_col_index)\n",
    "\n",
    "\n",
    "print(ca_case_race_total_df)\n",
    "if 'ca_case_race_100k_df' not in df_list:\n",
    "    df_list.append('ca_case_race_100k_df')\n",
    "\n",
    "print(\"Done\")\n",
    "\"\"\"\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
