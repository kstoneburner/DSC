{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "For 5.1 I'm choosing to work from the eBook. My process primarily involves copy/pasting code and copy from the book. My goal is to treat this assignment as future reference material. Therefore, my preference is to comment every line of code so I understand it's function. I'll bring in sections of the book as contextual reference material as well. It's a time-consuming process that isn't focused on learning the material per se, but as getting a general conceptual understanding then creating a method for future retrieval.\n",
    "\n",
    "At this phase of my life I have forgotten many multiples of anything I have created. One of my personal running themes is whenever I need to update old code, my first thought is 'who wrote this?'. The answer is always me....Every bit of it. Now, I try to over comment as much as possible. I don't always succeed, but it's a good goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stoneburner, Kurt\n",
    "- ## DSC 650 - Week XX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# //*** Imports and Load Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.datasets import imdb\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "#//*** Use the whole window in the IPYNB editor\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "#//*** Maximize columns and rows displayed by pandas\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stonk013\\Anaconda3\\envs\\tensorflow_1\\lib\\site-packages\\keras\\datasets\\imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\stonk013\\Anaconda3\\envs\\tensorflow_1\\lib\\site-packages\\keras\\datasets\\imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "#//*** Download Data and Load arrays\n",
    "(train_data, train_labels), (test_data,test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#//*** Word_index is dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "#//*** Maps indexes to words\n",
    "reverse_word_index = dict(\n",
    "    [(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "#//*** Decodes the Review\n",
    "decoded_review = ' '.join(\n",
    "    [reverse_word_index.get(i - 3, '?') for i in train_data[0]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can’t feed lists of integers into a neural network. You have to turn your lists intotensors. There are two ways to do that:\n",
    " - Pad your lists so that they all have the same length, turn them into an integertensor  of  shape  (samples,word_indices),  and  then  use  as  the  first  layer  inyour network a layer capable of handling such integer tensors (the Embeddinglayer, which we’ll cover in detail later in the book).\n",
    " \n",
    " \n",
    " - **(Example Below: vectorize_sequences)** One-hot  encode  your  lists  to  turn  them  into  vectors  of  0s  and  1s.  This  would mean, for instance, turning the sequence [3, 5] into a 10,000-dimensional vec-tor that would be all 0s except for indices 3 and 5, which would be 1s. Then you could use as the first layer in your network a Dense layer, capable of handling floating-point vector data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#//*** Lists of integers must be converted into tensors.\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    #//*** Builds zero filled matrix of shape dimension\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    \n",
    "    #//*** Assigns 1s to the specific integer for references.\n",
    "    #//*** This is manual one-hot encoding\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        \n",
    "         for j in sequence:   \n",
    "            results[i, j] = 1.\n",
    "                \n",
    "    return results\n",
    "    \n",
    "#//*** Download Data and Load arrays\n",
    "(train_data, train_labels), (test_data,test_labels) = imdb.load_data(num_words=10000)    \n",
    "    \n",
    "#//*** Vectorize the Training and Test data\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)\n",
    "\n",
    "#//*** Vectorize the Training and Test Labels\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Network ##\n",
    "The input data is vectors, and the labels are scalars (1s and 0s): this is the easiest setup you’ll  ever  encounter.  A  type  of  network  that  performs  well  on  such  a  problem  is a simple  stack  of  fully  connected  (Dense)  layers  with  relu  activations:  *Dense(16,activation='relu')*.  \n",
    "\n",
    "The argument  being  passed  to  each  Dense layer (16) is the number of hidden units of the layer. A hidden unit is a dimension in the representation space of the layer. Each such Dense layer with a relu activation implements the following chain of tensor operations: \n",
    "\n",
    "**output = relu(dot(W, input) + b)** \n",
    "\n",
    "Having 16 hidden units means the weight matrix W will have shape (input_dimension,16): the dot product with W will project the input data onto a 16-dimensional representation space (and then you’ll add the bias vector b and apply the relu operation). \n",
    "\n",
    "You can  intuitively understand the dimensionality of your representation space as  “how much freedom you’re allowing the network to have when learning internal representations.” *Having more hidden units (a  higher-dimensional representation  space) allows your network to learn more-complex representations, but it makes the network more  computationally  expensive and may lead to learning unwanted patterns (patterns that will improve performance on the training data but not on the test data).*\n",
    "\n",
    "There are two key architecture decisions to be made about such a stack of Dense layers: \n",
    "- How many layers to use\n",
    "- How many hidden units to choose for each layer\n",
    "\n",
    "For the time being go with the following architecture choice: \n",
    "- Two intermediate layers with 16 hidden units each \n",
    "- A third layer that will output the scalar prediction regarding the sentiment ofthe current review\n",
    "\n",
    "The intermediate layers will use *relu* as their activation function, and the final layer will use a sigmoid activation so as to output a probability (a score between 0 and 1, indicating how likely the sample is to have the target “1”: how likely the review is to be positive). A *relu* (rectified linear unit) is a function meant to zero out negative values, whereas a sigmoid “squashes” arbitrary values into the [0, 1] interval, outputting something that can be interpreted as a probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 2s 145us/step - loss: 0.5089 - acc: 0.7859 - val_loss: 0.4025 - val_acc: 0.8471\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 2s 114us/step - loss: 0.3072 - acc: 0.9012 - val_loss: 0.3041 - val_acc: 0.8879\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 0.2237 - acc: 0.9272 - val_loss: 0.3107 - val_acc: 0.8724\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 2s 114us/step - loss: 0.1766 - acc: 0.9430 - val_loss: 0.2723 - val_acc: 0.8914\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 0.1479 - acc: 0.9519 - val_loss: 0.2768 - val_acc: 0.8898\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.1196 - acc: 0.9623 - val_loss: 0.2960 - val_acc: 0.8842\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.1002 - acc: 0.9695 - val_loss: 0.3075 - val_acc: 0.8848\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.0873 - acc: 0.9753 - val_loss: 0.3296 - val_acc: 0.8819\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.0695 - acc: 0.9810 - val_loss: 0.3513 - val_acc: 0.8768\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 0.0613 - acc: 0.9850 - val_loss: 0.3666 - val_acc: 0.8784\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.0508 - acc: 0.9866 - val_loss: 0.3977 - val_acc: 0.8745\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.0395 - acc: 0.9917 - val_loss: 0.4217 - val_acc: 0.8744\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.0339 - acc: 0.9921 - val_loss: 0.4550 - val_acc: 0.8738\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.0279 - acc: 0.9944 - val_loss: 0.4865 - val_acc: 0.8723\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 2s 117us/step - loss: 0.0218 - acc: 0.9965 - val_loss: 0.5227 - val_acc: 0.8692\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 0.0173 - acc: 0.9975 - val_loss: 0.5645 - val_acc: 0.8698\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 0.0155 - acc: 0.9974 - val_loss: 0.5916 - val_acc: 0.8676\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 2s 116us/step - loss: 0.0115 - acc: 0.9985 - val_loss: 0.6789 - val_acc: 0.8628\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 0.0073 - acc: 0.9997 - val_loss: 0.6474 - val_acc: 0.8668\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 2s 115us/step - loss: 0.0075 - acc: 0.9995 - val_loss: 0.6891 - val_acc: 0.8665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "#//*** Compile the Model\n",
    "\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(lr=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#//*** Configure the Optimizer\n",
    "#model.compile(\n",
    "#    optimizer=optimizers.RMSprop(lr=0.001),\n",
    "#    loss=losses.binary_crossentropy,\n",
    "#    metrics=[metrics.binary_accuracy]\n",
    "#)\n",
    "\n",
    "\n",
    "#//*** Use Custom Losses and Metrics\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "\n",
    "#//*** Set Aside a Validation Set\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train[10000:]\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "#//*** Train Model\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    partial_x_train,\n",
    "    partial_y_train,\n",
    "    epochs=20,\n",
    "    batch_size=512,\n",
    "    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#//*** Plotting the training and validation loss\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "acc = history_dict['acc']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.4688 - accuracy: 0.8216\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.2688 - accuracy: 0.9067\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.2044 - accuracy: 0.9282\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1719 - accuracy: 0.9395\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1481 - accuracy: 0.9479\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1295 - accuracy: 0.9559\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1142 - accuracy: 0.9614\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0998 - accuracy: 0.9657\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0903 - accuracy: 0.9712\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0784 - accuracy: 0.9746\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0698 - accuracy: 0.9786\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0582 - accuracy: 0.9830\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0529 - accuracy: 0.9850\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0453 - accuracy: 0.9871\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0375 - accuracy: 0.9904\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0335 - accuracy: 0.9915\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0274 - accuracy: 0.9939\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0223 - accuracy: 0.9951\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0202 - accuracy: 0.9954\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0157 - accuracy: 0.9971\n",
      "25000/25000 [==============================] - 3s 109us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7674488276898861, 0.8497999906539917]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//*** retraining a model from scratch\n",
    "#//*** Previous Results didn't go well. Book suggests Overfitting, But it doesn't look like the \n",
    "#//*** Accuracy and Validation values worked well. \n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_binary_output_model(**kwargs):\n",
    "    #//*** Define the Model\n",
    "    from keras import models\n",
    "    from keras import layers\n",
    "    from keras import optimizers\n",
    "    \n",
    "    \n",
    "    #//*****************************\n",
    "    #//*** Set Default values\n",
    "    #//*****************************\n",
    "    total_layers = 2\n",
    "    hidden_units = 16\n",
    "    first_activation = \"relu\"\n",
    "    final_activation='sigmoid'\n",
    "    optimizer='rmsprop'  \n",
    "    loss = 'mse'\n",
    "    metrics=['accuracy']\n",
    "    shape = (0,0)\n",
    "    do_compile = True\n",
    "    \n",
    "    #//*** Apply Kwargs\n",
    "    for key,value in kwargs.items():\n",
    "        \n",
    "        if key == 'layers':\n",
    "            total_layers=value\n",
    "\n",
    "        if key == 'hidden_units':\n",
    "            hidden_units=value\n",
    "        \n",
    "        if key == 'loss':\n",
    "            loss=value\n",
    "        \n",
    "        if key == 'first_activation':\n",
    "            first_activation=value\n",
    "    \n",
    "        if key == 'final_activation':\n",
    "            final_activation=value\n",
    "    \n",
    "        if key == 'optimizer':\n",
    "            optimizer=value\n",
    "    \n",
    "        if key == 'metrics':\n",
    "            metrics=value\n",
    "            \n",
    "        if key == 'shape':\n",
    "            shape = value\n",
    "\n",
    "        if key == 'compile':\n",
    "            do_compile = value\n",
    "\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    \n",
    "    #//*** Add First Layer\n",
    "    model.add(layers.Dense(hidden_units, activation=first_activation, input_shape=shape ))\n",
    "    \n",
    "    \n",
    "    #//*** Add Additional Layers if total_layers greater than 2\n",
    "    for x in range(total_layers-2):\n",
    "        \n",
    "        #//*** These are basic layers with same number of hidden units and using first_activation\n",
    "        model.add(layers.Dense(hidden_units, activation=first_activation))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #//*** Add Final Layer\n",
    "    model.add(layers.Dense(1, activation=final_activation))\n",
    "    \n",
    "    #//*** Compile Model\n",
    "    if do_compile:\n",
    "        \n",
    "        model.compile(optimizer=optimizer,loss=loss,metrics=metrics)\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 0.4433 - accuracy: 0.8272\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.2559 - accuracy: 0.9098\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.1996 - accuracy: 0.9286\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.1669 - accuracy: 0.9406\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.1442 - accuracy: 0.9498\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1297 - accuracy: 0.9548\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.1145 - accuracy: 0.9604\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.1040 - accuracy: 0.9650\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.0925 - accuracy: 0.9685\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.0837 - accuracy: 0.9720\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.0749 - accuracy: 0.9761\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.0680 - accuracy: 0.9780\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0603 - accuracy: 0.9809\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0546 - accuracy: 0.9821\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0472 - accuracy: 0.9862\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0439 - accuracy: 0.9866\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0363 - accuracy: 0.9894\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0339 - accuracy: 0.9897\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0289 - accuracy: 0.9915\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.0254 - accuracy: 0.9930\n",
      "25000/25000 [==============================] - 2s 98us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.784260949203968, 0.8456000089645386]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//****************************\n",
    "#//*** Book Supplied Settings\n",
    "#//****************************\n",
    "model_shape = (10000,)\n",
    "layers = 3\n",
    "hidden_units = 16\n",
    "first_activation = \"relu\"\n",
    "final_activation = \"sigmoid\"\n",
    "optimizer = \"rmsprop\"\n",
    "loss = 'binary_crossentropy'\n",
    "model = build_binary_output_model(\n",
    "    shape=model_shape,\n",
    "    layers=layers, \n",
    "    hidden_units = hidden_units,\n",
    "    first_activation = first_activation,\n",
    "    final_activation=final_activation, \n",
    "    optimizer=optimizer,\n",
    "    loss=loss,metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further experiments ### \n",
    "The following experiments will help convince you that the architecture choices you’ve made are all fairly reasonable, although there’s still room for improvement:\n",
    " - You used two hidden layers. Try using one or three hidden layers, and see how doing so affects validation and test accuracy.\n",
    " - Try using layers with more hidden units or fewer hidden units: 32 units, 64 units,and so on.\n",
    " - Try using the mse loss function instead of binary_crossentropy.\n",
    " - Try using the tanh activation (an activation that was popular in the early days ofneural networks) instead of relu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 0.4433 - accuracy: 0.8302\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.2723 - accuracy: 0.9088\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.2169 - accuracy: 0.9256\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1853 - accuracy: 0.9362\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1622 - accuracy: 0.9458\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1461 - accuracy: 0.9507\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1328 - accuracy: 0.9561\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 2s 69us/step - loss: 0.1212 - accuracy: 0.9601\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1116 - accuracy: 0.9649\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1030 - accuracy: 0.9675\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0957 - accuracy: 0.9701\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0886 - accuracy: 0.9721\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0820 - accuracy: 0.9750\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0755 - accuracy: 0.9773\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0699 - accuracy: 0.9804\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0655 - accuracy: 0.9808\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0604 - accuracy: 0.9829\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0560 - accuracy: 0.9849\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0530 - accuracy: 0.9854\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0497 - accuracy: 0.9874\n",
      "25000/25000 [==============================] - 2s 99us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5378031985211372, 0.8550000190734863]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//****************************\n",
    "#//*** Suggestion use One Hidden Layer\n",
    "#//****************************\n",
    "model_shape = (10000,)\n",
    "layers = 2\n",
    "hidden_units = 16\n",
    "first_activation = \"relu\"\n",
    "final_activation = \"sigmoid\"\n",
    "optimizer = \"rmsprop\"\n",
    "loss = 'binary_crossentropy'\n",
    "model = build_binary_output_model(\n",
    "    shape=model_shape,\n",
    "    layers=layers, \n",
    "    hidden_units = hidden_units,\n",
    "    first_activation = first_activation,\n",
    "    final_activation=final_activation, \n",
    "    optimizer=optimizer,\n",
    "    loss=loss,metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 0.4713 - accuracy: 0.8161\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.2571 - accuracy: 0.9082\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1938 - accuracy: 0.9312\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1637 - accuracy: 0.9408\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1381 - accuracy: 0.9507\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.1166 - accuracy: 0.9599\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1029 - accuracy: 0.9652\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0848 - accuracy: 0.9725\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0700 - accuracy: 0.9784\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0587 - accuracy: 0.9816\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0492 - accuracy: 0.9848\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0373 - accuracy: 0.9897\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0315 - accuracy: 0.9910\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0240 - accuracy: 0.9933\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0193 - accuracy: 0.9947\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.0195 - accuracy: 0.9946\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0138 - accuracy: 0.9957\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0131 - accuracy: 0.9964\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 0.0124 - accuracy: 0.9967\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0021 - accuracy: 0.9999\n",
      "25000/25000 [==============================] - 3s 100us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.904493507720232, 0.8524399995803833]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//****************************************\n",
    "#//*** Suggestion: use Three Hidden Layers\n",
    "#//****************************************\n",
    "model_shape = (10000,)\n",
    "layers = 4\n",
    "hidden_units = 16\n",
    "first_activation = \"relu\"\n",
    "final_activation = \"sigmoid\"\n",
    "optimizer = \"rmsprop\"\n",
    "loss = 'binary_crossentropy'\n",
    "model = build_binary_output_model(\n",
    "    shape=model_shape,\n",
    "    layers=layers, \n",
    "    hidden_units = hidden_units,\n",
    "    first_activation = first_activation,\n",
    "    final_activation=final_activation, \n",
    "    optimizer=optimizer,\n",
    "    loss=loss,metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 2s 74us/step - loss: 0.4372 - accuracy: 0.8187\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 0.2454 - accuracy: 0.9107\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1895 - accuracy: 0.9308\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1567 - accuracy: 0.9434\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 0.1382 - accuracy: 0.9496\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1186 - accuracy: 0.9571\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0982 - accuracy: 0.9656\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0906 - accuracy: 0.9670\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0756 - accuracy: 0.9738\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0646 - accuracy: 0.9781\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0543 - accuracy: 0.9830\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0482 - accuracy: 0.9842\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0372 - accuracy: 0.9880\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 2s 72us/step - loss: 0.0317 - accuracy: 0.9898\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0239 - accuracy: 0.9930\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0228 - accuracy: 0.9933\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0195 - accuracy: 0.9944\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0142 - accuracy: 0.9963\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0157 - accuracy: 0.9962\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0140 - accuracy: 0.9960\n",
      "25000/25000 [==============================] - 2s 99us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9630567930829524, 0.8492400050163269]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//****************************************\n",
    "#//*** Suggestion: use 32 Hidden Units\n",
    "#//****************************************\n",
    "model_shape = (10000,)\n",
    "layers = 3\n",
    "hidden_units = 32\n",
    "first_activation = \"relu\"\n",
    "final_activation = \"sigmoid\"\n",
    "optimizer = \"rmsprop\"\n",
    "loss = 'binary_crossentropy'\n",
    "model = build_binary_output_model(\n",
    "    shape=model_shape,\n",
    "    layers=layers, \n",
    "    hidden_units = hidden_units,\n",
    "    first_activation = first_activation,\n",
    "    final_activation=final_activation, \n",
    "    optimizer=optimizer,\n",
    "    loss=loss,metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 2s 76us/step - loss: 0.4062 - accuracy: 0.8296\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.2327 - accuracy: 0.9105\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.1814 - accuracy: 0.9320\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.1433 - accuracy: 0.9466\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.1113 - accuracy: 0.9587\n",
      "25000/25000 [==============================] - 3s 101us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3624061553812027, 0.8736799955368042]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//****************************************\n",
    "#//*** Suggestion: use 64 Hidden Units\n",
    "#//****************************************\n",
    "model_shape = (10000,)\n",
    "layers = 3\n",
    "hidden_units = 64\n",
    "first_activation = \"relu\"\n",
    "final_activation = \"sigmoid\"\n",
    "optimizer = \"rmsprop\"\n",
    "loss = 'binary_crossentropy'\n",
    "model = build_binary_output_model(\n",
    "    shape=model_shape,\n",
    "    layers=layers, \n",
    "    hidden_units = hidden_units,\n",
    "    first_activation = first_activation,\n",
    "    final_activation=final_activation, \n",
    "    optimizer=optimizer,\n",
    "    loss=loss,metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.4265 - accuracy: 0.8335\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 2s 70us/step - loss: 0.2351 - accuracy: 0.9137\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1782 - accuracy: 0.9334\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1483 - accuracy: 0.9466\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.1260 - accuracy: 0.9558\n",
      "25000/25000 [==============================] - 2s 100us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.37048709134817126, 0.8697999715805054]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//****************************************\n",
    "#//*** Suggestion: use tanh activation\n",
    "#//****************************************\n",
    "model_shape = (10000,)\n",
    "layers = 3\n",
    "hidden_units = 16\n",
    "first_activation = \"tanh\"\n",
    "final_activation = \"sigmoid\"\n",
    "optimizer = \"rmsprop\"\n",
    "loss = 'binary_crossentropy'\n",
    "model = build_binary_output_model(\n",
    "    shape=model_shape,\n",
    "    layers=layers, \n",
    "    hidden_units = hidden_units,\n",
    "    first_activation = first_activation,\n",
    "    final_activation=final_activation, \n",
    "    optimizer=optimizer,\n",
    "    loss=loss,metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 2s 73us/step - loss: 0.1425 - accuracy: 0.8243\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0765 - accuracy: 0.9115\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0577 - accuracy: 0.9314\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0467 - accuracy: 0.9453\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 2s 71us/step - loss: 0.0396 - accuracy: 0.9538\n",
      "25000/25000 [==============================] - 3s 101us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09036892065763473, 0.8791999816894531]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#//****************************************\n",
    "#//*** Suggestion: use MSE loss\n",
    "#//****************************************\n",
    "model_shape = (10000,)\n",
    "layers = 3\n",
    "hidden_units = 16\n",
    "first_activation = \"relu\"\n",
    "final_activation = \"sigmoid\"\n",
    "optimizer = \"rmsprop\"\n",
    "loss = 'mse'\n",
    "model = build_binary_output_model(\n",
    "    shape=model_shape,\n",
    "    layers=layers, \n",
    "    hidden_units = hidden_units,\n",
    "    first_activation = first_activation,\n",
    "    final_activation=final_activation, \n",
    "    optimizer=optimizer,\n",
    "    loss=loss,metrics=['accuracy']  \n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
